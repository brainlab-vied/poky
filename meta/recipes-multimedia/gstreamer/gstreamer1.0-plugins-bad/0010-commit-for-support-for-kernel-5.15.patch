From 1837107fa1ad966b00ec816db83f282c668b9ed9 Mon Sep 17 00:00:00 2001
From: Deji Aribuki <deji.aribuki@gmail.com>
Date: Mon, 28 Aug 2023 11:54:08 +0200
Subject: [PATCH] commit for support for kernel 5.15

---
 gst-libs/gst/codecs/gsth264decoder.c        | 1733 ++++++++++++++-----
 gst-libs/gst/codecs/gsth264decoder.h        |  156 +-
 gst-libs/gst/codecs/gsth264picture.c        |  885 ++++++++--
 gst-libs/gst/codecs/gsth264picture.h        |  153 +-
 gst-libs/gst/codecs/gsth265decoder.c        |  728 ++++++--
 gst-libs/gst/codecs/gsth265decoder.h        |   34 +-
 gst-libs/gst/codecs/gsth265picture.c        |  261 ++-
 gst-libs/gst/codecs/gsth265picture.h        |   38 +-
 sys/nvcodec/gstnvh264dec.c                  |    2 +
 sys/v4l2codecs/gstv4l2codecallocator.c      |    3 +-
 sys/v4l2codecs/gstv4l2codecalphadecodebin.c |  231 +++
 sys/v4l2codecs/gstv4l2codecalphadecodebin.h |   57 +
 sys/v4l2codecs/gstv4l2codech264dec.c        |  693 +++++---
 sys/v4l2codecs/gstv4l2codech264dec.h        |    1 +
 sys/v4l2codecs/gstv4l2decoder.c             |  344 +++-
 sys/v4l2codecs/gstv4l2decoder.h             |   55 +-
 sys/v4l2codecs/linux/h264-ctrls.h           |  212 ---
 sys/v4l2codecs/linux/media.h                |    9 +-
 sys/v4l2codecs/linux/types-compat.h         |    2 +-
 sys/v4l2codecs/linux/v4l2-common.h          |    2 -
 sys/v4l2codecs/linux/v4l2-controls.h        | 1126 +++++++++---
 sys/v4l2codecs/linux/videodev2.h            |  129 +-
 sys/v4l2codecs/linux/vp8-ctrls.h            |  112 --
 sys/v4l2codecs/meson.build                  |    6 +-
 sys/v4l2codecs/plugin.c                     |   17 +-
 25 files changed, 5173 insertions(+), 1816 deletions(-)
 create mode 100644 sys/v4l2codecs/gstv4l2codecalphadecodebin.c
 create mode 100644 sys/v4l2codecs/gstv4l2codecalphadecodebin.h
 delete mode 100644 sys/v4l2codecs/linux/h264-ctrls.h
 delete mode 100644 sys/v4l2codecs/linux/vp8-ctrls.h

diff --git a/gst-libs/gst/codecs/gsth264decoder.c b/gst-libs/gst/codecs/gsth264decoder.c
index 7a79ce7a1..ea18f6a0c 100644
--- a/gst-libs/gst/codecs/gsth264decoder.c
+++ b/gst-libs/gst/codecs/gsth264decoder.c
@@ -58,6 +58,8 @@
 #include <config.h>
 #endif
 
+#include <gst/base/base.h>
+#include <stdio.h>
 #include "gsth264decoder.h"
 
 GST_DEBUG_CATEGORY (gst_h264_decoder_debug);
@@ -79,12 +81,11 @@ typedef enum
 
 struct _GstH264DecoderPrivate
 {
+  GstH264DecoderCompliance compliance;
+
+  guint8 profile_idc;
   gint width, height;
-  gint fps_num, fps_den;
-  gint upstream_par_n, upstream_par_d;
-  gint parsed_par_n, parsed_par_d;
-  gint parsed_fps_n, parsed_fps_d;
-  GstVideoColorimetry parsed_colorimetry;
+
   /* input codec_data, if any */
   GstBuffer *codec_data;
   guint nal_length_size;
@@ -94,6 +95,9 @@ struct _GstH264DecoderPrivate
   GstH264DecoderAlign align;
   GstH264NalParser *parser;
   GstH264Dpb *dpb;
+  /* Cache last field which can not enter the DPB, should be a non ref */
+  GstH264Picture *last_field;
+
   GstFlowReturn last_ret;
   /* used for low-latency vs. high throughput mode decision */
   gboolean is_live;
@@ -112,7 +116,6 @@ struct _GstH264DecoderPrivate
   gint max_frame_num;
   gint max_pic_num;
   gint max_long_term_frame_idx;
-  gsize max_num_reorder_frames;
 
   gint prev_frame_num;
   gint prev_ref_frame_num;
@@ -131,20 +134,37 @@ struct _GstH264DecoderPrivate
   gint last_output_poc;
 
   gboolean process_ref_pic_lists;
+  guint preferred_output_delay;
 
   /* Reference picture lists, constructed for each frame */
   GArray *ref_pic_list_p0;
   GArray *ref_pic_list_b0;
   GArray *ref_pic_list_b1;
 
+  /* Temporary picture list, for reference picture lists in fields,
+   * corresponding to 8.2.4.2.2 refFrameList0ShortTerm, refFrameList0LongTerm
+   * and 8.2.4.2.5 refFrameList1ShortTerm and refFrameListLongTerm */
+  GArray *ref_frame_list_0_short_term;
+  GArray *ref_frame_list_1_short_term;
+  GArray *ref_frame_list_long_term;
+
   /* Reference picture lists, constructed for each slice */
   GArray *ref_pic_list0;
   GArray *ref_pic_list1;
 
-  /* Cached array to handle pictures to be outputed */
-  GArray *to_output;
+  /* For delayed output */
+  GstQueueArray *output_queue;
 };
 
+typedef struct
+{
+  /* Holds ref */
+  GstVideoCodecFrame *frame;
+  GstH264Picture *picture;
+  /* Without ref */
+  GstH264Decoder *self;
+} GstH264DecoderOutputFrame;
+
 #define parent_class gst_h264_decoder_parent_class
 G_DEFINE_ABSTRACT_TYPE_WITH_CODE (GstH264Decoder, gst_h264_decoder,
     GST_TYPE_VIDEO_DECODER,
@@ -169,7 +189,7 @@ static gboolean gst_h264_decoder_process_sps (GstH264Decoder * self,
     GstH264SPS * sps);
 static gboolean gst_h264_decoder_decode_slice (GstH264Decoder * self);
 static gboolean gst_h264_decoder_decode_nal (GstH264Decoder * self,
-    GstH264NalUnit * nalu, GstClockTime pts);
+    GstH264NalUnit * nalu);
 static gboolean gst_h264_decoder_fill_picture_from_slice (GstH264Decoder * self,
     const GstH264Slice * slice, GstH264Picture * picture);
 static gboolean gst_h264_decoder_calculate_poc (GstH264Decoder * self,
@@ -180,9 +200,97 @@ static gboolean gst_h264_decoder_drain_internal (GstH264Decoder * self);
 static gboolean gst_h264_decoder_finish_current_picture (GstH264Decoder * self);
 static gboolean gst_h264_decoder_finish_picture (GstH264Decoder * self,
     GstH264Picture * picture);
-static void gst_h264_decoder_prepare_ref_pic_lists (GstH264Decoder * self);
+static void gst_h264_decoder_prepare_ref_pic_lists (GstH264Decoder * self,
+    GstH264Picture * current_picture);
 static void gst_h264_decoder_clear_ref_pic_lists (GstH264Decoder * self);
 static gboolean gst_h264_decoder_modify_ref_pic_lists (GstH264Decoder * self);
+static gboolean
+gst_h264_decoder_sliding_window_picture_marking (GstH264Decoder * self,
+    GstH264Picture * picture);
+static void gst_h264_decoder_do_output_picture (GstH264Decoder * self,
+    GstH264Picture * picture);
+static GstH264Picture *gst_h264_decoder_new_field_picture (GstH264Decoder *
+    self, GstH264Picture * picture);
+static void
+gst_h264_decoder_clear_output_frame (GstH264DecoderOutputFrame * output_frame);
+
+enum
+{
+  PROP_0,
+  PROP_COMPLIANCE,
+};
+
+/**
+ * gst_h264_decoder_compliance_get_type:
+ *
+ * Get the compliance type of the h264 decoder.
+ *
+ * Since: 1.20
+ */
+GType
+gst_h264_decoder_compliance_get_type (void)
+{
+  static gsize h264_decoder_compliance_type = 0;
+  static const GEnumValue compliances[] = {
+    {GST_H264_DECODER_COMPLIANCE_AUTO, "GST_H264_DECODER_COMPLIANCE_AUTO",
+        "auto"},
+    {GST_H264_DECODER_COMPLIANCE_STRICT, "GST_H264_DECODER_COMPLIANCE_STRICT",
+        "strict"},
+    {GST_H264_DECODER_COMPLIANCE_NORMAL, "GST_H264_DECODER_COMPLIANCE_NORMAL",
+        "normal"},
+    {GST_H264_DECODER_COMPLIANCE_FLEXIBLE,
+        "GST_H264_DECODER_COMPLIANCE_FLEXIBLE", "flexible"},
+    {0, NULL, NULL},
+  };
+
+
+  if (g_once_init_enter (&h264_decoder_compliance_type)) {
+    GType _type;
+
+    _type = g_enum_register_static ("GstH264DecoderCompliance", compliances);
+    g_once_init_leave (&h264_decoder_compliance_type, _type);
+  }
+
+  return (GType) h264_decoder_compliance_type;
+}
+
+static void
+gst_h264_decoder_get_property (GObject * object, guint property_id,
+    GValue * value, GParamSpec * pspec)
+{
+  GstH264Decoder *self = GST_H264_DECODER (object);
+  GstH264DecoderPrivate *priv = self->priv;
+
+  switch (property_id) {
+    case PROP_COMPLIANCE:
+      GST_OBJECT_LOCK (self);
+      g_value_set_enum (value, priv->compliance);
+      GST_OBJECT_UNLOCK (self);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, property_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_h264_decoder_set_property (GObject * object, guint property_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  GstH264Decoder *self = GST_H264_DECODER (object);
+  GstH264DecoderPrivate *priv = self->priv;
+
+  switch (property_id) {
+    case PROP_COMPLIANCE:
+      GST_OBJECT_LOCK (self);
+      priv->compliance = g_value_get_enum (value);
+      GST_OBJECT_UNLOCK (self);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, property_id, pspec);
+      break;
+  }
+}
 
 static void
 gst_h264_decoder_class_init (GstH264DecoderClass * klass)
@@ -191,6 +299,8 @@ gst_h264_decoder_class_init (GstH264DecoderClass * klass)
   GObjectClass *object_class = G_OBJECT_CLASS (klass);
 
   object_class->finalize = GST_DEBUG_FUNCPTR (gst_h264_decoder_finalize);
+  object_class->get_property = gst_h264_decoder_get_property;
+  object_class->set_property = gst_h264_decoder_set_property;
 
   decoder_class->start = GST_DEBUG_FUNCPTR (gst_h264_decoder_start);
   decoder_class->stop = GST_DEBUG_FUNCPTR (gst_h264_decoder_stop);
@@ -200,6 +310,22 @@ gst_h264_decoder_class_init (GstH264DecoderClass * klass)
   decoder_class->drain = GST_DEBUG_FUNCPTR (gst_h264_decoder_drain);
   decoder_class->handle_frame =
       GST_DEBUG_FUNCPTR (gst_h264_decoder_handle_frame);
+
+  /**
+   * GstH264Decoder:compliance:
+   *
+   * The compliance controls the behavior of the decoder to handle some
+   * subtle cases and contexts, such as the low-latency DPB bumping or
+   * mapping the baseline profile as the constrained-baseline profile,
+   * etc.
+   *
+   * Since: 1.20
+   */
+  g_object_class_install_property (object_class, PROP_COMPLIANCE,
+      g_param_spec_enum ("compliance", "Decoder Compliance",
+          "The decoder's behavior in compliance with the h264 spec.",
+          GST_TYPE_H264_DECODER_COMPLIANCE, GST_H264_DECODER_COMPLIANCE_AUTO,
+          G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT));
 }
 
 static void
@@ -211,6 +337,8 @@ gst_h264_decoder_init (GstH264Decoder * self)
 
   self->priv = priv = gst_h264_decoder_get_instance_private (self);
 
+  priv->last_output_poc = G_MININT32;
+
   priv->ref_pic_list_p0 = g_array_sized_new (FALSE, TRUE,
       sizeof (GstH264Picture *), 32);
   g_array_set_clear_func (priv->ref_pic_list_p0,
@@ -226,15 +354,30 @@ gst_h264_decoder_init (GstH264Decoder * self)
   g_array_set_clear_func (priv->ref_pic_list_b1,
       (GDestroyNotify) gst_h264_picture_clear);
 
+  priv->ref_frame_list_0_short_term = g_array_sized_new (FALSE, TRUE,
+      sizeof (GstH264Picture *), 32);
+  g_array_set_clear_func (priv->ref_frame_list_0_short_term,
+      (GDestroyNotify) gst_h264_picture_clear);
+
+  priv->ref_frame_list_1_short_term = g_array_sized_new (FALSE, TRUE,
+      sizeof (GstH264Picture *), 32);
+  g_array_set_clear_func (priv->ref_frame_list_1_short_term,
+      (GDestroyNotify) gst_h264_picture_clear);
+
+  priv->ref_frame_list_long_term = g_array_sized_new (FALSE, TRUE,
+      sizeof (GstH264Picture *), 32);
+  g_array_set_clear_func (priv->ref_frame_list_long_term,
+      (GDestroyNotify) gst_h264_picture_clear);
+
   priv->ref_pic_list0 = g_array_sized_new (FALSE, TRUE,
       sizeof (GstH264Picture *), 32);
   priv->ref_pic_list1 = g_array_sized_new (FALSE, TRUE,
       sizeof (GstH264Picture *), 32);
 
-  priv->to_output = g_array_sized_new (FALSE, TRUE,
-      sizeof (GstH264Picture *), 16);
-  g_array_set_clear_func (priv->to_output,
-      (GDestroyNotify) gst_h264_picture_clear);
+  priv->output_queue =
+      gst_queue_array_new_for_struct (sizeof (GstH264DecoderOutputFrame), 1);
+  gst_queue_array_set_clear_func (priv->output_queue,
+      (GDestroyNotify) gst_h264_decoder_clear_output_frame);
 }
 
 static void
@@ -246,19 +389,41 @@ gst_h264_decoder_finalize (GObject * object)
   g_array_unref (priv->ref_pic_list_p0);
   g_array_unref (priv->ref_pic_list_b0);
   g_array_unref (priv->ref_pic_list_b1);
+  g_array_unref (priv->ref_frame_list_0_short_term);
+  g_array_unref (priv->ref_frame_list_1_short_term);
+  g_array_unref (priv->ref_frame_list_long_term);
   g_array_unref (priv->ref_pic_list0);
   g_array_unref (priv->ref_pic_list1);
-  g_array_unref (priv->to_output);
+  gst_queue_array_free (priv->output_queue);
 
   G_OBJECT_CLASS (parent_class)->finalize (object);
 }
 
+static void
+gst_h264_decoder_reset (GstH264Decoder * self)
+{
+  GstH264DecoderPrivate *priv = self->priv;
+
+  gst_clear_buffer (&priv->codec_data);
+  g_clear_pointer (&self->input_state, gst_video_codec_state_unref);
+  g_clear_pointer (&priv->parser, gst_h264_nal_parser_free);
+  g_clear_pointer (&priv->dpb, gst_h264_dpb_free);
+  gst_h264_picture_clear (&priv->last_field);
+
+  priv->profile_idc = 0;
+  priv->width = 0;
+  priv->height = 0;
+  priv->nal_length_size = 4;
+}
+
 static gboolean
 gst_h264_decoder_start (GstVideoDecoder * decoder)
 {
   GstH264Decoder *self = GST_H264_DECODER (decoder);
   GstH264DecoderPrivate *priv = self->priv;
 
+  gst_h264_decoder_reset (self);
+
   priv->parser = gst_h264_nal_parser_new ();
   priv->dpb = gst_h264_dpb_new ();
 
@@ -269,36 +434,52 @@ static gboolean
 gst_h264_decoder_stop (GstVideoDecoder * decoder)
 {
   GstH264Decoder *self = GST_H264_DECODER (decoder);
-  GstH264DecoderPrivate *priv = self->priv;
 
-  if (self->input_state) {
-    gst_video_codec_state_unref (self->input_state);
-    self->input_state = NULL;
-  }
+  gst_h264_decoder_reset (self);
 
-  gst_clear_buffer (&priv->codec_data);
+  return TRUE;
+}
 
-  if (priv->parser) {
-    gst_h264_nal_parser_free (priv->parser);
-    priv->parser = NULL;
-  }
+static void
+gst_h264_decoder_clear_output_frame (GstH264DecoderOutputFrame * output_frame)
+{
+  if (!output_frame)
+    return;
 
-  if (priv->dpb) {
-    gst_h264_dpb_free (priv->dpb);
-    priv->dpb = NULL;
+  if (output_frame->frame) {
+    gst_video_decoder_release_frame (GST_VIDEO_DECODER (output_frame->self),
+        output_frame->frame);
+    output_frame->frame = NULL;
   }
 
-  return TRUE;
+  gst_h264_picture_clear (&output_frame->picture);
 }
 
 static void
-gst_h264_decoder_clear_dpb (GstH264Decoder * self)
+gst_h264_decoder_clear_dpb (GstH264Decoder * self, gboolean flush)
 {
+  GstVideoDecoder *decoder = GST_VIDEO_DECODER (self);
   GstH264DecoderPrivate *priv = self->priv;
+  GstH264Picture *picture;
+
+  /* If we are not flushing now, videodecoder baseclass will hold
+   * GstVideoCodecFrame. Release frames manually */
+  if (!flush) {
+    while ((picture = gst_h264_dpb_bump (priv->dpb, TRUE)) != NULL) {
+      GstVideoCodecFrame *frame = gst_video_decoder_get_frame (decoder,
+          picture->system_frame_number);
+
+      if (frame)
+        gst_video_decoder_release_frame (decoder, frame);
+      gst_h264_picture_unref (picture);
+    }
+  }
 
+  gst_queue_array_clear (priv->output_queue);
   gst_h264_decoder_clear_ref_pic_lists (self);
+  gst_h264_picture_clear (&priv->last_field);
   gst_h264_dpb_clear (priv->dpb);
-  priv->last_output_poc = -1;
+  priv->last_output_poc = G_MININT32;
 }
 
 static gboolean
@@ -306,7 +487,7 @@ gst_h264_decoder_flush (GstVideoDecoder * decoder)
 {
   GstH264Decoder *self = GST_H264_DECODER (decoder);
 
-  gst_h264_decoder_clear_dpb (self);
+  gst_h264_decoder_clear_dpb (self, TRUE);
 
   return TRUE;
 }
@@ -347,6 +528,11 @@ gst_h264_decoder_handle_frame (GstVideoDecoder * decoder,
       GST_TIME_FORMAT, GST_TIME_ARGS (GST_BUFFER_PTS (in_buf)),
       GST_TIME_ARGS (GST_BUFFER_DTS (in_buf)));
 
+  GST_DEBUG_OBJECT (self,
+      "handle frame, PTS: %" GST_TIME_FORMAT ", DTS: %"
+      GST_TIME_FORMAT, GST_TIME_ARGS (GST_BUFFER_PTS (in_buf)),
+      GST_TIME_ARGS (GST_BUFFER_DTS (in_buf)));
+
   priv->current_frame = frame;
   priv->last_ret = GST_FLOW_OK;
 
@@ -356,8 +542,7 @@ gst_h264_decoder_handle_frame (GstVideoDecoder * decoder,
         map.data, 0, map.size, priv->nal_length_size, &nalu);
 
     while (pres == GST_H264_PARSER_OK && decode_ret) {
-      decode_ret = gst_h264_decoder_decode_nal (self,
-          &nalu, GST_BUFFER_PTS (in_buf));
+      decode_ret = gst_h264_decoder_decode_nal (self, &nalu);
 
       pres = gst_h264_parser_identify_nalu_avc (priv->parser,
           map.data, nalu.offset + nalu.size, map.size, priv->nal_length_size,
@@ -371,8 +556,7 @@ gst_h264_decoder_handle_frame (GstVideoDecoder * decoder,
       pres = GST_H264_PARSER_OK;
 
     while (pres == GST_H264_PARSER_OK && decode_ret) {
-      decode_ret = gst_h264_decoder_decode_nal (self,
-          &nalu, GST_BUFFER_PTS (in_buf));
+      decode_ret = gst_h264_decoder_decode_nal (self, &nalu);
 
       pres = gst_h264_parser_identify_nalu (priv->parser,
           map.data, nalu.offset + nalu.size, map.size, &nalu);
@@ -553,54 +737,197 @@ gst_h264_decoder_preprocess_slice (GstH264Decoder * self, GstH264Slice * slice)
           slice->header.first_mb_in_slice);
       return FALSE;
     }
-
-    /* If the new picture is an IDR, flush DPB */
-    if (slice->nalu.idr_pic_flag) {
-      /* Output all remaining pictures, unless we are explicitly instructed
-       * not to do so */
-      if (!slice->header.dec_ref_pic_marking.no_output_of_prior_pics_flag)
-        gst_h264_decoder_drain (GST_VIDEO_DECODER (self));
-
-      gst_h264_dpb_clear (priv->dpb);
-    }
   }
 
   return TRUE;
 }
 
 static void
-gst_h264_decoder_update_pic_nums (GstH264Decoder * self, gint frame_num)
+gst_h264_decoder_update_pic_nums (GstH264Decoder * self,
+    GstH264Picture * current_picture, gint frame_num)
 {
   GstH264DecoderPrivate *priv = self->priv;
   GArray *dpb = gst_h264_dpb_get_pictures_all (priv->dpb);
   gint i;
 
+  g_return_val_if_fail (dpb != NULL, NULL);
+
   for (i = 0; i < dpb->len; i++) {
     GstH264Picture *picture = g_array_index (dpb, GstH264Picture *, i);
 
-    if (picture->field != GST_H264_PICTURE_FIELD_FRAME) {
-      GST_FIXME_OBJECT (self, "Interlaced video not supported");
-      continue;
-    }
-
-    if (!picture->ref)
+    if (!GST_H264_PICTURE_IS_REF (picture))
       continue;
 
-    if (picture->long_term) {
-      picture->long_term_pic_num = picture->long_term_frame_idx;
+    if (GST_H264_PICTURE_IS_LONG_TERM_REF (picture)) {
+      if (GST_H264_PICTURE_IS_FRAME (current_picture))
+        picture->long_term_pic_num = picture->long_term_frame_idx;
+      else if (current_picture->field == picture->field)
+        picture->long_term_pic_num = 2 * picture->long_term_frame_idx + 1;
+      else
+        picture->long_term_pic_num = 2 * picture->long_term_frame_idx;
     } else {
       if (picture->frame_num > frame_num)
         picture->frame_num_wrap = picture->frame_num - priv->max_frame_num;
       else
         picture->frame_num_wrap = picture->frame_num;
 
-      picture->pic_num = picture->frame_num_wrap;
+      if (GST_H264_PICTURE_IS_FRAME (current_picture))
+        picture->pic_num = picture->frame_num_wrap;
+      else if (picture->field == current_picture->field)
+        picture->pic_num = 2 * picture->frame_num_wrap + 1;
+      else
+        picture->pic_num = 2 * picture->frame_num_wrap;
     }
   }
 
   g_array_unref (dpb);
 }
 
+static GstH264Picture *
+gst_h264_decoder_split_frame (GstH264Decoder * self, GstH264Picture * picture)
+{
+  GstH264Picture *other_field;
+
+  g_assert (GST_H264_PICTURE_IS_FRAME (picture));
+
+  other_field = gst_h264_decoder_new_field_picture (self, picture);
+  if (!other_field) {
+    GST_WARNING_OBJECT (self,
+        "Couldn't split frame into complementary field pair");
+    return NULL;
+  }
+
+  GST_LOG_OBJECT (self, "Split picture %p, poc %d, frame num %d",
+      picture, picture->pic_order_cnt, picture->frame_num);
+
+  /* FIXME: enhance TFF decision by using picture timing SEI */
+  if (picture->top_field_order_cnt < picture->bottom_field_order_cnt) {
+    picture->field = GST_H264_PICTURE_FIELD_TOP_FIELD;
+    picture->pic_order_cnt = picture->top_field_order_cnt;
+
+    other_field->field = GST_H264_PICTURE_FIELD_BOTTOM_FIELD;
+    other_field->pic_order_cnt = picture->bottom_field_order_cnt;
+  } else {
+    picture->field = GST_H264_PICTURE_FIELD_BOTTOM_FIELD;
+    picture->pic_order_cnt = picture->bottom_field_order_cnt;
+
+    other_field->field = GST_H264_PICTURE_FIELD_TOP_FIELD;
+    other_field->pic_order_cnt = picture->top_field_order_cnt;
+  }
+
+  other_field->top_field_order_cnt = picture->top_field_order_cnt;
+  other_field->bottom_field_order_cnt = picture->bottom_field_order_cnt;
+  other_field->frame_num = picture->frame_num;
+  other_field->ref = picture->ref;
+  other_field->nonexisting = picture->nonexisting;
+  other_field->system_frame_number = picture->system_frame_number;
+
+  return other_field;
+}
+
+static gboolean
+output_picture_directly (GstH264Decoder * self, GstH264Picture * picture)
+{
+  GstH264DecoderPrivate *priv = self->priv;
+  GstH264Picture *out_pic = NULL;
+  gboolean ret = TRUE;
+
+  if (GST_H264_PICTURE_IS_FRAME (picture)) {
+    g_assert (priv->last_field == NULL);
+    out_pic = g_steal_pointer (&picture);
+    ret = TRUE;
+    goto output;
+  }
+
+  if (priv->last_field == NULL) {
+    if (picture->second_field) {
+      GST_WARNING ("Set the last output %p poc:%d, without first field",
+          picture, picture->pic_order_cnt);
+
+      ret = FALSE;
+      goto output;
+    }
+
+    /* Just cache the first field. */
+    priv->last_field = g_steal_pointer (&picture);
+    ret = TRUE;
+  } else {
+    if (!picture->second_field || !picture->other_field
+        || picture->other_field != priv->last_field) {
+      GST_WARNING ("The last field %p poc:%d is not the pair of the "
+          "current field %p poc:%d",
+          priv->last_field, priv->last_field->pic_order_cnt,
+          picture, picture->pic_order_cnt);
+
+      gst_h264_picture_clear (&priv->last_field);
+      ret = FALSE;
+      goto output;
+    }
+
+    GST_TRACE ("Pair the last field %p poc:%d and the current"
+        " field %p poc:%d",
+        priv->last_field, priv->last_field->pic_order_cnt,
+        picture, picture->pic_order_cnt);
+
+    out_pic = priv->last_field;
+    priv->last_field = NULL;
+    /* Link each field. */
+    out_pic->other_field = picture;
+  }
+
+output:
+  if (out_pic) {
+    gst_h264_dpb_set_last_output (priv->dpb, out_pic);
+    gst_h264_decoder_do_output_picture (self, out_pic);
+  }
+
+  gst_h264_picture_clear (&picture);
+
+  return ret;
+}
+
+static void
+add_picture_to_dpb (GstH264Decoder * self, GstH264Picture * picture)
+{
+  GstH264DecoderPrivate *priv = self->priv;
+
+  if (!gst_h264_dpb_get_interlaced (priv->dpb)) {
+    g_assert (priv->last_field == NULL);
+    gst_h264_dpb_add (priv->dpb, picture);
+    return;
+  }
+
+  /* The first field of the last picture may not be able to enter the
+     DPB if it is a non ref, but if the second field enters the DPB, we
+     need to add both of them. */
+  if (priv->last_field && picture->other_field == priv->last_field) {
+    gst_h264_dpb_add (priv->dpb, priv->last_field);
+    priv->last_field = NULL;
+  }
+
+  gst_h264_dpb_add (priv->dpb, picture);
+}
+
+static void
+_bump_dpb (GstH264Decoder * self, GstH264DpbBumpMode bump_level,
+    GstH264Picture * current_picture)
+{
+  GstH264DecoderPrivate *priv = self->priv;
+
+  while (gst_h264_dpb_needs_bump (priv->dpb, current_picture, bump_level)) {
+    GstH264Picture *to_output;
+
+    to_output = gst_h264_dpb_bump (priv->dpb, FALSE);
+
+    if (!to_output) {
+      GST_WARNING_OBJECT (self, "Bumping is needed but no picture to output");
+      break;
+    }
+
+    gst_h264_decoder_do_output_picture (self, to_output);
+  }
+}
+
 static gboolean
 gst_h264_decoder_handle_frame_num_gap (GstH264Decoder * self, gint frame_num)
 {
@@ -613,14 +940,35 @@ gst_h264_decoder_handle_frame_num_gap (GstH264Decoder * self, gint frame_num)
     return FALSE;
   }
 
+  if (priv->prev_ref_frame_num == frame_num) {
+    GST_TRACE_OBJECT (self,
+        "frame_num == PrevRefFrameNum (%d), not a gap", frame_num);
+    return TRUE;
+  }
+
+  if (((priv->prev_ref_frame_num + 1) % priv->max_frame_num) == frame_num) {
+    GST_TRACE_OBJECT (self,
+        "frame_num ==  (PrevRefFrameNum + 1) %% MaxFrameNum (%d), not a gap",
+        frame_num);
+    return TRUE;
+  }
+
+  if (gst_h264_dpb_get_size (priv->dpb) == 0) {
+    GST_TRACE_OBJECT (self, "DPB is empty, not a gap");
+    return TRUE;
+  }
+
   if (!sps->gaps_in_frame_num_value_allowed_flag) {
     /* This is likely the case where some frames were dropped.
      * then we need to keep decoding without error out */
-    GST_WARNING_OBJECT (self, "Invalid frame num %d", frame_num);
+    GST_WARNING_OBJECT (self, "Invalid frame num %d, maybe frame drop",
+        frame_num);
+
+    return TRUE;
   }
 
-  GST_DEBUG_OBJECT (self, "Handling frame num gap %d -> %d",
-      priv->prev_ref_frame_num, frame_num);
+  GST_DEBUG_OBJECT (self, "Handling frame num gap %d -> %d (MaxFrameNum: %d)",
+      priv->prev_ref_frame_num, frame_num, priv->max_frame_num);
 
   /* 7.4.3/7-23 */
   unused_short_term_frame_num =
@@ -632,13 +980,31 @@ gst_h264_decoder_handle_frame_num_gap (GstH264Decoder * self, gint frame_num)
             unused_short_term_frame_num))
       return FALSE;
 
-    gst_h264_decoder_update_pic_nums (self, unused_short_term_frame_num);
+    gst_h264_decoder_update_pic_nums (self, picture,
+        unused_short_term_frame_num);
 
-    if (!gst_h264_decoder_finish_picture (self, picture)) {
-      GST_WARNING ("Failed to finish picture %p", picture);
+    /* C.2.1 */
+    if (!gst_h264_decoder_sliding_window_picture_marking (self, picture)) {
+      GST_ERROR_OBJECT (self,
+          "Couldn't perform sliding window picture marking");
       return FALSE;
     }
 
+    gst_h264_dpb_delete_unused (priv->dpb);
+
+    _bump_dpb (self, GST_H264_DPB_BUMP_NORMAL_LATENCY, picture);
+
+    /* the picture is short term ref, add to DPB. */
+    if (gst_h264_dpb_get_interlaced (priv->dpb)) {
+      GstH264Picture *other_field =
+          gst_h264_decoder_split_frame (self, picture);
+
+      add_picture_to_dpb (self, picture);
+      add_picture_to_dpb (self, other_field);
+    } else {
+      add_picture_to_dpb (self, picture);
+    }
+
     unused_short_term_frame_num++;
     unused_short_term_frame_num %= priv->max_frame_num;
   }
@@ -662,8 +1028,8 @@ gst_h264_decoder_init_current_picture (GstH264Decoder * self)
   /* If the slice header indicates we will have to perform reference marking
    * process after this picture is decoded, store required data for that
    * purpose */
-  if (priv->current_slice.header.
-      dec_ref_pic_marking.adaptive_ref_pic_marking_mode_flag) {
+  if (priv->current_slice.header.dec_ref_pic_marking.
+      adaptive_ref_pic_marking_mode_flag) {
     priv->current_picture->dec_ref_pic_marking =
         priv->current_slice.header.dec_ref_pic_marking;
   }
@@ -679,6 +1045,7 @@ gst_h264_decoder_start_current_picture (GstH264Decoder * self)
   const GstH264SPS *sps;
   gint frame_num;
   gboolean ret = TRUE;
+  GstH264Picture *current_picture;
 
   g_assert (priv->current_picture != NULL);
   g_assert (priv->active_sps != NULL);
@@ -691,21 +1058,35 @@ gst_h264_decoder_start_current_picture (GstH264Decoder * self)
   if (priv->current_slice.nalu.idr_pic_flag)
     priv->prev_ref_frame_num = 0;
 
-  /* 7.4.3 */
-  if (frame_num != priv->prev_ref_frame_num &&
-      frame_num != (priv->prev_ref_frame_num + 1) % priv->max_frame_num &&
-      gst_h264_dpb_get_size (priv->dpb) > 0) {
-    if (!gst_h264_decoder_handle_frame_num_gap (self, frame_num))
-      return FALSE;
-  }
+  if (!gst_h264_decoder_handle_frame_num_gap (self, frame_num))
+    return FALSE;
 
   if (!gst_h264_decoder_init_current_picture (self))
     return FALSE;
 
-  gst_h264_decoder_update_pic_nums (self, frame_num);
+  current_picture = priv->current_picture;
+
+  /* If the new picture is an IDR, flush DPB */
+  if (current_picture->idr) {
+    if (!current_picture->dec_ref_pic_marking.no_output_of_prior_pics_flag) {
+      gst_h264_decoder_drain_internal (self);
+    } else {
+      /* C.4.4 Removal of pictures from the DPB before possible insertion
+       * of the current picture
+       *
+       * If decoded picture is IDR and no_output_of_prior_pics_flag is equal to 1
+       * or is inferred to be equal to 1, all frame buffers in the DPB
+       * are emptied without output of the pictures they contain,
+       * and DPB fullness is set to 0.
+       */
+      gst_h264_decoder_clear_dpb (self, FALSE);
+    }
+  }
+
+  gst_h264_decoder_update_pic_nums (self, current_picture, frame_num);
 
   if (priv->process_ref_pic_lists)
-    gst_h264_decoder_prepare_ref_pic_lists (self);
+    gst_h264_decoder_prepare_ref_pic_lists (self, current_picture);
 
   klass = GST_H264_DECODER_GET_CLASS (self);
   if (klass->start_picture)
@@ -720,9 +1101,118 @@ gst_h264_decoder_start_current_picture (GstH264Decoder * self)
   return TRUE;
 }
 
+static GstH264Picture *
+gst_h264_decoder_new_field_picture (GstH264Decoder * self,
+    GstH264Picture * picture)
+{
+  GstH264DecoderClass *klass = GST_H264_DECODER_GET_CLASS (self);
+  GstH264Picture *new_picture;
+
+  if (!klass->new_field_picture) {
+    GST_WARNING_OBJECT (self, "Subclass does not support interlaced stream");
+    return NULL;
+  }
+
+  new_picture = gst_h264_picture_new ();
+  /* don't confuse subclass by non-existing picture */
+  if (!picture->nonexisting &&
+      !klass->new_field_picture (self, picture, new_picture)) {
+    GST_ERROR_OBJECT (self, "Subclass couldn't handle new field picture");
+    gst_h264_picture_unref (new_picture);
+
+    return NULL;
+  }
+
+  new_picture->other_field = picture;
+  new_picture->second_field = TRUE;
+
+  return new_picture;
+}
+
+static gboolean
+gst_h264_decoder_find_first_field_picture (GstH264Decoder * self,
+    GstH264Slice * slice, GstH264Picture ** first_field)
+{
+  GstH264DecoderPrivate *priv = self->priv;
+  const GstH264SliceHdr *slice_hdr = &slice->header;
+  GstH264Picture *prev_field;
+  gboolean in_dpb;
+
+  *first_field = NULL;
+  prev_field = NULL;
+  in_dpb = FALSE;
+  if (gst_h264_dpb_get_interlaced (priv->dpb)) {
+    if (priv->last_field) {
+      prev_field = priv->last_field;
+      in_dpb = FALSE;
+    } else if (gst_h264_dpb_get_size (priv->dpb) > 0) {
+      GstH264Picture *prev_picture;
+      GArray *pictures;
+
+      pictures = gst_h264_dpb_get_pictures_all (priv->dpb);
+
+      g_return_val_if_fail (pictures != NULL, NULL);
+
+      prev_picture =
+          g_array_index (pictures, GstH264Picture *, pictures->len - 1);
+      g_array_unref (pictures); /* prev_picture should be held */
+
+      /* Previous picture was a field picture. */
+      if (!GST_H264_PICTURE_IS_FRAME (prev_picture)
+          && !prev_picture->other_field) {
+        prev_field = prev_picture;
+        in_dpb = TRUE;
+      }
+    }
+  } else {
+    g_assert (priv->last_field == NULL);
+  }
+
+  /* This is not a field picture */
+  if (!slice_hdr->field_pic_flag) {
+    if (!prev_field)
+      return TRUE;
+
+    GST_WARNING_OBJECT (self, "Previous picture %p (poc %d) is not complete",
+        prev_field, prev_field->pic_order_cnt);
+    goto error;
+  }
+
+  /* OK, this is the first field. */
+  if (!prev_field)
+    return TRUE;
+
+  if (prev_field->frame_num != slice_hdr->frame_num) {
+    GST_WARNING_OBJECT (self, "Previous picture %p (poc %d) is not complete",
+        prev_field, prev_field->pic_order_cnt);
+    goto error;
+  } else {
+    GstH264PictureField current_field = slice_hdr->bottom_field_flag ?
+        GST_H264_PICTURE_FIELD_BOTTOM_FIELD : GST_H264_PICTURE_FIELD_TOP_FIELD;
+
+    if (current_field == prev_field->field) {
+      GST_WARNING_OBJECT (self,
+          "Currnet picture and previous picture have identical field %d",
+          current_field);
+      goto error;
+    }
+  }
+
+  *first_field = gst_h264_picture_ref (prev_field);
+  return TRUE;
+
+error:
+  if (!in_dpb) {
+    gst_h264_picture_clear (&priv->last_field);
+  } else {
+    /* FIXME: implement fill gap field picture if it is already in DPB */
+  }
+
+  return FALSE;
+}
+
 static gboolean
-gst_h264_decoder_parse_slice (GstH264Decoder * self, GstH264NalUnit * nalu,
-    GstClockTime pts)
+gst_h264_decoder_parse_slice (GstH264Decoder * self, GstH264NalUnit * nalu)
 {
   GstH264DecoderPrivate *priv = self->priv;
   GstH264ParserResult pres = GST_H264_PARSER_OK;
@@ -747,29 +1237,68 @@ gst_h264_decoder_parse_slice (GstH264Decoder * self, GstH264NalUnit * nalu,
   priv->active_pps = priv->current_slice.header.pps;
   priv->active_sps = priv->active_pps->sequence;
 
+  /* Check whether field picture boundary within given codec frame.
+   * This might happen in case that upstream sent buffer per frame unit,
+   * not picture unit (i.e., AU unit).
+   * If AU boundary is detected, then finish first field picture we decoded
+   * in this chain, we should finish the current picture and
+   * start new field picture decoding */
+  if (gst_h264_dpb_get_interlaced (priv->dpb) && priv->current_picture &&
+      !GST_H264_PICTURE_IS_FRAME (priv->current_picture) &&
+      !priv->current_picture->second_field) {
+    GstH264PictureField prev_field = priv->current_picture->field;
+    GstH264PictureField cur_field = GST_H264_PICTURE_FIELD_FRAME;
+    if (priv->current_slice.header.field_pic_flag)
+      cur_field = priv->current_slice.header.bottom_field_flag ?
+          GST_H264_PICTURE_FIELD_BOTTOM_FIELD :
+          GST_H264_PICTURE_FIELD_TOP_FIELD;
+
+    if (cur_field != prev_field) {
+      GST_LOG_OBJECT (self,
+          "Found new field picture, finishing the first field picture");
+      gst_h264_decoder_finish_current_picture (self);
+    }
+  }
+
   if (!priv->current_picture) {
     GstH264DecoderClass *klass = GST_H264_DECODER_GET_CLASS (self);
-    GstH264Picture *picture;
+    GstH264Picture *picture = NULL;
+    GstH264Picture *first_field = NULL;
     gboolean ret = TRUE;
 
-    picture = gst_h264_picture_new ();
-    picture->pts = pts;
-    /* This allows accessing the frame from the picture. */
-    picture->system_frame_number = priv->current_frame->system_frame_number;
-
-    priv->current_picture = picture;
     g_assert (priv->current_frame);
 
-    if (klass->new_picture)
-      ret = klass->new_picture (self, priv->current_frame, picture);
-
-    if (!ret) {
-      GST_ERROR_OBJECT (self, "subclass does not want accept new picture");
-      priv->current_picture = NULL;
-      gst_h264_picture_unref (picture);
+    if (!gst_h264_decoder_find_first_field_picture (self,
+            &priv->current_slice, &first_field)) {
+      GST_ERROR_OBJECT (self, "Couldn't find or determine first picture");
       return FALSE;
     }
 
+    if (first_field) {
+      picture = gst_h264_decoder_new_field_picture (self, first_field);
+      gst_h264_picture_unref (first_field);
+
+      if (!picture) {
+        GST_ERROR_OBJECT (self, "Couldn't duplicate the first field picture");
+        return FALSE;
+      }
+    } else {
+      picture = gst_h264_picture_new ();
+
+      if (klass->new_picture)
+        ret = klass->new_picture (self, priv->current_frame, picture);
+
+      if (!ret) {
+        GST_ERROR_OBJECT (self, "subclass does not want accept new picture");
+        gst_h264_picture_unref (picture);
+        return FALSE;
+      }
+    }
+
+    /* This allows accessing the frame from the picture. */
+    picture->system_frame_number = priv->current_frame->system_frame_number;
+    priv->current_picture = picture;
+
     if (!gst_h264_decoder_start_current_picture (self)) {
       GST_ERROR_OBJECT (self, "start picture failed");
       return FALSE;
@@ -780,8 +1309,7 @@ gst_h264_decoder_parse_slice (GstH264Decoder * self, GstH264NalUnit * nalu,
 }
 
 static gboolean
-gst_h264_decoder_decode_nal (GstH264Decoder * self, GstH264NalUnit * nalu,
-    GstClockTime pts)
+gst_h264_decoder_decode_nal (GstH264Decoder * self, GstH264NalUnit * nalu)
 {
   gboolean ret = TRUE;
 
@@ -801,7 +1329,7 @@ gst_h264_decoder_decode_nal (GstH264Decoder * self, GstH264NalUnit * nalu,
     case GST_H264_NAL_SLICE_DPC:
     case GST_H264_NAL_SLICE_IDR:
     case GST_H264_NAL_SLICE_EXT:
-      ret = gst_h264_decoder_parse_slice (self, nalu, pts);
+      ret = gst_h264_decoder_parse_slice (self, nalu);
       break;
     default:
       break;
@@ -951,6 +1479,7 @@ static gboolean
 gst_h264_decoder_fill_picture_from_slice (GstH264Decoder * self,
     const GstH264Slice * slice, GstH264Picture * picture)
 {
+  GstH264DecoderClass *klass = GST_H264_DECODER_GET_CLASS (self);
   const GstH264SliceHdr *slice_hdr = &slice->header;
   const GstH264PPS *pps;
   const GstH264SPS *sps;
@@ -979,16 +1508,23 @@ gst_h264_decoder_fill_picture_from_slice (GstH264Decoder * self,
   else
     picture->field = GST_H264_PICTURE_FIELD_FRAME;
 
-  if (picture->field != GST_H264_PICTURE_FIELD_FRAME) {
-    GST_FIXME ("Interlace video not supported");
+  if (!GST_H264_PICTURE_IS_FRAME (picture) && !klass->new_field_picture) {
+    GST_FIXME_OBJECT (self, "Subclass doesn't support interlace stream");
     return FALSE;
   }
 
   picture->nal_ref_idc = slice->nalu.ref_idc;
-  picture->ref = slice->nalu.ref_idc != 0;
+  if (slice->nalu.ref_idc != 0)
+    gst_h264_picture_set_reference (picture,
+        GST_H264_PICTURE_REF_SHORT_TERM, FALSE);
+
+  picture->frame_num = slice_hdr->frame_num;
 
-  /* This assumes non-interlaced stream */
-  picture->frame_num = picture->pic_num = slice_hdr->frame_num;
+  /* 7.4.3 */
+  if (!slice_hdr->field_pic_flag)
+    picture->pic_num = slice_hdr->frame_num;
+  else
+    picture->pic_num = 2 * slice_hdr->frame_num + 1;
 
   picture->pic_order_cnt_type = sps->pic_order_cnt_type;
   switch (picture->pic_order_cnt_type) {
@@ -1066,15 +1602,21 @@ gst_h264_decoder_calculate_poc (GstH264Decoder * self, GstH264Picture * picture)
             picture->pic_order_cnt_msb + picture->pic_order_cnt_lsb;
       }
 
-      if (picture->field != GST_H264_PICTURE_FIELD_TOP_FIELD) {
-        if (picture->field == GST_H264_PICTURE_FIELD_FRAME) {
-          picture->bottom_field_order_cnt =
-              picture->top_field_order_cnt +
+      switch (picture->field) {
+        case GST_H264_PICTURE_FIELD_FRAME:
+          picture->top_field_order_cnt = picture->pic_order_cnt_msb +
+              picture->pic_order_cnt_lsb;
+          picture->bottom_field_order_cnt = picture->top_field_order_cnt +
               picture->delta_pic_order_cnt_bottom;
-        } else {
-          picture->bottom_field_order_cnt =
-              picture->pic_order_cnt_msb + picture->pic_order_cnt_lsb;
-        }
+          break;
+        case GST_H264_PICTURE_FIELD_TOP_FIELD:
+          picture->top_field_order_cnt = picture->pic_order_cnt_msb +
+              picture->pic_order_cnt_lsb;
+          break;
+        case GST_H264_PICTURE_FIELD_BOTTOM_FIELD:
+          picture->bottom_field_order_cnt = picture->pic_order_cnt_msb +
+              picture->pic_order_cnt_lsb;
+          break;
       }
       break;
     }
@@ -1134,7 +1676,7 @@ gst_h264_decoder_calculate_poc (GstH264Decoder * self, GstH264Picture * picture)
       if (!picture->nal_ref_idc)
         expected_pic_order_cnt += sps->offset_for_non_ref_pic;
 
-      if (picture->field == GST_H264_PICTURE_FIELD_FRAME) {
+      if (GST_H264_PICTURE_IS_FRAME (picture)) {
         picture->top_field_order_cnt =
             expected_pic_order_cnt + picture->delta_pic_order_cnt0;
         picture->bottom_field_order_cnt = picture->top_field_order_cnt +
@@ -1174,7 +1716,7 @@ gst_h264_decoder_calculate_poc (GstH264Decoder * self, GstH264Picture * picture)
             2 * (picture->frame_num_offset + picture->frame_num);
       }
 
-      if (picture->field == GST_H264_PICTURE_FIELD_FRAME) {
+      if (GST_H264_PICTURE_IS_FRAME (picture)) {
         picture->top_field_order_cnt = temp_pic_order_cnt;
         picture->bottom_field_order_cnt = temp_pic_order_cnt;
       } else if (picture->field == GST_H264_PICTURE_FIELD_BOTTOM_FIELD) {
@@ -1211,24 +1753,29 @@ gst_h264_decoder_calculate_poc (GstH264Decoder * self, GstH264Picture * picture)
 }
 
 static void
-gst_h264_decoder_do_output_picture (GstH264Decoder * self,
-    GstH264Picture * picture, gboolean clear_dpb)
+gst_h264_decoder_drain_output_queue (GstH264Decoder * self, guint num)
 {
   GstH264DecoderPrivate *priv = self->priv;
-  GstH264DecoderClass *klass;
-  GstVideoCodecFrame *frame = NULL;
-
-  picture->outputted = TRUE;
+  GstH264DecoderClass *klass = GST_H264_DECODER_GET_CLASS (self);
 
-  if (clear_dpb && !picture->ref)
-    gst_h264_dpb_delete_by_poc (priv->dpb, picture->pic_order_cnt);
+  g_assert (klass->output_picture);
 
-  if (picture->nonexisting) {
-    GST_DEBUG_OBJECT (self, "Skipping output, non-existing frame_num %d",
-        picture->frame_num);
-    gst_h264_picture_unref (picture);
-    return;
+  while (gst_queue_array_get_length (priv->output_queue) > num) {
+    GstH264DecoderOutputFrame *output_frame = (GstH264DecoderOutputFrame *)
+        gst_queue_array_pop_head_struct (priv->output_queue);
+    priv->last_ret =
+        klass->output_picture (self, output_frame->frame,
+        output_frame->picture);
   }
+}
+
+static void
+gst_h264_decoder_do_output_picture (GstH264Decoder * self,
+    GstH264Picture * picture)
+{
+  GstH264DecoderPrivate *priv = self->priv;
+  GstVideoCodecFrame *frame = NULL;
+  GstH264DecoderOutputFrame output_frame;
 
   GST_LOG_OBJECT (self, "Outputting picture %p (frame_num %d, poc %d)",
       picture, picture->frame_num, picture->pic_order_cnt);
@@ -1254,10 +1801,12 @@ gst_h264_decoder_do_output_picture (GstH264Decoder * self,
     return;
   }
 
-  klass = GST_H264_DECODER_GET_CLASS (self);
+  output_frame.frame = frame;
+  output_frame.picture = picture;
+  output_frame.self = self;
+  gst_queue_array_push_tail_struct (priv->output_queue, &output_frame);
 
-  g_assert (klass->output_picture);
-  priv->last_ret = klass->output_picture (self, frame, picture);
+  gst_h264_decoder_drain_output_queue (self, priv->preferred_output_delay);
 }
 
 static gboolean
@@ -1318,31 +1867,18 @@ static gboolean
 gst_h264_decoder_drain_internal (GstH264Decoder * self)
 {
   GstH264DecoderPrivate *priv = self->priv;
-  GArray *to_output = priv->to_output;
+  GstH264Picture *picture;
 
-  /* We are around to drain, so we can get rist of everything that has been
-   * outputed already */
-  gst_h264_dpb_delete_outputed (priv->dpb);
-  gst_h264_dpb_get_pictures_not_outputted (priv->dpb, to_output);
-  g_array_sort (to_output, (GCompareFunc) poc_asc_compare);
-
-  while (to_output->len) {
-    GstH264Picture *picture = g_array_index (to_output, GstH264Picture *, 0);
-
-    /* We want the last reference when outputing so take a ref and then remove
-     * from both arrays. */
-    gst_h264_picture_ref (picture);
-    g_array_remove_index (to_output, 0);
-    gst_h264_dpb_delete_by_poc (priv->dpb, picture->pic_order_cnt);
-
-    GST_LOG_OBJECT (self, "Output picture %p (frame num %d, poc %d)", picture,
-        picture->frame_num, picture->pic_order_cnt);
-    gst_h264_decoder_do_output_picture (self, picture, FALSE);
+  while ((picture = gst_h264_dpb_bump (priv->dpb, TRUE)) != NULL) {
+    gst_h264_decoder_do_output_picture (self, picture);
   }
 
-  g_array_set_size (to_output, 0);
+  gst_h264_decoder_drain_output_queue (self, 0);
+
+  gst_h264_picture_clear (&priv->last_field);
   gst_h264_dpb_clear (priv->dpb);
-  priv->last_output_poc = 0;
+  priv->last_output_poc = G_MININT32;
+
   return TRUE;
 }
 
@@ -1351,151 +1887,87 @@ gst_h264_decoder_handle_memory_management_opt (GstH264Decoder * self,
     GstH264Picture * picture)
 {
   GstH264DecoderPrivate *priv = self->priv;
-  gint i, j;
+  gint i;
 
   for (i = 0; i < G_N_ELEMENTS (picture->dec_ref_pic_marking.ref_pic_marking);
       i++) {
     GstH264RefPicMarking *ref_pic_marking =
         &picture->dec_ref_pic_marking.ref_pic_marking[i];
-    GstH264Picture *to_mark;
-    gint pic_num_x;
-
-    switch (ref_pic_marking->memory_management_control_operation) {
-      case 0:
-        /* Normal end of operations' specification */
-        return TRUE;
-      case 1:
-        /* Mark a short term reference picture as unused so it can be removed
-         * if outputted */
-        pic_num_x =
-            picture->pic_num - (ref_pic_marking->difference_of_pic_nums_minus1 +
-            1);
-        to_mark = gst_h264_dpb_get_short_ref_by_pic_num (priv->dpb, pic_num_x);
-        if (to_mark) {
-          to_mark->ref = FALSE;
-        } else {
-          GST_WARNING_OBJECT (self, "Invalid short term ref pic num to unmark");
-          return FALSE;
-        }
-        break;
-
-      case 2:
-        /* Mark a long term reference picture as unused so it can be removed
-         * if outputted */
-        to_mark = gst_h264_dpb_get_long_ref_by_pic_num (priv->dpb,
-            ref_pic_marking->long_term_pic_num);
-        if (to_mark) {
-          to_mark->ref = FALSE;
-        } else {
-          GST_WARNING_OBJECT (self, "Invalid long term ref pic num to unmark");
-          return FALSE;
-        }
-        break;
+    guint8 type = ref_pic_marking->memory_management_control_operation;
 
-      case 3:
-        /* Mark a short term reference picture as long term reference */
-        pic_num_x =
-            picture->pic_num - (ref_pic_marking->difference_of_pic_nums_minus1 +
-            1);
-        to_mark = gst_h264_dpb_get_short_ref_by_pic_num (priv->dpb, pic_num_x);
-        if (to_mark) {
-          to_mark->long_term = TRUE;
-          to_mark->long_term_frame_idx = ref_pic_marking->long_term_frame_idx;
-        } else {
-          GST_WARNING_OBJECT (self,
-              "Invalid short term ref pic num to mark as long ref");
-          return FALSE;
-        }
-        break;
+    GST_TRACE_OBJECT (self, "memory management operation %d, type %d", i, type);
 
-      case 4:{
-        GArray *pictures = gst_h264_dpb_get_pictures_all (priv->dpb);
+    /* Normal end of operations' specification */
+    if (type == 0)
+      return TRUE;
 
-        /* Unmark all reference pictures with long_term_frame_idx over new max */
+    switch (type) {
+      case 4:
         priv->max_long_term_frame_idx =
             ref_pic_marking->max_long_term_frame_idx_plus1 - 1;
-
-        for (j = 0; j < pictures->len; j++) {
-          GstH264Picture *pic = g_array_index (pictures, GstH264Picture *, j);
-          if (pic->long_term &&
-              pic->long_term_frame_idx > priv->max_long_term_frame_idx)
-            pic->ref = FALSE;
-        }
-
-        g_array_unref (pictures);
         break;
-      }
-
       case 5:
-        /* Unmark all reference pictures */
-        gst_h264_dpb_mark_all_non_ref (priv->dpb);
         priv->max_long_term_frame_idx = -1;
-        picture->mem_mgmt_5 = TRUE;
-        break;
-
-      case 6:{
-        GArray *pictures = gst_h264_dpb_get_pictures_all (priv->dpb);
-
-        /* Replace long term reference pictures with current picture.
-         * First unmark if any existing with this long_term_frame_idx... */
-
-        for (j = 0; j < pictures->len; j++) {
-          GstH264Picture *pic = g_array_index (pictures, GstH264Picture *, j);
-
-          if (pic->long_term &&
-              pic->long_term_frame_idx == ref_pic_marking->long_term_frame_idx)
-            pic->ref = FALSE;
-        }
-
-        g_array_unref (pictures);
-
-        /* and mark the current one instead */
-        picture->ref = TRUE;
-        picture->long_term = TRUE;
-        picture->long_term_frame_idx = ref_pic_marking->long_term_frame_idx;
         break;
-      }
-
       default:
-        g_assert_not_reached ();
         break;
     }
+
+    if (!gst_h264_dpb_perform_memory_management_control_operation (priv->dpb,
+            ref_pic_marking, picture)) {
+      GST_WARNING_OBJECT (self, "memory management operation type %d failed",
+          type);
+      /* Most likely our implementation fault, but let's just perform
+       * next MMCO if any */
+    }
   }
 
   return TRUE;
 }
 
 static gboolean
-gst_h264_decoder_sliding_window_picture_marking (GstH264Decoder * self)
+gst_h264_decoder_sliding_window_picture_marking (GstH264Decoder * self,
+    GstH264Picture * picture)
 {
   GstH264DecoderPrivate *priv = self->priv;
   const GstH264SPS *sps = priv->active_sps;
   gint num_ref_pics;
   gint max_num_ref_frames;
 
+  /* Skip this for the second field */
+  if (picture->second_field)
+    return TRUE;
+
   if (!sps) {
     GST_ERROR_OBJECT (self, "No active sps");
     return FALSE;
   }
 
   /* 8.2.5.3. Ensure the DPB doesn't overflow by discarding the oldest picture */
-  num_ref_pics = gst_h264_dpb_num_ref_pictures (priv->dpb);
+  num_ref_pics = gst_h264_dpb_num_ref_frames (priv->dpb);
   max_num_ref_frames = MAX (1, sps->num_ref_frames);
 
-  if (num_ref_pics > max_num_ref_frames) {
-    GST_WARNING_OBJECT (self,
-        "num_ref_pics %d is larger than allowed maximum %d",
-        num_ref_pics, max_num_ref_frames);
-    return FALSE;
-  }
+  if (num_ref_pics < max_num_ref_frames)
+    return TRUE;
 
-  if (num_ref_pics == max_num_ref_frames) {
+  /* In theory, num_ref_pics shouldn't be larger than max_num_ref_frames
+   * but it could happen if our implementation is wrong somehow or so.
+   * Just try to remove reference pictures as many as possible in order to
+   * avoid DPB overflow.
+   */
+  while (num_ref_pics >= max_num_ref_frames) {
     /* Max number of reference pics reached, need to remove one of the short
      * term ones. Find smallest frame_num_wrap short reference picture and mark
      * it as unused */
     GstH264Picture *to_unmark =
         gst_h264_dpb_get_lowest_frame_num_short_ref (priv->dpb);
 
+    if (num_ref_pics > max_num_ref_frames) {
+      GST_WARNING_OBJECT (self,
+          "num_ref_pics %d is larger than allowed maximum %d",
+          num_ref_pics, max_num_ref_frames);
+    }
+
     if (!to_unmark) {
       GST_WARNING_OBJECT (self, "Could not find a short ref picture to unmark");
       return FALSE;
@@ -1505,8 +1977,10 @@ gst_h264_decoder_sliding_window_picture_marking (GstH264Decoder * self)
         "Unmark reference flag of picture %p (frame_num %d, poc %d)",
         to_unmark, to_unmark->frame_num, to_unmark->pic_order_cnt);
 
-    to_unmark->ref = FALSE;
+    gst_h264_picture_set_reference (to_unmark, GST_H264_PICTURE_REF_NONE, TRUE);
     gst_h264_picture_unref (to_unmark);
+
+    num_ref_pics--;
   }
 
   return TRUE;
@@ -1528,11 +2002,13 @@ gst_h264_decoder_reference_picture_marking (GstH264Decoder * self,
     gst_h264_dpb_mark_all_non_ref (priv->dpb);
 
     if (picture->dec_ref_pic_marking.long_term_reference_flag) {
-      picture->long_term = TRUE;
+      gst_h264_picture_set_reference (picture,
+          GST_H264_PICTURE_REF_LONG_TERM, FALSE);
       picture->long_term_frame_idx = 0;
       priv->max_long_term_frame_idx = 0;
     } else {
-      picture->long_term = FALSE;
+      gst_h264_picture_set_reference (picture,
+          GST_H264_PICTURE_REF_SHORT_TERM, FALSE);
       priv->max_long_term_frame_idx = -1;
     }
 
@@ -1553,19 +2029,48 @@ gst_h264_decoder_reference_picture_marking (GstH264Decoder * self,
     return gst_h264_decoder_handle_memory_management_opt (self, picture);
   }
 
-  return gst_h264_decoder_sliding_window_picture_marking (self);
+  return gst_h264_decoder_sliding_window_picture_marking (self, picture);
+}
+
+static GstH264DpbBumpMode
+get_bump_level (GstH264Decoder * self)
+{
+  GstH264DecoderPrivate *priv = self->priv;
+
+  /* User set the mode explicitly. */
+  switch (priv->compliance) {
+    case GST_H264_DECODER_COMPLIANCE_STRICT:
+      return GST_H264_DPB_BUMP_NORMAL_LATENCY;
+    case GST_H264_DECODER_COMPLIANCE_NORMAL:
+      return GST_H264_DPB_BUMP_LOW_LATENCY;
+    case GST_H264_DECODER_COMPLIANCE_FLEXIBLE:
+      return GST_H264_DPB_BUMP_VERY_LOW_LATENCY;
+    default:
+      break;
+  }
+
+  /* GST_H264_DECODER_COMPLIANCE_AUTO case. */
+
+  if (priv->is_live) {
+    /* The baseline and constrained-baseline profiles do not have B frames
+       and do not use the picture reorder, safe to use the higher bump level. */
+    if (priv->profile_idc == GST_H264_PROFILE_BASELINE)
+      return GST_H264_DPB_BUMP_VERY_LOW_LATENCY;
+
+    return GST_H264_DPB_BUMP_LOW_LATENCY;
+  }
+
+  return GST_H264_DPB_BUMP_NORMAL_LATENCY;
 }
 
 static gboolean
 gst_h264_decoder_finish_picture (GstH264Decoder * self,
     GstH264Picture * picture)
 {
+  GstVideoDecoder *decoder = GST_VIDEO_DECODER (self);
   GstH264DecoderPrivate *priv = self->priv;
-  GArray *not_outputted = priv->to_output;
-  guint num_remaining;
-#ifndef GST_DISABLE_GST_DEBUG
-  gint i;
-#endif
+  gboolean ret = TRUE;
+  GstH264DpbBumpMode bump_level = get_bump_level (self);
 
   /* Finish processing the picture.
    * Start by storing previous picture data for later use */
@@ -1587,185 +2092,80 @@ gst_h264_decoder_finish_picture (GstH264Decoder * self,
    * them as such */
   gst_h264_dpb_delete_unused (priv->dpb);
 
-  GST_LOG_OBJECT (self,
-      "Finishing picture %p (frame_num %d, poc %d), entries in DPB %d",
-      picture, picture->frame_num, picture->pic_order_cnt,
-      gst_h264_dpb_get_size (priv->dpb));
-
-  /* The ownership of pic will either be transferred to DPB - if the picture is
-   * still needed (for output and/or reference) - or we will release it
-   * immediately if we manage to output it here and won't have to store it for
-   * future reference */
-
-  /* Get all pictures that haven't been outputted yet */
-  gst_h264_dpb_get_pictures_not_outputted (priv->dpb, not_outputted);
-  /* Include the one we've just decoded */
-  g_array_append_val (not_outputted, picture);
-
-  /* for debugging */
-#ifndef GST_DISABLE_GST_DEBUG
-  if (gst_debug_category_get_threshold (GST_CAT_DEFAULT) >= GST_LEVEL_TRACE) {
-    GST_TRACE_OBJECT (self, "Before sorting not outputted list");
-    for (i = 0; i < not_outputted->len; i++) {
-      GstH264Picture *tmp = g_array_index (not_outputted, GstH264Picture *, i);
-      GST_TRACE_OBJECT (self,
-          "\t%dth picture %p (frame_num %d, poc %d)", i, tmp,
-          tmp->frame_num, tmp->pic_order_cnt);
-    }
-  }
-#endif
-
-  /* Sort in output order */
-  g_array_sort (not_outputted, (GCompareFunc) poc_asc_compare);
-
-#ifndef GST_DISABLE_GST_DEBUG
-  if (gst_debug_category_get_threshold (GST_CAT_DEFAULT) >= GST_LEVEL_TRACE) {
-    GST_TRACE_OBJECT (self,
-        "After sorting not outputted list in poc ascending order");
-    for (i = 0; i < not_outputted->len; i++) {
-      GstH264Picture *tmp = g_array_index (not_outputted, GstH264Picture *, i);
-      GST_TRACE_OBJECT (self,
-          "\t%dth picture %p (frame_num %d, poc %d)", i, tmp,
-          tmp->frame_num, tmp->pic_order_cnt);
-    }
-  }
-#endif
-
-  /* Try to output as many pictures as we can. A picture can be output,
-   * if the number of decoded and not yet outputted pictures that would remain
-   * in DPB afterwards would at least be equal to max_num_reorder_frames.
-   * If the outputted picture is not a reference picture, it doesn't have
-   * to remain in the DPB and can be removed */
-  num_remaining = not_outputted->len;
-
-  while (num_remaining > priv->max_num_reorder_frames ||
-      /* If the condition below is used, this is an invalid stream. We should
-       * not be forced to output beyond max_num_reorder_frames in order to
-       * make room in DPB to store the current picture (if we need to do so).
-       * However, if this happens, ignore max_num_reorder_frames and try
-       * to output more. This may cause out-of-order output, but is not
-       * fatal, and better than failing instead */
-      ((gst_h264_dpb_is_full (priv->dpb) && (picture && (!picture->outputted
-                      || picture->ref)))
-          && num_remaining)) {
-    gboolean clear_dpb = TRUE;
-    GstH264Picture *to_output =
-        g_array_index (not_outputted, GstH264Picture *, 0);
-
-    gst_h264_picture_ref (to_output);
-    g_array_remove_index (not_outputted, 0);
-
-    if (num_remaining <= priv->max_num_reorder_frames) {
-      GST_WARNING_OBJECT (self,
-          "Invalid stream, max_num_reorder_frames not preserved");
-    }
-
-    GST_LOG_OBJECT (self,
-        "Output picture %p (frame num %d)", to_output, to_output->frame_num);
-
-    /* Current picture hasn't been inserted into DPB yet, so don't remove it
-     * if we managed to output it immediately */
-    if (picture && to_output == picture) {
-      clear_dpb = FALSE;
+  /* If field pictures belong to different codec frame,
+   * drop codec frame of the second field because we are consuming
+   * only the first codec frame via GstH264Decoder::output_picture() method */
+  if (picture->second_field && picture->other_field &&
+      picture->system_frame_number !=
+      picture->other_field->system_frame_number) {
+    GstVideoCodecFrame *frame = gst_video_decoder_get_frame (decoder,
+        picture->system_frame_number);
 
-      if (picture->ref) {
-        GST_TRACE_OBJECT (self,
-            "Put current picture %p (frame num %d, poc %d) to dpb",
-            picture, picture->frame_num, picture->pic_order_cnt);
-        gst_h264_dpb_add (priv->dpb, gst_h264_picture_ref (picture));
+    gst_video_decoder_release_frame (decoder, frame);
+  }
+
+  /* C.4.4 */
+  if (picture->mem_mgmt_5) {
+    GST_TRACE_OBJECT (self, "Memory management type 5, drain the DPB");
+    gst_h264_decoder_drain_internal (self);
+  }
+
+  _bump_dpb (self, bump_level, picture);
+
+  /* Add a ref to avoid the case of directly outputed and destroyed. */
+  gst_h264_picture_ref (picture);
+
+  /* C.4.5.1, C.4.5.2
+     - If the current decoded picture is the second field of a complementary
+     reference field pair, add to DPB.
+     C.4.5.1
+     For A reference decoded picture, the "bumping" process is invoked
+     repeatedly until there is an empty frame buffer, then add to DPB:
+     C.4.5.2
+     For a non-reference decoded picture, if there is empty frame buffer
+     after bumping the smaller POC, add to DPB.
+     Otherwise, output directly. */
+  if ((picture->second_field && picture->other_field
+          && picture->other_field->ref)
+      || picture->ref || gst_h264_dpb_has_empty_frame_buffer (priv->dpb)) {
+    /* Split frame into top/bottom field pictures for reference picture marking
+     * process. Even if current picture has field_pic_flag equal to zero,
+     * if next picture is a field picture, complementary field pair of reference
+     * frame should have individual pic_num and long_term_pic_num.
+     */
+    if (gst_h264_dpb_get_interlaced (priv->dpb) &&
+        GST_H264_PICTURE_IS_FRAME (picture)) {
+      GstH264Picture *other_field =
+          gst_h264_decoder_split_frame (self, picture);
+
+      add_picture_to_dpb (self, picture);
+      if (!other_field) {
+        GST_WARNING_OBJECT (self,
+            "Couldn't split frame into complementary field pair");
+        /* Keep decoding anyway... */
+      } else {
+        add_picture_to_dpb (self, other_field);
       }
-
-      /* and mark current picture is handled */
-      picture = NULL;
+    } else {
+      add_picture_to_dpb (self, picture);
     }
-
-    gst_h264_decoder_do_output_picture (self, to_output, clear_dpb);
-
-    num_remaining--;
+  } else {
+    ret = output_picture_directly (self, picture);
   }
 
-  /* If we haven't managed to output the picture that we just decoded, or if
-   * it's a reference picture, we have to store it in DPB */
-  if (picture && (!picture->outputted || picture->ref)) {
-    if (gst_h264_dpb_is_full (priv->dpb)) {
-      /* If we haven't managed to output anything to free up space in DPB
-       * to store this picture, it's an error in the stream */
-      GST_WARNING_OBJECT (self, "Could not free up space in DPB");
-
-      g_array_set_size (not_outputted, 0);
-      return FALSE;
-    }
-
-    GST_TRACE_OBJECT (self,
-        "Put picture %p (outputted %d, ref %d, frame num %d, poc %d) to dpb",
-        picture, picture->outputted, picture->ref, picture->frame_num,
-        picture->pic_order_cnt);
-    gst_h264_dpb_add (priv->dpb, gst_h264_picture_ref (picture));
-  }
-
-  /* clear possible reference to the current picture.
-   * If *picture* is still non-null, it means that the current picture not
-   * outputted yet, and DPB may or may not hold the reference of the picture */
-  if (picture)
-    gst_h264_picture_ref (picture);
-
-  g_array_set_size (not_outputted, 0);
-
-  /* C.4.5.3 "Bumping" process for non-DPB full case, DPB full cases should be
-   * covered above */
-  /* FIXME: should cover interlaced streams */
-  if (picture && !picture->outputted &&
-      picture->field == GST_H264_PICTURE_FIELD_FRAME) {
-    gboolean do_output = TRUE;
-    if (picture->idr &&
-        !picture->dec_ref_pic_marking.no_output_of_prior_pics_flag) {
-      /* The current picture is an IDR picture and no_output_of_prior_pics_flag
-       * is not equal to 1 and is not inferred to be equal to 1, as specified
-       * in clause C.4.4 */
-      GST_TRACE_OBJECT (self, "Output IDR picture");
-    } else if (picture->mem_mgmt_5) {
-      /* The current picture has memory_management_control_operation equal to 5,
-       * as specified in clause C.4.4 */
-      GST_TRACE_OBJECT (self, "Output mem_mgmt_5 picture");
-    } else if (priv->last_output_poc >= 0 &&
-        picture->pic_order_cnt > priv->last_output_poc &&
-        (picture->pic_order_cnt - priv->last_output_poc) <= 2 &&
-        /* NOTE: this might have a negative effect on throughput performance
-         * depending on hardware implementation.
-         * TODO: Possible solution is threading but it would make decoding flow
-         * very complicated. */
-        priv->is_live) {
-      /* NOTE: this condition is not specified by spec but we can output
-       * this picture based on calculated POC and last outputted POC */
-
-      /* NOTE: The assumption here is, every POC of frame will have step of two.
-       * however, if the assumption is wrong, (i.e., POC step is one, not two),
-       * this would break output order. If this assumption is wrong,
-       * please remove this condition.
-       */
-      GST_LOG_OBJECT (self,
-          "Forcing output picture %p (frame num %d, poc %d, last poc %d)",
-          picture, picture->frame_num, picture->pic_order_cnt,
-          priv->last_output_poc);
-    } else {
-      do_output = FALSE;
-      GST_TRACE_OBJECT (self, "Current picture %p (frame num %d, poc %d) "
-          "is not ready to be output picture",
-          picture, picture->frame_num, picture->pic_order_cnt);
-    }
+  GST_LOG_OBJECT (self,
+      "Finishing picture %p (frame_num %d, poc %d), entries in DPB %d",
+      picture, picture->frame_num, picture->pic_order_cnt,
+      gst_h264_dpb_get_size (priv->dpb));
 
-    if (do_output) {
-      /* pass ownership of the current picture. At this point,
-       * dpb must be holding a reference of the current picture */
-      gst_h264_decoder_do_output_picture (self, picture, TRUE);
-      picture = NULL;
-    }
-  }
+  gst_h264_picture_unref (picture);
 
-  if (picture)
-    gst_h264_picture_unref (picture);
+  /* For the live mode, we try to bump here to avoid waiting
+     for another decoding circle. */
+  if (priv->is_live && priv->compliance != GST_H264_DECODER_COMPLIANCE_STRICT)
+    _bump_dpb (self, bump_level, NULL);
 
-  return TRUE;
+  return ret;
 }
 
 static gboolean
@@ -1773,27 +2173,39 @@ gst_h264_decoder_update_max_num_reorder_frames (GstH264Decoder * self,
     GstH264SPS * sps)
 {
   GstH264DecoderPrivate *priv = self->priv;
+  gsize max_num_reorder_frames = 0;
 
   if (sps->vui_parameters_present_flag
       && sps->vui_parameters.bitstream_restriction_flag) {
-    priv->max_num_reorder_frames = sps->vui_parameters.num_reorder_frames;
-    if (priv->max_num_reorder_frames >
-        gst_h264_dpb_get_max_num_pics (priv->dpb)) {
+    max_num_reorder_frames = sps->vui_parameters.num_reorder_frames;
+    if (max_num_reorder_frames > gst_h264_dpb_get_max_num_frames (priv->dpb)) {
       GST_WARNING
           ("max_num_reorder_frames present, but larger than MaxDpbFrames (%d > %d)",
-          (gint) priv->max_num_reorder_frames,
-          gst_h264_dpb_get_max_num_pics (priv->dpb));
+          (gint) max_num_reorder_frames,
+          gst_h264_dpb_get_max_num_frames (priv->dpb));
 
-      priv->max_num_reorder_frames = 0;
+      max_num_reorder_frames = 0;
       return FALSE;
     }
 
+    gst_h264_dpb_set_max_num_reorder_frames (priv->dpb, max_num_reorder_frames);
+
     return TRUE;
   }
 
-  /* max_num_reorder_frames not present, infer from profile/constraints
-   * (see VUI semantics in spec) */
-  if (sps->constraint_set3_flag) {
+  if (priv->compliance == GST_H264_DECODER_COMPLIANCE_STRICT) {
+    gst_h264_dpb_set_max_num_reorder_frames (priv->dpb,
+        gst_h264_dpb_get_max_num_frames (priv->dpb));
+    return TRUE;
+  }
+
+  /* max_num_reorder_frames not present, infer it from profile/constraints. */
+  if (sps->profile_idc == 66 || sps->profile_idc == 83) {
+    /* baseline, constrained baseline and scalable-baseline profiles
+       only contain I/P frames. */
+    max_num_reorder_frames = 0;
+  } else if (sps->constraint_set3_flag) {
+    /* constraint_set3_flag may mean the -intra only profile. */
     switch (sps->profile_idc) {
       case 44:
       case 86:
@@ -1801,17 +2213,18 @@ gst_h264_decoder_update_max_num_reorder_frames (GstH264Decoder * self,
       case 110:
       case 122:
       case 244:
-        priv->max_num_reorder_frames = 0;
+        max_num_reorder_frames = 0;
         break;
       default:
-        priv->max_num_reorder_frames =
-            gst_h264_dpb_get_max_num_pics (priv->dpb);
+        max_num_reorder_frames = gst_h264_dpb_get_max_num_frames (priv->dpb);
         break;
     }
   } else {
-    priv->max_num_reorder_frames = gst_h264_dpb_get_max_num_pics (priv->dpb);
+    max_num_reorder_frames = gst_h264_dpb_get_max_num_frames (priv->dpb);
   }
 
+  gst_h264_dpb_set_max_num_reorder_frames (priv->dpb, max_num_reorder_frames);
+
   return TRUE;
 }
 
@@ -1884,9 +2297,61 @@ h264_level_to_max_dpb_mbs (GstH264DecoderLevel level)
   return 0;
 }
 
+static void
+gst_h264_decoder_set_latency (GstH264Decoder * self, const GstH264SPS * sps,
+    gint max_dpb_size)
+{
+  GstH264DecoderPrivate *priv = self->priv;
+  GstCaps *caps;
+  GstClockTime min, max;
+  GstStructure *structure;
+  gint fps_d = 1, fps_n = 0;
+  guint32 num_reorder_frames;
+
+  caps = gst_pad_get_current_caps (GST_VIDEO_DECODER_SRC_PAD (self));
+  if (!caps)
+    return;
+
+  structure = gst_caps_get_structure (caps, 0);
+  if (gst_structure_get_fraction (structure, "framerate", &fps_n, &fps_d)) {
+    if (fps_n == 0) {
+      /* variable framerate: see if we have a max-framerate */
+      gst_structure_get_fraction (structure, "max-framerate", &fps_n, &fps_d);
+    }
+  }
+  gst_caps_unref (caps);
+
+  /* if no fps or variable, then 25/1 */
+  if (fps_n == 0) {
+    fps_n = 25;
+    fps_d = 1;
+  }
+
+  num_reorder_frames = priv->is_live ? 0 : 1;
+  if (sps->vui_parameters_present_flag
+      && sps->vui_parameters.bitstream_restriction_flag)
+    num_reorder_frames = sps->vui_parameters.num_reorder_frames;
+  if (num_reorder_frames > max_dpb_size)
+    num_reorder_frames = priv->is_live ? 0 : 1;
+
+  /* Consider output delay wanted by subclass */
+  num_reorder_frames += priv->preferred_output_delay;
+
+  min = gst_util_uint64_scale_int (num_reorder_frames * GST_SECOND, fps_d,
+      fps_n);
+  max = gst_util_uint64_scale_int ((max_dpb_size + priv->preferred_output_delay)
+      * GST_SECOND, fps_d, fps_n);
+
+  GST_LOG_OBJECT (self,
+      "latency min %" G_GUINT64_FORMAT " max %" G_GUINT64_FORMAT, min, max);
+
+  gst_video_decoder_set_latency (GST_VIDEO_DECODER (self), min, max);
+}
+
 static gboolean
 gst_h264_decoder_process_sps (GstH264Decoder * self, GstH264SPS * sps)
 {
+  GstH264DecoderClass *klass = GST_H264_DECODER_GET_CLASS (self);
   GstH264DecoderPrivate *priv = self->priv;
   guint8 level;
   gint max_dpb_mbs;
@@ -1894,12 +2359,26 @@ gst_h264_decoder_process_sps (GstH264Decoder * self, GstH264SPS * sps)
   gint max_dpb_frames;
   gint max_dpb_size;
   gint prev_max_dpb_size;
+  gboolean prev_interlaced;
+  gboolean interlaced;
 
   if (sps->frame_mbs_only_flag == 0) {
-    GST_FIXME_OBJECT (self, "frame_mbs_only_flag != 1 not supported");
-    return FALSE;
+    if (!klass->new_field_picture) {
+      GST_FIXME_OBJECT (self,
+          "frame_mbs_only_flag != 1 not supported by subclass");
+      return FALSE;
+    }
+
+    if (sps->mb_adaptive_frame_field_flag) {
+      GST_LOG_OBJECT (self,
+          "mb_adaptive_frame_field_flag == 1, MBAFF sequence");
+    } else {
+      GST_LOG_OBJECT (self, "mb_adaptive_frame_field_flag == 0, PAFF sequence");
+    }
   }
 
+  interlaced = !sps->frame_mbs_only_flag;
+
   /* Spec A.3.1 and A.3.2
    * For Baseline, Constrained Baseline and Main profile, the indicated level is
    * Level 1b if level_idc is equal to 11 and constraint_set3_flag is equal to 1
@@ -1941,34 +2420,45 @@ gst_h264_decoder_process_sps (GstH264Decoder * self, GstH264SPS * sps)
   /* Safety, so that subclass don't need bound checking */
   g_return_val_if_fail (max_dpb_size <= GST_H264_DPB_MAX_SIZE, FALSE);
 
-  prev_max_dpb_size = gst_h264_dpb_get_max_num_pics (priv->dpb);
+  prev_max_dpb_size = gst_h264_dpb_get_max_num_frames (priv->dpb);
+  prev_interlaced = gst_h264_dpb_get_interlaced (priv->dpb);
   if (priv->width != sps->width || priv->height != sps->height ||
-      prev_max_dpb_size != max_dpb_size) {
+      prev_max_dpb_size != max_dpb_size || prev_interlaced != interlaced) {
     GstH264DecoderClass *klass = GST_H264_DECODER_GET_CLASS (self);
 
     GST_DEBUG_OBJECT (self,
-        "SPS updated, resolution: %dx%d -> %dx%d, dpb size: %d -> %d",
+        "SPS updated, resolution: %dx%d -> %dx%d, dpb size: %d -> %d, "
+        "interlaced %d -> %d",
         priv->width, priv->height, sps->width, sps->height,
-        prev_max_dpb_size, max_dpb_size);
+        prev_max_dpb_size, max_dpb_size, prev_interlaced, interlaced);
 
     if (gst_h264_decoder_drain (GST_VIDEO_DECODER (self)) != GST_FLOW_OK)
       return FALSE;
 
     g_assert (klass->new_sequence);
 
-    if (!klass->new_sequence (self, sps, max_dpb_size)) {
+    if (klass->get_preferred_output_delay) {
+      priv->preferred_output_delay =
+          klass->get_preferred_output_delay (self, priv->is_live);
+    } else {
+      priv->preferred_output_delay = 0;
+    }
+
+    if (!klass->new_sequence (self, sps,
+            max_dpb_size + priv->preferred_output_delay)) {
       GST_ERROR_OBJECT (self, "subclass does not want accept new sequence");
       return FALSE;
     }
 
+    priv->profile_idc = sps->profile_idc;
     priv->width = sps->width;
     priv->height = sps->height;
 
-    gst_h264_dpb_set_max_num_pics (priv->dpb, max_dpb_size);
+    gst_h264_decoder_set_latency (self, sps, max_dpb_size);
+    gst_h264_dpb_set_max_num_frames (priv->dpb, max_dpb_size);
+    gst_h264_dpb_set_interlaced (priv->dpb, interlaced);
   }
 
-  GST_DEBUG_OBJECT (self, "Set DPB max size %d", max_dpb_size);
-
   return gst_h264_decoder_update_max_num_reorder_frames (self, sps);
 }
 
@@ -1980,7 +2470,8 @@ gst_h264_decoder_init_gap_picture (GstH264Decoder * self,
   picture->nal_ref_idc = 1;
   picture->frame_num = picture->pic_num = frame_num;
   picture->dec_ref_pic_marking.adaptive_ref_pic_marking_mode_flag = FALSE;
-  picture->ref = TRUE;
+  picture->ref = GST_H264_PICTURE_REF_SHORT_TERM;
+  picture->ref_pic = TRUE;
   picture->dec_ref_pic_marking.long_term_reference_flag = FALSE;
   picture->field = GST_H264_PICTURE_FIELD_FRAME;
 
@@ -2047,7 +2538,8 @@ long_term_pic_num_asc_compare (const GstH264Picture ** a,
 }
 
 static void
-construct_ref_pic_lists_p (GstH264Decoder * self)
+construct_ref_pic_lists_p (GstH264Decoder * self,
+    GstH264Picture * current_picture)
 {
   GstH264DecoderPrivate *priv = self->priv;
   gint pos;
@@ -2058,11 +2550,13 @@ construct_ref_pic_lists_p (GstH264Decoder * self)
    */
   g_array_set_size (priv->ref_pic_list_p0, 0);
 
-  gst_h264_dpb_get_pictures_short_term_ref (priv->dpb, priv->ref_pic_list_p0);
+  gst_h264_dpb_get_pictures_short_term_ref (priv->dpb,
+      TRUE, FALSE, priv->ref_pic_list_p0);
   g_array_sort (priv->ref_pic_list_p0, (GCompareFunc) pic_num_desc_compare);
 
   pos = priv->ref_pic_list_p0->len;
-  gst_h264_dpb_get_pictures_long_term_ref (priv->dpb, priv->ref_pic_list_p0);
+  gst_h264_dpb_get_pictures_long_term_ref (priv->dpb,
+      FALSE, priv->ref_pic_list_p0);
   g_qsort_with_data (&g_array_index (priv->ref_pic_list_p0, gpointer, pos),
       priv->ref_pic_list_p0->len - pos, sizeof (gpointer),
       (GCompareDataFunc) long_term_pic_num_asc_compare, NULL);
@@ -2073,7 +2567,7 @@ construct_ref_pic_lists_p (GstH264Decoder * self)
     for (pos = 0; pos < priv->ref_pic_list_p0->len; pos++) {
       GstH264Picture *ref =
           g_array_index (priv->ref_pic_list_p0, GstH264Picture *, pos);
-      if (!ref->long_term)
+      if (!GST_H264_PICTURE_IS_LONG_TERM_REF (ref))
         g_string_append_printf (str, "|%i", ref->pic_num);
       else
         g_string_append_printf (str, "|%is", ref->pic_num);
@@ -2084,6 +2578,139 @@ construct_ref_pic_lists_p (GstH264Decoder * self)
 #endif
 }
 
+static gint
+frame_num_wrap_desc_compare (const GstH264Picture ** a,
+    const GstH264Picture ** b)
+{
+  return (*b)->frame_num_wrap - (*a)->frame_num_wrap;
+}
+
+static gint
+long_term_frame_idx_asc_compare (const GstH264Picture ** a,
+    const GstH264Picture ** b)
+{
+  return (*a)->long_term_frame_idx - (*b)->long_term_frame_idx;
+}
+
+/* init_picture_refs_fields_1 in gstvaapidecoder_h264.c */
+static void
+init_picture_refs_fields_1 (GstH264Decoder * self, GstH264PictureField field,
+    GArray * ref_frame_list, GArray * ref_pic_list_x)
+{
+  guint i = 0, j = 0;
+
+  do {
+    for (; i < ref_frame_list->len; i++) {
+      GstH264Picture *pic = g_array_index (ref_frame_list, GstH264Picture *, i);
+      if (pic->field == field) {
+        pic = gst_h264_picture_ref (pic);
+        g_array_append_val (ref_pic_list_x, pic);
+        i++;
+        break;
+      }
+    }
+
+    for (; j < ref_frame_list->len; j++) {
+      GstH264Picture *pic = g_array_index (ref_frame_list, GstH264Picture *, j);
+      if (pic->field != field) {
+        pic = gst_h264_picture_ref (pic);
+        g_array_append_val (ref_pic_list_x, pic);
+        j++;
+        break;
+      }
+    }
+  } while (i < ref_frame_list->len || j < ref_frame_list->len);
+}
+
+static void
+construct_ref_field_pic_lists_p (GstH264Decoder * self,
+    GstH264Picture * current_picture)
+{
+  GstH264DecoderPrivate *priv = self->priv;
+  gint pos;
+
+  g_array_set_size (priv->ref_pic_list_p0, 0);
+  g_array_set_size (priv->ref_frame_list_0_short_term, 0);
+  g_array_set_size (priv->ref_frame_list_long_term, 0);
+
+  /* 8.2.4.2.2, 8.2.4.2.5 refFrameList0ShortTerm:
+   * short-term ref pictures sorted by descending frame_num_wrap.
+   */
+  gst_h264_dpb_get_pictures_short_term_ref (priv->dpb,
+      TRUE, TRUE, priv->ref_frame_list_0_short_term);
+  g_array_sort (priv->ref_frame_list_0_short_term,
+      (GCompareFunc) frame_num_wrap_desc_compare);
+
+#ifndef GST_DISABLE_GST_DEBUG
+  if (gst_debug_category_get_threshold (GST_CAT_DEFAULT) >= GST_LEVEL_TRACE
+      && priv->ref_frame_list_0_short_term->len) {
+    GString *str = g_string_new (NULL);
+    for (pos = 0; pos < priv->ref_frame_list_0_short_term->len; pos++) {
+      GstH264Picture *ref = g_array_index (priv->ref_frame_list_0_short_term,
+          GstH264Picture *, pos);
+      g_string_append_printf (str, "|%i(%d)", ref->frame_num_wrap, ref->field);
+    }
+    GST_TRACE_OBJECT (self, "ref_frame_list_0_short_term (%d): %s|",
+        current_picture->field, str->str);
+    g_string_free (str, TRUE);
+  }
+#endif
+
+  /* 8.2.4.2.2 refFrameList0LongTerm,:
+   * long-term ref pictures sorted by ascending long_term_frame_idx.
+   */
+  gst_h264_dpb_get_pictures_long_term_ref (priv->dpb,
+      TRUE, priv->ref_frame_list_long_term);
+  g_array_sort (priv->ref_frame_list_long_term,
+      (GCompareFunc) long_term_frame_idx_asc_compare);
+
+#ifndef GST_DISABLE_GST_DEBUG
+  if (gst_debug_category_get_threshold (GST_CAT_DEFAULT) >= GST_LEVEL_TRACE
+      && priv->ref_frame_list_long_term->len) {
+    GString *str = g_string_new (NULL);
+    for (pos = 0; pos < priv->ref_frame_list_long_term->len; pos++) {
+      GstH264Picture *ref = g_array_index (priv->ref_frame_list_0_short_term,
+          GstH264Picture *, pos);
+      g_string_append_printf (str, "|%i(%d)", ref->long_term_frame_idx,
+          ref->field);
+    }
+    GST_TRACE_OBJECT (self, "ref_frame_list_0_long_term (%d): %s|",
+        current_picture->field, str->str);
+    g_string_free (str, TRUE);
+  }
+#endif
+
+  /* 8.2.4.2.5 */
+  init_picture_refs_fields_1 (self, current_picture->field,
+      priv->ref_frame_list_0_short_term, priv->ref_pic_list_p0);
+  init_picture_refs_fields_1 (self, current_picture->field,
+      priv->ref_frame_list_long_term, priv->ref_pic_list_p0);
+
+#ifndef GST_DISABLE_GST_DEBUG
+  if (gst_debug_category_get_threshold (GST_CAT_DEFAULT) >= GST_LEVEL_DEBUG
+      && priv->ref_pic_list_p0->len) {
+    GString *str = g_string_new (NULL);
+    for (pos = 0; pos < priv->ref_pic_list_p0->len; pos++) {
+      GstH264Picture *ref =
+          g_array_index (priv->ref_pic_list_p0, GstH264Picture *, pos);
+      if (!GST_H264_PICTURE_IS_LONG_TERM_REF (ref))
+        g_string_append_printf (str, "|%i(%d)s", ref->frame_num_wrap,
+            ref->field);
+      else
+        g_string_append_printf (str, "|%i(%d)l", ref->long_term_frame_idx,
+            ref->field);
+    }
+    GST_DEBUG_OBJECT (self, "ref_pic_list_p0 (%d): %s|", current_picture->field,
+        str->str);
+    g_string_free (str, TRUE);
+  }
+#endif
+
+  /* Clear temporary lists, now pictures are owned by ref_pic_list_p0 */
+  g_array_set_size (priv->ref_frame_list_0_short_term, 0);
+  g_array_set_size (priv->ref_frame_list_long_term, 0);
+}
+
 static gboolean
 lists_are_equal (GArray * l1, GArray * l2)
 {
@@ -2115,7 +2742,8 @@ split_ref_pic_list_b (GstH264Decoder * self, GArray * ref_pic_list_b,
 }
 
 static void
-print_ref_pic_list_b (GstH264Decoder * self, GArray * ref_list_b, gint index)
+print_ref_pic_list_b (GstH264Decoder * self, GArray * ref_list_b,
+    const gchar * name)
 {
 #ifndef GST_DISABLE_GST_DEBUG
   GString *str;
@@ -2129,20 +2757,21 @@ print_ref_pic_list_b (GstH264Decoder * self, GArray * ref_list_b, gint index)
   for (i = 0; i < ref_list_b->len; i++) {
     GstH264Picture *ref = g_array_index (ref_list_b, GstH264Picture *, i);
 
-    if (!ref->long_term)
+    if (!GST_H264_PICTURE_IS_LONG_TERM_REF (ref))
       g_string_append_printf (str, "|%i", ref->pic_order_cnt);
     else
       g_string_append_printf (str, "|%il", ref->long_term_pic_num);
   }
 
-  GST_DEBUG_OBJECT (self, "ref_pic_list_b%i: %s| curr %i", index, str->str,
+  GST_DEBUG_OBJECT (self, "%s: %s| curr %i", name, str->str,
       self->priv->current_picture->pic_order_cnt);
   g_string_free (str, TRUE);
 #endif
 }
 
 static void
-construct_ref_pic_lists_b (GstH264Decoder * self)
+construct_ref_pic_lists_b (GstH264Decoder * self,
+    GstH264Picture * current_picture)
 {
   GstH264DecoderPrivate *priv = self->priv;
   gint pos;
@@ -2154,13 +2783,20 @@ construct_ref_pic_lists_b (GstH264Decoder * self)
    */
   g_array_set_size (priv->ref_pic_list_b0, 0);
   g_array_set_size (priv->ref_pic_list_b1, 0);
-  gst_h264_dpb_get_pictures_short_term_ref (priv->dpb, priv->ref_pic_list_b0);
+
+  /* 8.2.4.2.3
+   * When pic_order_cnt_type is equal to 0, reference pictures that are marked
+   * as "non-existing" as specified in clause 8.2.5.2 are not included in either
+   * RefPicList0 or RefPicList1
+   */
+  gst_h264_dpb_get_pictures_short_term_ref (priv->dpb,
+      current_picture->pic_order_cnt_type != 0, FALSE, priv->ref_pic_list_b0);
 
   /* First sort ascending, this will put [1] in right place and finish
    * [2]. */
-  print_ref_pic_list_b (self, priv->ref_pic_list_b0, 0);
+  print_ref_pic_list_b (self, priv->ref_pic_list_b0, "ref_pic_list_b0");
   g_array_sort (priv->ref_pic_list_b0, (GCompareFunc) poc_asc_compare);
-  print_ref_pic_list_b (self, priv->ref_pic_list_b0, 0);
+  print_ref_pic_list_b (self, priv->ref_pic_list_b0, "ref_pic_list_b0");
 
   /* Find first with POC > current_picture's POC to get first element
    * in [2]... */
@@ -2175,7 +2811,8 @@ construct_ref_pic_lists_b (GstH264Decoder * self)
 
   /* Now add [3] and sort by ascending long_term_pic_num. */
   pos = priv->ref_pic_list_b0->len;
-  gst_h264_dpb_get_pictures_long_term_ref (priv->dpb, priv->ref_pic_list_b0);
+  gst_h264_dpb_get_pictures_long_term_ref (priv->dpb,
+      FALSE, priv->ref_pic_list_b0);
   g_qsort_with_data (&g_array_index (priv->ref_pic_list_b0, gpointer, pos),
       priv->ref_pic_list_b0->len - pos, sizeof (gpointer),
       (GCompareDataFunc) long_term_pic_num_asc_compare, NULL);
@@ -2185,7 +2822,8 @@ construct_ref_pic_lists_b (GstH264Decoder * self)
    * [2] shortterm ref pics with POC < curr_pic's POC by descending POC,
    * [3] longterm ref pics by ascending long_term_pic_num.
    */
-  gst_h264_dpb_get_pictures_short_term_ref (priv->dpb, priv->ref_pic_list_b1);
+  gst_h264_dpb_get_pictures_short_term_ref (priv->dpb,
+      current_picture->pic_order_cnt_type != 0, FALSE, priv->ref_pic_list_b1);
 
   /* First sort by descending POC. */
   g_array_sort (priv->ref_pic_list_b1, (GCompareFunc) poc_desc_compare);
@@ -2201,7 +2839,8 @@ construct_ref_pic_lists_b (GstH264Decoder * self)
 
   /* Now add [3] and sort by ascending long_term_pic_num */
   pos = priv->ref_pic_list_b1->len;
-  gst_h264_dpb_get_pictures_long_term_ref (priv->dpb, priv->ref_pic_list_b1);
+  gst_h264_dpb_get_pictures_long_term_ref (priv->dpb,
+      FALSE, priv->ref_pic_list_b1);
   g_qsort_with_data (&g_array_index (priv->ref_pic_list_b1, gpointer, pos),
       priv->ref_pic_list_b1->len - pos, sizeof (gpointer),
       (GCompareDataFunc) long_term_pic_num_asc_compare, NULL);
@@ -2217,15 +2856,155 @@ construct_ref_pic_lists_b (GstH264Decoder * self)
     list[1] = pic;
   }
 
-  print_ref_pic_list_b (self, priv->ref_pic_list_b0, 0);
-  print_ref_pic_list_b (self, priv->ref_pic_list_b1, 1);
+  print_ref_pic_list_b (self, priv->ref_pic_list_b0, "ref_pic_list_b0");
+  print_ref_pic_list_b (self, priv->ref_pic_list_b1, "ref_pic_list_b1");
 }
 
 static void
-gst_h264_decoder_prepare_ref_pic_lists (GstH264Decoder * self)
+construct_ref_field_pic_lists_b (GstH264Decoder * self,
+    GstH264Picture * current_picture)
 {
-  construct_ref_pic_lists_p (self);
-  construct_ref_pic_lists_b (self);
+  GstH264DecoderPrivate *priv = self->priv;
+  gint pos;
+
+  /* refFrameList0ShortTerm (8.2.4.2.4) [[1] [2]], where:
+   * [1] shortterm ref pics with POC < current_picture's POC sorted by descending POC,
+   * [2] shortterm ref pics with POC > current_picture's POC by ascending POC,
+   */
+  g_array_set_size (priv->ref_pic_list_b0, 0);
+  g_array_set_size (priv->ref_pic_list_b1, 0);
+  g_array_set_size (priv->ref_frame_list_0_short_term, 0);
+  g_array_set_size (priv->ref_frame_list_1_short_term, 0);
+  g_array_set_size (priv->ref_frame_list_long_term, 0);
+
+  /* 8.2.4.2.4
+   * When pic_order_cnt_type is equal to 0, reference pictures that are marked
+   * as "non-existing" as specified in clause 8.2.5.2 are not included in either
+   * RefPicList0 or RefPicList1
+   */
+  gst_h264_dpb_get_pictures_short_term_ref (priv->dpb,
+      current_picture->pic_order_cnt_type != 0, TRUE,
+      priv->ref_frame_list_0_short_term);
+
+  /* First sort ascending, this will put [1] in right place and finish
+   * [2]. */
+  print_ref_pic_list_b (self, priv->ref_frame_list_0_short_term,
+      "ref_frame_list_0_short_term");
+  g_array_sort (priv->ref_frame_list_0_short_term,
+      (GCompareFunc) poc_asc_compare);
+  print_ref_pic_list_b (self, priv->ref_frame_list_0_short_term,
+      "ref_frame_list_0_short_term");
+
+  /* Find first with POC > current_picture's POC to get first element
+   * in [2]... */
+  pos = split_ref_pic_list_b (self, priv->ref_frame_list_0_short_term,
+      (GCompareFunc) poc_asc_compare);
+
+  GST_DEBUG_OBJECT (self, "split point %i", pos);
+
+  /* and sort [1] descending, thus finishing sequence [1] [2]. */
+  g_qsort_with_data (priv->ref_frame_list_0_short_term->data, pos,
+      sizeof (gpointer), (GCompareDataFunc) poc_desc_compare, NULL);
+
+  /* refFrameList1ShortTerm (8.2.4.2.4) [[1] [2]], where:
+   * [1] shortterm ref pics with POC > curr_pic's POC sorted by ascending POC,
+   * [2] shortterm ref pics with POC < curr_pic's POC by descending POC,
+   */
+  gst_h264_dpb_get_pictures_short_term_ref (priv->dpb,
+      current_picture->pic_order_cnt_type != 0, TRUE,
+      priv->ref_frame_list_1_short_term);
+
+  /* First sort by descending POC. */
+  g_array_sort (priv->ref_frame_list_1_short_term,
+      (GCompareFunc) poc_desc_compare);
+
+  /* Split at first with POC < current_picture's POC to get first element
+   * in [2]... */
+  pos = split_ref_pic_list_b (self, priv->ref_frame_list_1_short_term,
+      (GCompareFunc) poc_desc_compare);
+
+  /* and sort [1] ascending. */
+  g_qsort_with_data (priv->ref_frame_list_1_short_term->data, pos,
+      sizeof (gpointer), (GCompareDataFunc) poc_asc_compare, NULL);
+
+  /* 8.2.4.2.2 refFrameList0LongTerm,:
+   * long-term ref pictures sorted by ascending long_term_frame_idx.
+   */
+  gst_h264_dpb_get_pictures_long_term_ref (priv->dpb,
+      TRUE, priv->ref_frame_list_long_term);
+  g_array_sort (priv->ref_frame_list_long_term,
+      (GCompareFunc) long_term_frame_idx_asc_compare);
+
+  /* 8.2.4.2.5 RefPicList0 */
+  init_picture_refs_fields_1 (self, current_picture->field,
+      priv->ref_frame_list_0_short_term, priv->ref_pic_list_b0);
+  init_picture_refs_fields_1 (self, current_picture->field,
+      priv->ref_frame_list_long_term, priv->ref_pic_list_b0);
+
+  /* 8.2.4.2.5 RefPicList1 */
+  init_picture_refs_fields_1 (self, current_picture->field,
+      priv->ref_frame_list_1_short_term, priv->ref_pic_list_b1);
+  init_picture_refs_fields_1 (self, current_picture->field,
+      priv->ref_frame_list_long_term, priv->ref_pic_list_b1);
+
+  /* If lists identical, swap first two entries in RefPicList1 (spec
+   * 8.2.4.2.5) */
+  if (priv->ref_pic_list_b1->len > 1
+      && lists_are_equal (priv->ref_pic_list_b0, priv->ref_pic_list_b1)) {
+    /* swap */
+    GstH264Picture **list = (GstH264Picture **) priv->ref_pic_list_b1->data;
+    GstH264Picture *pic = list[0];
+    list[0] = list[1];
+    list[1] = pic;
+  }
+
+  print_ref_pic_list_b (self, priv->ref_pic_list_b0, "ref_pic_list_b0");
+  print_ref_pic_list_b (self, priv->ref_pic_list_b1, "ref_pic_list_b1");
+
+  /* Clear temporary lists, now pictures are owned by ref_pic_list_b0
+   * and ref_pic_list_b1 */
+  g_array_set_size (priv->ref_frame_list_0_short_term, 0);
+  g_array_set_size (priv->ref_frame_list_1_short_term, 0);
+  g_array_set_size (priv->ref_frame_list_long_term, 0);
+}
+
+static void
+gst_h264_decoder_prepare_ref_pic_lists (GstH264Decoder * self,
+    GstH264Picture * current_picture)
+{
+  GstH264DecoderPrivate *priv = self->priv;
+  gboolean construct_list = FALSE;
+  gint i;
+  GArray *dpb_array = gst_h264_dpb_get_pictures_all (priv->dpb);
+  g_return_val_if_fail (dpb_array != NULL, NULL);
+
+  /* 8.2.4.2.1 ~ 8.2.4.2.4
+   * When this process is invoked, there shall be at least one reference entry
+   * that is currently marked as "used for reference"
+   * (i.e., as "used for short-term reference" or "used for long-term reference")
+   * and is not marked as "non-existing"
+   */
+  for (i = 0; i < dpb_array->len; i++) {
+    GstH264Picture *picture = g_array_index (dpb_array, GstH264Picture *, i);
+    if (GST_H264_PICTURE_IS_REF (picture) && !picture->nonexisting) {
+      construct_list = TRUE;
+      break;
+    }
+  }
+  g_array_unref (dpb_array);
+
+  if (!construct_list) {
+    gst_h264_decoder_clear_ref_pic_lists (self);
+    return;
+  }
+
+  if (GST_H264_PICTURE_IS_FRAME (current_picture)) {
+    construct_ref_pic_lists_p (self, current_picture);
+    construct_ref_pic_lists_b (self, current_picture);
+  } else {
+    construct_ref_field_pic_lists_p (self, current_picture);
+    construct_ref_field_pic_lists_b (self, current_picture);
+  }
 }
 
 static void
@@ -2241,7 +3020,7 @@ gst_h264_decoder_clear_ref_pic_lists (GstH264Decoder * self)
 static gint
 long_term_pic_num_f (GstH264Decoder * self, const GstH264Picture * picture)
 {
-  if (picture->ref && picture->long_term)
+  if (GST_H264_PICTURE_IS_LONG_TERM_REF (picture))
     return picture->long_term_pic_num;
   return 2 * (self->priv->max_long_term_frame_idx + 1);
 }
@@ -2249,7 +3028,7 @@ long_term_pic_num_f (GstH264Decoder * self, const GstH264Picture * picture)
 static gint
 pic_num_f (GstH264Decoder * self, const GstH264Picture * picture)
 {
-  if (!picture->long_term)
+  if (!GST_H264_PICTURE_IS_LONG_TERM_REF (picture))
     return picture->pic_num;
   return self->priv->max_pic_num;
 }
@@ -2360,7 +3139,7 @@ modify_ref_pic_list (GstH264Decoder * self, int list)
         if (!pic) {
           GST_WARNING_OBJECT (self, "Malformed stream, no pic num %d",
               pic_num_lx);
-          return FALSE;
+          break;
         }
         shift_right_and_insert (ref_pic_listx, ref_idx_lx,
             num_ref_idx_lX_active_minus1, pic);
@@ -2381,12 +3160,12 @@ modify_ref_pic_list (GstH264Decoder * self, int list)
       case 2:
         /* (8-28) */
         g_assert (num_ref_idx_lX_active_minus1 + 1 < 32);
-        pic = gst_h264_dpb_get_long_ref_by_pic_num (priv->dpb,
+        pic = gst_h264_dpb_get_long_ref_by_long_term_pic_num (priv->dpb,
             list_mod->value.long_term_pic_num);
         if (!pic) {
           GST_WARNING_OBJECT (self, "Malformed stream, no pic num %d",
               list_mod->value.long_term_pic_num);
-          return FALSE;
+          break;
         }
         shift_right_and_insert (ref_pic_listx, ref_idx_lx,
             num_ref_idx_lX_active_minus1, pic);
@@ -2443,11 +3222,15 @@ gst_h264_decoder_modify_ref_pic_lists (GstH264Decoder * self)
   GstH264DecoderPrivate *priv = self->priv;
   GstH264SliceHdr *slice_hdr = &priv->current_slice.header;
 
-  /* fill reference picture lists for B and S/SP slices */
+  g_array_set_size (priv->ref_pic_list0, 0);
+  g_array_set_size (priv->ref_pic_list1, 0);
+
   if (GST_H264_IS_P_SLICE (slice_hdr) || GST_H264_IS_SP_SLICE (slice_hdr)) {
+    /* 8.2.4 fill reference picture list RefPicList0 for P or SP slice */
     copy_pic_list_into (priv->ref_pic_list0, priv->ref_pic_list_p0);
     return modify_ref_pic_list (self, 0);
-  } else {
+  } else if (GST_H264_IS_B_SLICE (slice_hdr)) {
+    /* 8.2.4 fill reference picture list RefPicList0 and RefPicList1 for B slice */
     copy_pic_list_into (priv->ref_pic_list0, priv->ref_pic_list_b0);
     copy_pic_list_into (priv->ref_pic_list1, priv->ref_pic_list_b1);
     return modify_ref_pic_list (self, 0)
diff --git a/gst-libs/gst/codecs/gsth264decoder.h b/gst-libs/gst/codecs/gsth264decoder.h
index fa94aa296..710b6c9fc 100644
--- a/gst-libs/gst/codecs/gsth264decoder.h
+++ b/gst-libs/gst/codecs/gsth264decoder.h
@@ -36,6 +36,49 @@ G_BEGIN_DECLS
 #define GST_IS_H264_DECODER_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE((klass),GST_TYPE_H264_DECODER))
 #define GST_H264_DECODER_CAST(obj)       ((GstH264Decoder*)obj)
 
+/**
+ * GstH264DecoderCompliance:
+ * @GST_H264_DECODER_COMPLIANCE_AUTO: The decoder behavior is
+ *     automatically choosen.
+ * @GST_H264_DECODER_COMPLIANCE_STRICT: The decoder behavior strictly
+ *     conforms to the SPEC. All the decoder behaviors conform to the
+ *     SPEC, not including any nonstandard behavior which is not
+ *     mentioned in the SPEC.
+ * @GST_H264_DECODER_COMPLIANCE_NORMAL: The decoder behavior normally
+ *     conforms to the SPEC. Most behaviors conform to the SPEC but
+ *     including some nonstandard features which are widely used or
+ *     often used in the industry practice. This meets the request of
+ *     real streams and usages, but may not 100% conform to the
+ *     SPEC. It has very low risk. E.g., we will output pictures
+ *     without waiting DPB being full for the lower latency, which may
+ *     cause B frame disorder when there are reference frames with
+ *     smaller POC after it in decoder order. And the baseline profile
+ *     may be mapped to the constrained-baseline profile, but it may
+ *     have problems when a real baseline stream comes with FMO or
+ *     ASO.
+ * @GST_H264_DECODER_COMPLIANCE_FLEXIBLE: The decoder behavior
+ *     flexibly conforms to the SPEC. It uses the nonstandard features
+ *     more aggressively in order to get better performance(for
+ *     example, lower latency). It may change the result of the
+ *     decoder and should be used carefully. Besides including all
+ *     risks in *normal* mode, it has more risks, such as frames
+ *     disorder when reference frames POC decrease in decoder order.
+ *
+ * Since: 1.20
+ */
+typedef enum
+{
+  GST_H264_DECODER_COMPLIANCE_AUTO,
+  GST_H264_DECODER_COMPLIANCE_STRICT,
+  GST_H264_DECODER_COMPLIANCE_NORMAL,
+  GST_H264_DECODER_COMPLIANCE_FLEXIBLE
+} GstH264DecoderCompliance;
+
+#define GST_TYPE_H264_DECODER_COMPLIANCE (gst_h264_decoder_compliance_get_type())
+
+GST_CODECS_API
+GType gst_h264_decoder_compliance_get_type (void);
+
 typedef struct _GstH264Decoder GstH264Decoder;
 typedef struct _GstH264DecoderClass GstH264DecoderClass;
 typedef struct _GstH264DecoderPrivate GstH264DecoderPrivate;
@@ -60,70 +103,137 @@ struct _GstH264Decoder
 
 /**
  * GstH264DecoderClass:
- * @new_sequence:   Notifies subclass of SPS update
- * @new_picture:    Optional.
- *                  Called whenever new #GstH264Picture is created.
- *                  Subclass can set implementation specific user data
- *                  on the #GstH264Picture via gst_h264_picture_set_user_data()
- * @start_picture:  Optional.
- *                  Called per one #GstH264Picture to notify subclass to prepare
- *                  decoding process for the #GstH264Picture
- * @decode_slice:   Provides per slice data with parsed slice header and
- *                  required raw bitstream for subclass to decode it.
- *                  if gst_h264_decoder_set_process_ref_pic_lists() is called
- *                  with %TRUE by the subclass, @ref_pic_list0 and @ref_pic_list1
- *                  are non-%NULL.
- * @end_picture:    Optional.
- *                  Called per one #GstH264Picture to notify subclass to finish
- *                  decoding process for the #GstH264Picture
- * @output_picture: Called with a #GstH264Picture which is required to be outputted.
- *                  Subclass can retrieve parent #GstVideoCodecFrame by using
- *                  gst_video_decoder_get_frame() with system_frame_number
- *                  and the #GstVideoCodecFrame must be consumed by subclass via
- *                  gst_video_decoder_{finish,drop,release}_frame().
+ *
+ * The opaque #GstH264DecoderClass data structure.
  */
 struct _GstH264DecoderClass
 {
+  /*< private >*/
   GstVideoDecoderClass parent_class;
 
+  /**
+   * GstH264DecoderClass::new_sequence:
+   * @decoder: a #GstH264Decoder
+   * @sps: a #GstH264SPS
+   * @max_dpb_size: the size of dpb including preferred output delay
+   *   by subclass reported via get_preferred_output_delay method.
+   *
+   * Notifies subclass of SPS update
+   */
   gboolean      (*new_sequence)     (GstH264Decoder * decoder,
                                      const GstH264SPS * sps,
                                      gint max_dpb_size);
 
   /**
-   * GstH264Decoder:new_picture:
+   * GstH264DecoderClass::new_picture:
    * @decoder: a #GstH264Decoder
    * @frame: (transfer none): a #GstVideoCodecFrame
    * @picture: (transfer none): a #GstH264Picture
+   *
+   * Optional. Called whenever new #GstH264Picture is created.
+   * Subclass can set implementation specific user data
+   * on the #GstH264Picture via gst_h264_picture_set_user_data()
    */
   gboolean      (*new_picture)      (GstH264Decoder * decoder,
                                      GstVideoCodecFrame * frame,
                                      GstH264Picture * picture);
 
+  /**
+   * GstH264DecoderClass::new_field_picture:
+   * @decoder: a #GstH264Decoder
+   * @first_field: (transfer none): the first field #GstH264Picture already decoded
+   * @second_field: (transfer none): a #GstH264Picture for the second field
+   *
+   * Called when a new field picture is created for interlaced field picture.
+   * Subclass can attach implementation specific user data on @second_field via
+   * gst_h264_picture_set_user_data()
+   *
+   * Since: 1.20
+   */
+  gboolean      (*new_field_picture)  (GstH264Decoder * decoder,
+                                       const GstH264Picture * first_field,
+                                       GstH264Picture * second_field);
+
+  /**
+   * GstH264DecoderClass::start_picture:
+   * @decoder: a #GstH264Decoder
+   * @picture: (transfer none): a #GstH264Picture
+   * @slice: (transfer none): a #GstH264Slice
+   * @dpb: (transfer none): a #GstH264Dpb
+   *
+   * Optional. Called per one #GstH264Picture to notify subclass to prepare
+   * decoding process for the #GstH264Picture
+   */
   gboolean      (*start_picture)    (GstH264Decoder * decoder,
                                      GstH264Picture * picture,
                                      GstH264Slice * slice,
                                      GstH264Dpb * dpb);
 
+  /**
+   * GstH264DecoderClass::decode_slice:
+   * @decoder: a #GstH264Decoder
+   * @picture: (transfer none): a #GstH264Picture
+   * @slice: (transfer none): a #GstH264Slice
+   * @ref_pic_list0: (element-type GstH264Picture) (transfer none):
+   *    an array of #GstH264Picture pointers
+   * @ref_pic_list1: (element-type GstH264Picture) (transfer none):
+   *    an array of #GstH264Picture pointers
+   *
+   * Provides per slice data with parsed slice header and required raw bitstream
+   * for subclass to decode it. If gst_h264_decoder_set_process_ref_pic_lists()
+   * is called with %TRUE by the subclass, @ref_pic_list0 and @ref_pic_list1
+   * are non-%NULL.
+   * In case of interlaced stream, @ref_pic_list0 and @ref_pic_list1 will
+   * contain only the first field of complementary reference field pair
+   * if currently being decoded picture is a frame picture. Subclasses might
+   * need to retrive the other field (i.e., the second field) of the picture
+   * if needed.
+   */
   gboolean      (*decode_slice)     (GstH264Decoder * decoder,
                                      GstH264Picture * picture,
                                      GstH264Slice * slice,
                                      GArray * ref_pic_list0,
                                      GArray * ref_pic_list1);
 
+  /**
+   * GstH264DecoderClass::end_picture:
+   * @decoder: a #GstH264Decoder
+   * @picture: (transfer none): a #GstH264Picture
+   *
+   * Optional. Called per one #GstH264Picture to notify subclass to finish
+   * decoding process for the #GstH264Picture
+   */
   gboolean      (*end_picture)      (GstH264Decoder * decoder,
                                      GstH264Picture * picture);
 
   /**
-   * GstH264Decoder:output_picture:
+   * GstH264DecoderClass::output_picture:
    * @decoder: a #GstH264Decoder
    * @frame: (transfer full): a #GstVideoCodecFrame
    * @picture: (transfer full): a #GstH264Picture
+   *
+   * Called with a #GstH264Picture which is required to be outputted.
+   * The #GstVideoCodecFrame must be consumed by subclass.
    */
   GstFlowReturn (*output_picture)   (GstH264Decoder * decoder,
                                      GstVideoCodecFrame * frame,
                                      GstH264Picture * picture);
 
+  /**
+   * GstH264DecoderClass::get_preferred_output_delay:
+   * @decoder: a #GstH264Decoder
+   * @live: whether upstream is live or not
+   *
+   * Optional. Called by baseclass to query whether delaying output is
+   * preferred by subclass or not.
+   *
+   * Returns: the number of perferred delayed output frame
+   *
+   * Since: 1.20
+   */
+  guint (*get_preferred_output_delay)   (GstH264Decoder * decoder,
+                                         gboolean live);
+
   /*< private >*/
   gpointer padding[GST_PADDING_LARGE];
 };
diff --git a/gst-libs/gst/codecs/gsth264picture.c b/gst-libs/gst/codecs/gsth264picture.c
index 41b357134..cf8c9c20b 100644
--- a/gst-libs/gst/codecs/gsth264picture.c
+++ b/gst-libs/gst/codecs/gsth264picture.c
@@ -22,6 +22,8 @@
 #endif
 
 #include "gsth264picture.h"
+#include <stdlib.h>
+#include <stdio.h>
 
 GST_DEBUG_CATEGORY_EXTERN (gst_h264_decoder_debug);
 #define GST_CAT_DEFAULT gst_h264_decoder_debug
@@ -51,7 +53,6 @@ gst_h264_picture_new (void)
 
   pic = g_new0 (GstH264Picture, 1);
 
-  pic->pts = GST_CLOCK_TIME_NONE;
   pic->top_field_order_cnt = G_MAXINT32;
   pic->bottom_field_order_cnt = G_MAXINT32;
   pic->field = GST_H264_PICTURE_FIELD_FRAME;
@@ -106,9 +107,23 @@ gst_h264_picture_get_user_data (GstH264Picture * picture)
 struct _GstH264Dpb
 {
   GArray *pic_list;
-  gint max_num_pics;
+  gint max_num_frames;
+  gint num_output_needed;
+  guint32 max_num_reorder_frames;
+  gint32 last_output_poc;
+  gboolean last_output_non_ref;
+
+  gboolean interlaced;
 };
 
+static void
+gst_h264_dpb_init (GstH264Dpb * dpb)
+{
+  dpb->num_output_needed = 0;
+  dpb->last_output_poc = G_MININT32;
+  dpb->last_output_non_ref = FALSE;
+}
+
 /**
  * gst_h264_dpb_new: (skip)
  *
@@ -122,6 +137,7 @@ gst_h264_dpb_new (void)
   GstH264Dpb *dpb;
 
   dpb = g_new0 (GstH264Dpb, 1);
+  gst_h264_dpb_init (dpb);
 
   dpb->pic_list =
       g_array_sized_new (FALSE, TRUE, sizeof (GstH264Picture *),
@@ -133,32 +149,67 @@ gst_h264_dpb_new (void)
 }
 
 /**
- * gst_h264_dpb_set_max_num_pics:
+ * gst_h264_dpb_set_max_num_frames:
  * @dpb: a #GstH264Dpb
- * @max_num_pics: the maximum number of picture
+ * @max_num_frames: the maximum number of picture
+ *
+ * Set the number of maximum allowed frames to store
  *
- * Set the number of maximum allowed pictures to store
+ * Since: 1.20
  */
 void
-gst_h264_dpb_set_max_num_pics (GstH264Dpb * dpb, gint max_num_pics)
+gst_h264_dpb_set_max_num_frames (GstH264Dpb * dpb, gint max_num_frames)
 {
   g_return_if_fail (dpb != NULL);
 
-  dpb->max_num_pics = max_num_pics;
+  dpb->max_num_frames = max_num_frames;
 }
 
 /**
- * gst_h264_dpb_get_max_num_pics:
+ * gst_h264_dpb_get_max_num_frames:
  * @dpb: a #GstH264Dpb
  *
- * Returns: the number of maximum pictures
+ * Returns: the number of maximum frames
+ *
+ * Since: 1.20
  */
 gint
-gst_h264_dpb_get_max_num_pics (GstH264Dpb * dpb)
+gst_h264_dpb_get_max_num_frames (GstH264Dpb * dpb)
 {
   g_return_val_if_fail (dpb != NULL, 0);
 
-  return dpb->max_num_pics;
+  return dpb->max_num_frames;
+}
+
+/**
+ * gst_h264_dpb_set_interlaced:
+ * @dpb: a #GstH264Dpb
+ * @interlaced: %TRUE if interlaced
+ *
+ * Since: 1.20
+ */
+void
+gst_h264_dpb_set_interlaced (GstH264Dpb * dpb, gboolean interlaced)
+{
+  g_return_if_fail (dpb != NULL);
+
+  dpb->interlaced = interlaced;
+}
+
+/**
+ * gst_h264_dpb_get_interlaced:
+ * @dpb: a #GstH264Dpb
+ *
+ * Returns: %TRUE if @dpb is configured for interlaced stream
+ *
+ * Since: 1.20
+ */
+gboolean
+gst_h264_dpb_get_interlaced (GstH264Dpb * dpb)
+{
+  g_return_val_if_fail (dpb != NULL, FALSE);
+
+  return dpb->interlaced;
 }
 
 /**
@@ -189,87 +240,86 @@ gst_h264_dpb_clear (GstH264Dpb * dpb)
   g_return_if_fail (dpb != NULL);
 
   g_array_set_size (dpb->pic_list, 0);
+  gst_h264_dpb_init (dpb);
 }
 
 /**
- * gst_h264_dpb_add:
+ * gst_h264_dpb_set_max_num_reorder_frames:
  * @dpb: a #GstH264Dpb
- * @picture: (transfer full): a #GstH264Picture
+ * @max_num_reorder_frames: the max number of reorder frames, which
+ * should not exceed the max size of DPB.
  *
- * Store the @picture
+ * Since: 1.20
  */
 void
-gst_h264_dpb_add (GstH264Dpb * dpb, GstH264Picture * picture)
+gst_h264_dpb_set_max_num_reorder_frames (GstH264Dpb * dpb,
+    guint32 max_num_reorder_frames)
 {
   g_return_if_fail (dpb != NULL);
-  g_return_if_fail (GST_IS_H264_PICTURE (picture));
+  g_return_if_fail (max_num_reorder_frames <= dpb->max_num_frames);
 
-  g_array_append_val (dpb->pic_list, picture);
+  dpb->max_num_reorder_frames = max_num_reorder_frames;
 }
 
 /**
- * gst_h264_dpb_delete_unused:
+ * gst_h264_dpb_add:
  * @dpb: a #GstH264Dpb
+ * @picture: (transfer full): a #GstH264Picture
  *
- * Delete already outputted and not referenced all pictures from dpb
+ * Store the @picture
  */
 void
-gst_h264_dpb_delete_unused (GstH264Dpb * dpb)
+gst_h264_dpb_add (GstH264Dpb * dpb, GstH264Picture * picture)
 {
-  gint i;
-
   g_return_if_fail (dpb != NULL);
+  g_return_if_fail (GST_IS_H264_PICTURE (picture));
 
-  for (i = 0; i < dpb->pic_list->len; i++) {
-    GstH264Picture *picture =
-        g_array_index (dpb->pic_list, GstH264Picture *, i);
-
-    if (picture->outputted && !picture->ref) {
-      GST_TRACE ("remove picture %p (frame num %d) from dpb",
-          picture, picture->frame_num);
-      g_array_remove_index_fast (dpb->pic_list, i);
-      i--;
+  /* C.4.2 Decoding of gaps in frame_num and storage of "non-existing" pictures
+   *
+   * The "non-existing" frame is stored in an empty frame buffer and is marked
+   * as "not needed for output", and the DPB fullness is incremented by one */
+  if (!picture->nonexisting) {
+    picture->needed_for_output = TRUE;
+
+    if (GST_H264_PICTURE_IS_FRAME (picture)) {
+      dpb->num_output_needed++;
+    } else {
+      /* We can do output only when field pair are complete */
+      if (picture->second_field) {
+        dpb->num_output_needed++;
+      }
     }
+  } else {
+    picture->needed_for_output = FALSE;
   }
-}
 
-/**
- * gst_h264_dpb_delete_outputed:
- * @dpb: a #GstH264Dpb
- *
- * Delete already outputted picture, even if they are referenced.
- *
- * Since: 1.18
- */
-void
-gst_h264_dpb_delete_outputed (GstH264Dpb * dpb)
-{
-  gint i;
+  /* Link each field */
+  if (picture->second_field && picture->other_field) {
+    picture->other_field->other_field = picture;
+  }
 
-  g_return_if_fail (dpb != NULL);
+  g_array_append_val (dpb->pic_list, picture);
 
-  for (i = 0; i < dpb->pic_list->len; i++) {
-    GstH264Picture *picture =
-        g_array_index (dpb->pic_list, GstH264Picture *, i);
+  if (dpb->pic_list->len > dpb->max_num_frames * (dpb->interlaced + 1))
+    GST_ERROR ("DPB size is %d, exceed the max size %d",
+        dpb->pic_list->len, dpb->max_num_frames * (dpb->interlaced + 1));
 
-    if (picture->outputted) {
-      GST_TRACE ("remove picture %p (frame num %d) from dpb",
-          picture, picture->frame_num);
-      g_array_remove_index_fast (dpb->pic_list, i);
-      i--;
-    }
+  /* The IDR frame or mem_mgmt_5 */
+  if (picture->pic_order_cnt == 0) {
+    GST_TRACE ("last_output_poc reset because of IDR or mem_mgmt_5");
+    dpb->last_output_poc = G_MININT32;
+    dpb->last_output_non_ref = FALSE;
   }
 }
 
 /**
- * gst_h264_dpb_delete_by_poc:
+ * gst_h264_dpb_delete_unused:
  * @dpb: a #GstH264Dpb
- * @poc: a poc of #GstH264Picture to remove
  *
- * Delete a #GstH264Dpb by @poc
+ * Delete already outputted and not referenced all pictures from dpb
  */
 void
-gst_h264_dpb_delete_by_poc (GstH264Dpb * dpb, gint poc)
+gst_h264_dpb_delete_unused (GstH264Dpb * dpb)
 {
   gint i;
 
@@ -279,26 +329,28 @@ gst_h264_dpb_delete_by_poc (GstH264Dpb * dpb, gint poc)
     GstH264Picture *picture =
         g_array_index (dpb->pic_list, GstH264Picture *, i);
 
-    if (picture->pic_order_cnt == poc) {
-      GST_TRACE ("remove picture %p for poc %d (frame num %d) from dpb",
-          picture, poc, picture->frame_num);
-
-      g_array_remove_index_fast (dpb->pic_list, i);
-      return;
+    /* NOTE: don't use g_array_remove_index_fast here since the last picture
+     * need to be referenced for bumping decision */
+    if (!picture->needed_for_output && !GST_H264_PICTURE_IS_REF (picture)) {
+      GST_TRACE
+          ("remove picture %p (frame num: %d, poc: %d, field: %d) from dpb",
+          picture, picture->frame_num, picture->pic_order_cnt, picture->field);
+      g_array_remove_index (dpb->pic_list, i);
+      i--;
     }
   }
-
-  GST_WARNING ("Couldn't find picture with poc %d", poc);
 }
 
 /**
- * gst_h264_dpb_num_ref_pictures:
+ * gst_h264_dpb_num_ref_frames:
  * @dpb: a #GstH264Dpb
  *
- * Returns: The number of referenced pictures
+ * Returns: The number of referenced frames
+ *
+ * Since: 1.20
  */
 gint
-gst_h264_dpb_num_ref_pictures (GstH264Dpb * dpb)
+gst_h264_dpb_num_ref_frames (GstH264Dpb * dpb)
 {
   gint i;
   gint ret = 0;
@@ -309,7 +361,11 @@ gst_h264_dpb_num_ref_pictures (GstH264Dpb * dpb)
     GstH264Picture *picture =
         g_array_index (dpb->pic_list, GstH264Picture *, i);
 
-    if (picture->ref)
+    /* Count frame, not field picture */
+    if (picture->second_field)
+      continue;
+
+    if (GST_H264_PICTURE_IS_REF (picture))
       ret++;
   }
 
@@ -333,7 +389,7 @@ gst_h264_dpb_mark_all_non_ref (GstH264Dpb * dpb)
     GstH264Picture *picture =
         g_array_index (dpb->pic_list, GstH264Picture *, i);
 
-    picture->ref = FALSE;
+    gst_h264_picture_set_reference (picture, GST_H264_PICTURE_REF_NONE, FALSE);
   }
 }
 
@@ -357,7 +413,8 @@ gst_h264_dpb_get_short_ref_by_pic_num (GstH264Dpb * dpb, gint pic_num)
     GstH264Picture *picture =
         g_array_index (dpb->pic_list, GstH264Picture *, i);
 
-    if (picture->ref && !picture->long_term && picture->pic_num == pic_num)
+    if (GST_H264_PICTURE_IS_SHORT_TERM_REF (picture)
+        && picture->pic_num == pic_num)
       return picture;
   }
 
@@ -367,16 +424,19 @@ gst_h264_dpb_get_short_ref_by_pic_num (GstH264Dpb * dpb, gint pic_num)
 }
 
 /**
- * gst_h264_dpb_get_long_ref_by_pic_num:
+ * gst_h264_dpb_get_long_ref_by_long_term_pic_num:
  * @dpb: a #GstH264Dpb
- * @pic_num: a picture number
+ * @long_term_pic_num: a long term picture number
  *
- * Find a long term reference picture which has matching picture number
+ * Find a long term reference picture which has matching long term picture number
  *
  * Returns: (nullable) (transfer none): a #GstH264Picture
+ *
+ * Since: 1.20
  */
 GstH264Picture *
-gst_h264_dpb_get_long_ref_by_pic_num (GstH264Dpb * dpb, gint pic_num)
+gst_h264_dpb_get_long_ref_by_long_term_pic_num (GstH264Dpb * dpb,
+    gint long_term_pic_num)
 {
   gint i;
 
@@ -386,11 +446,12 @@ gst_h264_dpb_get_long_ref_by_pic_num (GstH264Dpb * dpb, gint pic_num)
     GstH264Picture *picture =
         g_array_index (dpb->pic_list, GstH264Picture *, i);
 
-    if (picture->ref && picture->long_term && picture->pic_num == pic_num)
+    if (GST_H264_PICTURE_IS_LONG_TERM_REF (picture) &&
+        picture->long_term_pic_num == long_term_pic_num)
       return picture;
   }
 
-  GST_WARNING ("No long term reference picture for %d", pic_num);
+  GST_WARNING ("No long term reference picture for %d", long_term_pic_num);
 
   return NULL;
 }
@@ -415,7 +476,7 @@ gst_h264_dpb_get_lowest_frame_num_short_ref (GstH264Dpb * dpb)
     GstH264Picture *picture =
         g_array_index (dpb->pic_list, GstH264Picture *, i);
 
-    if (picture->ref && !picture->long_term &&
+    if (GST_H264_PICTURE_IS_SHORT_TERM_REF (picture) &&
         (!ret || picture->frame_num_wrap < ret->frame_num_wrap))
       ret = picture;
   }
@@ -426,44 +487,22 @@ gst_h264_dpb_get_lowest_frame_num_short_ref (GstH264Dpb * dpb)
   return ret;
 }
 
-/**
- * gst_h264_dpb_get_pictures_not_outputted:
- * @dpb: a #GstH264Dpb
- * @out: (out) (element-type GstH264Picture) (transfer full): an array
- *   of #GstH264Picture pointer
- *
- * Retrieve all not-outputted pictures from @dpb
- */
-void
-gst_h264_dpb_get_pictures_not_outputted (GstH264Dpb * dpb, GArray * out)
-{
-  gint i;
-
-  g_return_if_fail (dpb != NULL);
-  g_return_if_fail (out != NULL);
-
-  for (i = 0; i < dpb->pic_list->len; i++) {
-    GstH264Picture *picture =
-        g_array_index (dpb->pic_list, GstH264Picture *, i);
-
-    if (!picture->outputted) {
-      gst_h264_picture_ref (picture);
-      g_array_append_val (out, picture);
-    }
-  }
-}
-
 /**
  * gst_h264_dpb_get_pictures_short_term_ref:
  * @dpb: a #GstH264Dpb
+ * @include_non_existing: %TRUE if non-existing pictures need to be included
+ * @include_second_field: %TRUE if the second field pictures need to be included
  * @out: (out) (element-type GstH264Picture) (transfer full): an array
  *   of #GstH264Picture pointers
  *
  * Retrieve all short-term reference pictures from @dpb. The picture will be
  * appended to the array.
+ *
+ * Since: 1.20
  */
 void
-gst_h264_dpb_get_pictures_short_term_ref (GstH264Dpb * dpb, GArray * out)
+gst_h264_dpb_get_pictures_short_term_ref (GstH264Dpb * dpb,
+    gboolean include_non_existing, gboolean include_second_field, GArray * out)
 {
   gint i;
 
@@ -474,7 +513,12 @@ gst_h264_dpb_get_pictures_short_term_ref (GstH264Dpb * dpb, GArray * out)
     GstH264Picture *picture =
         g_array_index (dpb->pic_list, GstH264Picture *, i);
 
-    if (picture->ref && !picture->long_term) {
+    if (!include_second_field && picture->second_field)
+      continue;
+
+    if (GST_H264_PICTURE_IS_SHORT_TERM_REF (picture) &&
+        (include_non_existing || (!include_non_existing &&
+                !picture->nonexisting))) {
       gst_h264_picture_ref (picture);
       g_array_append_val (out, picture);
     }
@@ -484,14 +528,18 @@ gst_h264_dpb_get_pictures_short_term_ref (GstH264Dpb * dpb, GArray * out)
 /**
  * gst_h264_dpb_get_pictures_long_term_ref:
  * @dpb: a #GstH264Dpb
- * @out: (out) (element-type GstH264Picture) (transfer full): an arrat
+ * @include_second_field: %TRUE if the second field pictures need to be included
+ * @out: (out) (element-type GstH264Picture) (transfer full): an array
  *   of #GstH264Picture pointer
  *
  * Retrieve all long-term reference pictures from @dpb. The picture will be
  * appended to the array.
+ *
+ * Since: 1.20
  */
 void
-gst_h264_dpb_get_pictures_long_term_ref (GstH264Dpb * dpb, GArray * out)
+gst_h264_dpb_get_pictures_long_term_ref (GstH264Dpb * dpb,
+    gboolean include_second_field, GArray * out)
 {
   gint i;
 
@@ -502,7 +550,10 @@ gst_h264_dpb_get_pictures_long_term_ref (GstH264Dpb * dpb, GArray * out)
     GstH264Picture *picture =
         g_array_index (dpb->pic_list, GstH264Picture *, i);
 
-    if (picture->ref && picture->long_term) {
+    if (!include_second_field && picture->second_field)
+      continue;
+
+    if (GST_H264_PICTURE_IS_LONG_TERM_REF (picture)) {
       gst_h264_picture_ref (picture);
       g_array_append_val (out, picture);
     }
@@ -538,20 +589,6 @@ gst_h264_dpb_get_size (GstH264Dpb * dpb)
   return dpb->pic_list->len;
 }
 
-/**
- * gst_h264_dpb_is_full:
- * @dpb: a #GstH264Dpb
- *
- * Return: %TRUE if @dpb is full
- */
-gboolean
-gst_h264_dpb_is_full (GstH264Dpb * dpb)
-{
-  g_return_val_if_fail (dpb != NULL, -1);
-
-  return dpb->pic_list->len >= dpb->max_num_pics;
-}
-
 /**
  * gst_h264_dpb_get_picture:
  * @dpb: a #GstH264Dpb
@@ -582,3 +619,601 @@ gst_h264_dpb_get_picture (GstH264Dpb * dpb, guint32 system_frame_number)
 
   return NULL;
 }
+
+/**
+ * gst_h264_dpb_has_empty_frame_buffer:
+ * @dpb: a #GstH264Dpb
+ *
+ * Returns: %TRUE if @dpb still has empty frame buffers.
+ *
+ * Since: 1.20
+ */
+gboolean
+gst_h264_dpb_has_empty_frame_buffer (GstH264Dpb * dpb)
+{
+  if (!dpb->interlaced) {
+    if (dpb->pic_list->len < dpb->max_num_frames)
+      return TRUE;
+  } else {
+    gint i;
+    gint count = 0;
+    /* Count the number of complementary field pairs */
+    for (i = 0; i < dpb->pic_list->len; i++) {
+      GstH264Picture *picture =
+          g_array_index (dpb->pic_list, GstH264Picture *, i);
+
+      if (picture->second_field)
+        continue;
+
+      if (GST_H264_PICTURE_IS_FRAME (picture) || picture->other_field)
+        count++;
+    }
+
+    if (count < dpb->max_num_frames)
+      return TRUE;
+  }
+
+  return FALSE;
+}
+
+static gint
+gst_h264_dpb_get_lowest_output_needed_picture (GstH264Dpb * dpb,
+    GstH264Picture ** picture)
+{
+  gint i;
+  GstH264Picture *lowest = NULL;
+  gint index = -1;
+
+  *picture = NULL;
+
+  for (i = 0; i < dpb->pic_list->len; i++) {
+    GstH264Picture *picture =
+        g_array_index (dpb->pic_list, GstH264Picture *, i);
+
+    if (!picture->needed_for_output)
+      continue;
+
+    if (!GST_H264_PICTURE_IS_FRAME (picture) &&
+        (!picture->other_field || picture->second_field))
+      continue;
+
+    if (!lowest) {
+      lowest = picture;
+      index = i;
+      continue;
+    }
+
+    if (picture->pic_order_cnt < lowest->pic_order_cnt) {
+      lowest = picture;
+      index = i;
+    }
+  }
+
+  if (lowest)
+    *picture = gst_h264_picture_ref (lowest);
+
+  return index;
+}
+
+/**
+ * gst_h264_dpb_needs_bump:
+ * @dpb: a #GstH264Dpb
+ * @to_insert: the current #GstH264Picture to insert to dpb.
+ * @latency_mode: The required #GstH264DpbBumpMode for bumping.
+ *
+ * Returns: %TRUE if bumping is required
+ *
+ * Since: 1.20
+ */
+gboolean
+gst_h264_dpb_needs_bump (GstH264Dpb * dpb, GstH264Picture * to_insert,
+    GstH264DpbBumpMode latency_mode)
+{
+  GstH264Picture *picture = NULL;
+  gint32 lowest_poc;
+  gboolean is_ref_picture;
+  gint lowest_index;
+
+  g_return_val_if_fail (dpb != NULL, FALSE);
+  g_assert (dpb->num_output_needed >= 0);
+
+  lowest_poc = G_MAXINT32;
+  is_ref_picture = FALSE;
+  lowest_index = gst_h264_dpb_get_lowest_output_needed_picture (dpb, &picture);
+  if (lowest_index >= 0) {
+    lowest_poc = picture->pic_order_cnt;
+    is_ref_picture = picture->ref_pic;
+    gst_h264_picture_unref (picture);
+  } else {
+    goto normal_bump;
+  }
+
+  if (latency_mode >= GST_H264_DPB_BUMP_LOW_LATENCY) {
+    /* If low latency, we should not wait for the DPB becoming full.
+       We try to bump the picture as soon as possible without the
+       frames disorder. The policy is from the safe to some risk. */
+
+    /* Do not support interlaced mode. */
+    if (gst_h264_dpb_get_interlaced (dpb))
+      goto normal_bump;
+
+    /* Equal to normal bump. */
+    if (!gst_h264_dpb_has_empty_frame_buffer (dpb))
+      goto normal_bump;
+
+    /* 7.4.1.2.2: The values of picture order count for the coded pictures
+       in consecutive access units in decoding order containing non-reference
+       pictures shall be non-decreasing. Safe. */
+    if (dpb->last_output_non_ref && !is_ref_picture) {
+      g_assert (dpb->last_output_poc < G_MAXINT32);
+      GST_TRACE ("Continuous non-reference frame poc: %d -> %d,"
+          " bumping for low-latency.", dpb->last_output_poc, lowest_poc);
+      return TRUE;
+    }
+
+    /* num_reorder_frames indicates the maximum number of frames, that
+       precede any frame in the coded video sequence in decoding order
+       and follow it in output order. Safe. */
+    if (lowest_index >= dpb->max_num_reorder_frames) {
+      guint i, need_output;
+
+      need_output = 0;
+      for (i = 0; i < lowest_index; i++) {
+        GstH264Picture *p = g_array_index (dpb->pic_list, GstH264Picture *, i);
+        if (p->needed_for_output)
+          need_output++;
+      }
+
+      if (need_output >= dpb->max_num_reorder_frames) {
+        GST_TRACE ("frame with lowest poc %d has %d precede frame, already"
+            " satisfy num_reorder_frames %d, bumping for low-latency.",
+            dpb->last_output_poc, lowest_index, dpb->max_num_reorder_frames);
+        return TRUE;
+      }
+    }
+
+    /* Bump leading picture with the negative POC if already found positive
+       POC. It's even impossible to insert another negative POC after the
+       positive POCs. Almost safe. */
+    if (to_insert && to_insert->pic_order_cnt > 0 && lowest_poc < 0) {
+      GST_TRACE ("The negative poc %d, bumping for low-latency.", lowest_poc);
+      return TRUE;
+    }
+
+    /* There may be leading frames with negative POC following the IDR
+       frame in decoder order, so when IDR comes, we need to check the
+       following pictures. In most cases, leading pictures are in increasing
+       POC order. Bump and should be safe. */
+    if (lowest_poc == 0 && gst_h264_dpb_get_size (dpb) <= 1) {
+      if (to_insert && to_insert->pic_order_cnt > lowest_poc) {
+        GST_TRACE ("The IDR or mem_mgmt_5 frame, bumping for low-latency.");
+        return TRUE;
+      }
+
+      GST_TRACE ("The IDR or mem_mgmt_5 frame is not the first frame.");
+      goto normal_bump;
+    }
+
+    /* When non-ref frame has the lowest POC, it's unlike to insert another
+       ref frame with very small POC. Bump and should be safe. */
+    if (!is_ref_picture) {
+      GST_TRACE ("non ref with lowest-poc: %d bumping for low-latency",
+          lowest_poc);
+      return TRUE;
+    }
+
+    /* When insert non-ref frame with bigger POC, it's unlike to insert
+       another ref frame with very small POC. Bump and should be safe. */
+    if (to_insert && !to_insert->ref_pic
+        && lowest_poc < to_insert->pic_order_cnt) {
+      GST_TRACE ("lowest-poc: %d < to insert non ref pic: %d, bumping "
+          "for low-latency", lowest_poc, to_insert->pic_order_cnt);
+      return TRUE;
+    }
+
+    if (latency_mode >= GST_H264_DPB_BUMP_VERY_LOW_LATENCY) {
+      /* PicOrderCnt increment by <=2. Not all streams meet this, but in
+         practice this condition can be used.
+         For stream with 2 poc increment like:
+         0(IDR), 2(P), 4(P), 6(P), 12(P), 8(B), 10(B)....
+         This can work well, but for streams with 1 poc increment like:
+         0(IDR), 2(P), 4(P), 1(B), 3(B) ...
+         This can cause picture disorder. Most stream in practice has the
+         2 poc increment, but this may have risk and be careful. */
+      if (lowest_poc > dpb->last_output_poc
+          && lowest_poc - dpb->last_output_poc <= 2) {
+        GST_TRACE ("lowest-poc: %d, last-output-poc: %d, diff <= 2, "
+            "bumping for very-low-latency", lowest_poc, dpb->last_output_poc);
+        return TRUE;
+      }
+    }
+  }
+
+normal_bump:
+  /* C.4.5.3: The "bumping" process is invoked in the following cases.
+     - There is no empty frame buffer and a empty frame buffer is needed
+     for storage of an inferred "non-existing" frame.
+     - There is no empty frame buffer and an empty frame buffer is needed
+     for storage of a decoded (non-IDR) reference picture.
+     - There is no empty frame buffer and the current picture is a non-
+     reference picture that is not the second field of a complementary
+     non-reference field pair and there are pictures in the DPB that are
+     marked as "needed for output" that precede the current non-reference
+     picture in output order. */
+  if (gst_h264_dpb_has_empty_frame_buffer (dpb)) {
+    GST_TRACE ("DPB has empty frame buffer, no need bumping.");
+    return FALSE;
+  }
+
+  if (to_insert && to_insert->ref_pic) {
+    GST_TRACE ("No empty frame buffer for ref frame, need bumping.");
+    return TRUE;
+  }
+
+  if (to_insert && to_insert->pic_order_cnt > lowest_poc) {
+    GST_TRACE ("No empty frame buffer, lowest poc %d < current poc %d,"
+        " need bumping.", lowest_poc, to_insert->pic_order_cnt);
+    return TRUE;
+  }
+
+  GST_TRACE ("No empty frame buffer, but lowest poc %d > current poc %d,"
+      " no need bumping.", lowest_poc, to_insert->pic_order_cnt);
+
+  return FALSE;
+}
+
+/**
+ * gst_h264_dpb_bump:
+ * @dpb: a #GstH265Dpb
+ * @drain: whether draining or not
+ *
+ * Perform bumping process as defined in C.4.5.3 "Bumping" process.
+ * If @drain is %TRUE, @dpb will remove a #GstH264Picture from internal array
+ * so that returned #GstH264Picture could hold the last reference of it
+ *
+ * Returns: (nullable) (transfer full): a #GstH264Picture which is needed to be
+ * outputted
+ *
+ * Since: 1.20
+ */
+GstH264Picture *
+gst_h264_dpb_bump (GstH264Dpb * dpb, gboolean drain)
+{
+  GstH264Picture *picture;
+  GstH264Picture *other_picture;
+  gint i;
+  gint index;
+
+  g_return_val_if_fail (dpb != NULL, NULL);
+
+  index = gst_h264_dpb_get_lowest_output_needed_picture (dpb, &picture);
+
+  if (!picture || index < 0)
+    return NULL;
+
+  picture->needed_for_output = FALSE;
+
+  dpb->num_output_needed--;
+  g_assert (dpb->num_output_needed >= 0);
+
+  /* NOTE: don't use g_array_remove_index_fast here since the last picture
+   * need to be referenced for bumping decision */
+  if (!GST_H264_PICTURE_IS_REF (picture) || drain)
+    g_array_remove_index (dpb->pic_list, index);
+
+  other_picture = picture->other_field;
+  if (other_picture) {
+    other_picture->needed_for_output = FALSE;
+
+    /* At this moment, this picture should be interlaced */
+    picture->buffer_flags |= GST_VIDEO_BUFFER_FLAG_INTERLACED;
+
+    /* FIXME: need to check picture timing SEI for the case where top/bottom poc
+     * are identical */
+    if (picture->pic_order_cnt < other_picture->pic_order_cnt)
+      picture->buffer_flags |= GST_VIDEO_BUFFER_FLAG_TFF;
+
+    if (!other_picture->ref) {
+      for (i = 0; i < dpb->pic_list->len; i++) {
+        GstH264Picture *tmp =
+            g_array_index (dpb->pic_list, GstH264Picture *, i);
+
+        if (tmp == other_picture) {
+          g_array_remove_index (dpb->pic_list, i);
+          break;
+        }
+      }
+    }
+    /* Now other field may or may not exist */
+  }
+
+  dpb->last_output_poc = picture->pic_order_cnt;
+  dpb->last_output_non_ref = !picture->ref_pic;
+
+  return picture;
+}
+
+/**
+ * gst_h264_dpb_set_last_output:
+ * @dpb: a #GstH264Dpb
+ * @picture: a #GstH264Picture of the last output.
+ *
+ * Notify the DPB that @picture is output directly without storing
+ * in the DPB.
+ *
+ * Since: 1.20
+ */
+void
+gst_h264_dpb_set_last_output (GstH264Dpb * dpb, GstH264Picture * picture)
+{
+  g_return_if_fail (dpb != NULL);
+  g_return_if_fail (GST_IS_H264_PICTURE (picture));
+
+  dpb->last_output_poc = picture->pic_order_cnt;
+  dpb->last_output_non_ref = !picture->ref_pic;
+}
+
+static gint
+get_picNumX (GstH264Picture * picture, GstH264RefPicMarking * ref_pic_marking)
+{
+  return picture->pic_num -
+      (ref_pic_marking->difference_of_pic_nums_minus1 + 1);
+}
+
+/**
+ * gst_h264_dpb_perform_memory_management_control_operation:
+ * @dpb: a #GstH265Dpb
+ * @ref_pic_marking: a #GstH264RefPicMarking
+ * @picture: a #GstH264Picture
+ *
+ * Perform "8.2.5.4 Adaptive memory control decoded reference picture marking process"
+ *
+ * Returns: %TRUE if successful
+ *
+ * Since: 1.20
+ */
+gboolean
+gst_h264_dpb_perform_memory_management_control_operation (GstH264Dpb * dpb,
+    GstH264RefPicMarking * ref_pic_marking, GstH264Picture * picture)
+{
+  guint8 type;
+  gint pic_num_x;
+  gint max_long_term_frame_idx;
+  GstH264Picture *other;
+  gint i;
+
+  g_return_val_if_fail (dpb != NULL, FALSE);
+  g_return_val_if_fail (ref_pic_marking != NULL, FALSE);
+  g_return_val_if_fail (picture != NULL, FALSE);
+
+  type = ref_pic_marking->memory_management_control_operation;
+
+  switch (type) {
+    case 0:
+      /* Normal end of operations' specification */
+      break;
+    case 1:
+      /* 8.2.5.4.1 Mark a short term reference picture as unused so it can be
+       * removed if outputted */
+      pic_num_x = get_picNumX (picture, ref_pic_marking);
+      other = gst_h264_dpb_get_short_ref_by_pic_num (dpb, pic_num_x);
+      if (other) {
+        gst_h264_picture_set_reference (other,
+            GST_H264_PICTURE_REF_NONE, GST_H264_PICTURE_IS_FRAME (picture));
+        GST_TRACE ("MMCO-1: unmark short-term ref picture %p, (poc %d)",
+            other, other->pic_order_cnt);
+      } else {
+        GST_WARNING ("Invalid picNumX %d for operation type 1", pic_num_x);
+        return FALSE;
+      }
+      break;
+    case 2:
+      /* 8.2.5.4.2 Mark a long term reference picture as unused so it can be
+       * removed if outputted */
+      other = gst_h264_dpb_get_long_ref_by_long_term_pic_num (dpb,
+          ref_pic_marking->long_term_pic_num);
+      if (other) {
+        gst_h264_picture_set_reference (other,
+            GST_H264_PICTURE_REF_NONE, FALSE);
+        GST_TRACE ("MMCO-2: unmark long-term ref picture %p, (poc %d)",
+            other, other->pic_order_cnt);
+      } else {
+        GST_WARNING ("Invalid LongTermPicNum %d for operation type 2",
+            ref_pic_marking->long_term_pic_num);
+        return FALSE;
+      }
+      break;
+    case 3:
+      /* 8.2.5.4.3 Mark a short term reference picture as long term reference */
+
+      pic_num_x = get_picNumX (picture, ref_pic_marking);
+
+      other = gst_h264_dpb_get_short_ref_by_pic_num (dpb, pic_num_x);
+      if (!other) {
+        GST_WARNING ("Invalid picNumX %d for operation type 3", pic_num_x);
+        return FALSE;
+      }
+
+      /* If we have long-term ref picture for LongTermFrameIdx,
+       * mark the picture as non-reference */
+      for (i = 0; i < dpb->pic_list->len; i++) {
+        GstH264Picture *tmp =
+            g_array_index (dpb->pic_list, GstH264Picture *, i);
+
+        if (GST_H264_PICTURE_IS_LONG_TERM_REF (tmp)
+            && tmp->long_term_frame_idx == ref_pic_marking->long_term_frame_idx) {
+          if (GST_H264_PICTURE_IS_FRAME (tmp)) {
+            /* When long_term_frame_idx is already assigned to a long-term
+             * reference frame, that frame is marked as "unused for reference"
+             */
+            gst_h264_picture_set_reference (tmp,
+                GST_H264_PICTURE_REF_NONE, TRUE);
+            GST_TRACE ("MMCO-3: unmark old long-term frame %p (poc %d)",
+                tmp, tmp->pic_order_cnt);
+          } else if (tmp->other_field &&
+              GST_H264_PICTURE_IS_LONG_TERM_REF (tmp->other_field) &&
+              tmp->other_field->long_term_frame_idx ==
+              ref_pic_marking->long_term_frame_idx) {
+            /* When long_term_frame_idx is already assigned to a long-term
+             * reference field pair, that complementary field pair and both of
+             * its fields are marked as "unused for reference"
+             */
+            gst_h264_picture_set_reference (tmp,
+                GST_H264_PICTURE_REF_NONE, TRUE);
+            GST_TRACE ("MMCO-3: unmark old long-term field-pair %p (poc %d)",
+                tmp, tmp->pic_order_cnt);
+          } else {
+            /* When long_term_frame_idx is already assigned to a reference field,
+             * and that reference field is not part of a complementary field
+             * pair that includes the picture specified by picNumX,
+             * that field is marked as "unused for reference"
+             */
+
+            /* Check "tmp" (a long-term ref pic) is part of
+             * "other" (a picture to be updated from short-term to long-term)
+             * complementary field pair */
+
+            /* NOTE: "other" here is short-ref, so "other" and "tmp" must not be
+             * identical picture */
+            if (!tmp->other_field) {
+              gst_h264_picture_set_reference (tmp,
+                  GST_H264_PICTURE_REF_NONE, FALSE);
+              GST_TRACE ("MMCO-3: unmark old long-term field %p (poc %d)",
+                  tmp, tmp->pic_order_cnt);
+            } else if (tmp->other_field != other &&
+                (!other->other_field || other->other_field != tmp)) {
+              gst_h264_picture_set_reference (tmp,
+                  GST_H264_PICTURE_REF_NONE, FALSE);
+              GST_TRACE ("MMCO-3: unmark old long-term field %p (poc %d)",
+                  tmp, tmp->pic_order_cnt);
+            }
+          }
+          break;
+        }
+      }
+
+      gst_h264_picture_set_reference (other,
+          GST_H264_PICTURE_REF_LONG_TERM, GST_H264_PICTURE_IS_FRAME (picture));
+      other->long_term_frame_idx = ref_pic_marking->long_term_frame_idx;
+
+      GST_TRACE ("MMCO-3: mark long-term ref pic %p, index %d, (poc %d)",
+          other, other->long_term_frame_idx, other->pic_order_cnt);
+
+      if (other->other_field &&
+          GST_H264_PICTURE_IS_LONG_TERM_REF (other->other_field)) {
+        other->other_field->long_term_frame_idx =
+            ref_pic_marking->long_term_frame_idx;
+      }
+      break;
+    case 4:
+      /* 8.2.5.4.4  All pictures for which LongTermFrameIdx is greater than
+       * max_long_term_frame_idx_plus1  1 and that are marked as
+       * "used for long-term reference" are marked as "unused for reference */
+      max_long_term_frame_idx =
+          ref_pic_marking->max_long_term_frame_idx_plus1 - 1;
+
+      GST_TRACE ("MMCO-4: max_long_term_frame_idx %d", max_long_term_frame_idx);
+
+      for (i = 0; i < dpb->pic_list->len; i++) {
+        other = g_array_index (dpb->pic_list, GstH264Picture *, i);
+
+        if (GST_H264_PICTURE_IS_LONG_TERM_REF (other) &&
+            other->long_term_frame_idx > max_long_term_frame_idx) {
+          gst_h264_picture_set_reference (other,
+              GST_H264_PICTURE_REF_NONE, FALSE);
+          GST_TRACE ("MMCO-4: unmark long-term ref pic %p, index %d, (poc %d)",
+              other, other->long_term_frame_idx, other->pic_order_cnt);
+        }
+      }
+      break;
+    case 5:
+      /* 8.2.5.4.5 Unmark all reference pictures */
+      for (i = 0; i < dpb->pic_list->len; i++) {
+        other = g_array_index (dpb->pic_list, GstH264Picture *, i);
+        gst_h264_picture_set_reference (other,
+            GST_H264_PICTURE_REF_NONE, FALSE);
+      }
+      picture->mem_mgmt_5 = TRUE;
+      picture->frame_num = 0;
+      /* When the current picture includes a memory management control operation
+         equal to 5, after the decoding of the current picture, tempPicOrderCnt
+         is set equal to PicOrderCnt( CurrPic ), TopFieldOrderCnt of the current
+         picture (if any) is set equal to TopFieldOrderCnt - tempPicOrderCnt,
+         and BottomFieldOrderCnt of the current picture (if any) is set equal to
+         BottomFieldOrderCnt - tempPicOrderCnt. */
+      if (picture->field == GST_H264_PICTURE_FIELD_TOP_FIELD) {
+        picture->top_field_order_cnt = picture->pic_order_cnt = 0;
+      } else if (picture->field == GST_H264_PICTURE_FIELD_BOTTOM_FIELD) {
+        picture->bottom_field_order_cnt = picture->pic_order_cnt = 0;
+      } else {
+        picture->top_field_order_cnt -= picture->pic_order_cnt;
+        picture->bottom_field_order_cnt -= picture->pic_order_cnt;
+        picture->pic_order_cnt = MIN (picture->top_field_order_cnt,
+            picture->bottom_field_order_cnt);
+      }
+      break;
+    case 6:
+      /* 8.2.5.4.6 Replace long term reference pictures with current picture.
+       * First unmark if any existing with this long_term_frame_idx */
+
+      /* If we have long-term ref picture for LongTermFrameIdx,
+       * mark the picture as non-reference */
+      for (i = 0; i < dpb->pic_list->len; i++) {
+        other = g_array_index (dpb->pic_list, GstH264Picture *, i);
+
+        if (GST_H264_PICTURE_IS_LONG_TERM_REF (other) &&
+            other->long_term_frame_idx ==
+            ref_pic_marking->long_term_frame_idx) {
+          GST_TRACE ("MMCO-6: unmark old long-term ref pic %p (poc %d)",
+              other, other->pic_order_cnt);
+          gst_h264_picture_set_reference (other,
+              GST_H264_PICTURE_REF_NONE, TRUE);
+          break;
+        }
+      }
+
+      gst_h264_picture_set_reference (picture,
+          GST_H264_PICTURE_REF_LONG_TERM, picture->second_field);
+      picture->long_term_frame_idx = ref_pic_marking->long_term_frame_idx;
+      if (picture->other_field &&
+          GST_H264_PICTURE_IS_LONG_TERM_REF (picture->other_field)) {
+        picture->other_field->long_term_frame_idx =
+            ref_pic_marking->long_term_frame_idx;
+      }
+      break;
+    default:
+      g_assert_not_reached ();
+      return FALSE;
+  }
+
+  return TRUE;
+}
+
+/**
+ * gst_h264_picture_set_reference:
+ * @picture: a #GstH264Picture
+ * @reference: a GstH264PictureReference
+ * @other_field: %TRUE if @reference needs to be applied to the
+ * other field if any
+ *
+ * Update reference picture type of @picture with @reference
+ *
+ * Since: 1.20
+ */
+void
+gst_h264_picture_set_reference (GstH264Picture * picture,
+    GstH264PictureReference reference, gboolean other_field)
+{
+  g_return_if_fail (picture != NULL);
+
+  picture->ref = reference;
+  if (reference > GST_H264_PICTURE_REF_NONE)
+    picture->ref_pic = TRUE;
+
+  if (other_field && picture->other_field) {
+    picture->other_field->ref = reference;
+
+    if (reference > GST_H264_PICTURE_REF_NONE)
+      picture->other_field->ref_pic = TRUE;
+  }
+}
diff --git a/gst-libs/gst/codecs/gsth264picture.h b/gst-libs/gst/codecs/gsth264picture.h
index 27d237dd2..a028c00b1 100644
--- a/gst-libs/gst/codecs/gsth264picture.h
+++ b/gst-libs/gst/codecs/gsth264picture.h
@@ -21,8 +21,8 @@
 #define __GST_H264_PICTURE_H__
 
 #include <gst/codecs/codecs-prelude.h>
-
 #include <gst/codecparsers/gsth264parser.h>
+#include <gst/video/video.h>
 
 G_BEGIN_DECLS
 
@@ -37,6 +37,50 @@ typedef struct _GstH264Picture GstH264Picture;
 /* As specified in A.3.1 h) and A.3.2 f) */
 #define GST_H264_DPB_MAX_SIZE 16
 
+/**
+ * GST_H264_PICTURE_IS_REF:
+ * @picture: a #GstH264Picture
+ *
+ * Check whether @picture is used for short-term or long-term reference
+ *
+ * Since: 1.20
+ */
+#define GST_H264_PICTURE_IS_REF(picture) \
+    ((picture)->ref != GST_H264_PICTURE_REF_NONE)
+
+/**
+ * GST_H264_PICTURE_IS_SHORT_TERM_REF:
+ * @picture: a #GstH264Picture
+ *
+ * Check whether @picture is used for short-term reference
+ *
+ * Since: 1.20
+ */
+#define GST_H264_PICTURE_IS_SHORT_TERM_REF(picture) \
+    ((picture)->ref == GST_H264_PICTURE_REF_SHORT_TERM)
+
+/**
+ * GST_H264_PICTURE_IS_LONG_TERM_REF:
+ * @picture: a #GstH264Picture
+ *
+ * Check whether @picture is used for long-term reference
+ *
+ * Since: 1.20
+ */
+#define GST_H264_PICTURE_IS_LONG_TERM_REF(picture) \
+    ((picture)->ref == GST_H264_PICTURE_REF_LONG_TERM)
+
+/**
+ * GST_H264_PICTURE_IS_FRAME:
+ * @picture: a #GstH264Picture
+ *
+ * Check whether @picture is a frame (not a field picture)
+ *
+ * Since: 1.20
+ */
+#define GST_H264_PICTURE_IS_FRAME(picture) \
+    ((picture)->field == GST_H264_PICTURE_FIELD_FRAME)
+
 struct _GstH264Slice
 {
   GstH264SliceHdr header;
@@ -52,13 +96,28 @@ typedef enum
   GST_H264_PICTURE_FIELD_BOTTOM_FIELD,
 } GstH264PictureField;
 
+/**
+ * GstH264PictureReference:
+ * @GST_H264_PICTURE_REF_NONE: Not used for reference picture
+ * @GST_H264_PICTURE_REF_SHORT_TERM: Used for short-term reference picture
+ * @GST_H264_PICTURE_REF_LONG_TERM: Used for long-term reference picture
+ *
+ * Since: 1.20
+ */
+typedef enum
+{
+  GST_H264_PICTURE_REF_NONE = 0,
+  GST_H264_PICTURE_REF_SHORT_TERM,
+  GST_H264_PICTURE_REF_LONG_TERM,
+} GstH264PictureReference;
+
 struct _GstH264Picture
 {
+  /*< private >*/
   GstMiniObject parent;
 
   GstH264SliceType type;
 
-  GstClockTime pts;
   /* From GstVideoCodecFrame */
   guint32 system_frame_number;
 
@@ -83,9 +142,10 @@ struct _GstH264Picture
   gint nal_ref_idc;
   gboolean idr;
   gint idr_pic_id;
-  gboolean ref;
-  gboolean long_term;
-  gboolean outputted;
+  GstH264PictureReference ref;
+  /* Whether a reference picture. */
+  gboolean ref_pic;
+  gboolean needed_for_output;
   gboolean mem_mgmt_5;
 
   gboolean nonexisting;
@@ -94,10 +154,31 @@ struct _GstH264Picture
 
   GstH264DecRefPicMarking dec_ref_pic_marking;
 
+  /* For interlaced decoding */
+  gboolean second_field;
+  GstH264Picture * other_field;
+
+  GstVideoBufferFlags buffer_flags;
+
   gpointer user_data;
   GDestroyNotify notify;
 };
 
+/**
+ * GstH264DpbBumpMode:
+ * @GST_H264_DPB_BUMP_NORMAL_LATENCY: No latency requirement for DBP bumping.
+ * @GST_H264_DPB_BUMP_LOW_LATENCY: Low-latency requirement for DBP bumping.
+ * @GST_H264_DPB_BUMP_VERY_LOW_LATENCY: Very low-latency requirement for DBP bumping.
+ *
+ * Since: 1.20
+ */
+typedef enum
+{
+  GST_H264_DPB_BUMP_NORMAL_LATENCY,
+  GST_H264_DPB_BUMP_LOW_LATENCY,
+  GST_H264_DPB_BUMP_VERY_LOW_LATENCY
+} GstH264DpbBumpMode;
+
 GST_CODECS_API
 GType gst_h264_picture_get_type (void);
 
@@ -150,11 +231,22 @@ GST_CODECS_API
 GstH264Dpb * gst_h264_dpb_new (void);
 
 GST_CODECS_API
-void  gst_h264_dpb_set_max_num_pics (GstH264Dpb * dpb,
-                                     gint max_num_pics);
+void  gst_h264_dpb_set_max_num_frames (GstH264Dpb * dpb,
+                                       gint max_num_frames);
+
+GST_CODECS_API
+gint gst_h264_dpb_get_max_num_frames  (GstH264Dpb * dpb);
+
+GST_CODECS_API
+void gst_h264_dpb_set_interlaced      (GstH264Dpb * dpb,
+                                       gboolean interlaced);
 
 GST_CODECS_API
-gint gst_h264_dpb_get_max_num_pics  (GstH264Dpb * dpb);
+void gst_h264_dpb_set_max_num_reorder_frames (GstH264Dpb * dpb,
+                                              guint32 max_num_reorder_frames);
+
+GST_CODECS_API
+gboolean gst_h264_dpb_get_interlaced  (GstH264Dpb * dpb);
 
 GST_CODECS_API
 void  gst_h264_dpb_free             (GstH264Dpb * dpb);
@@ -170,14 +262,7 @@ GST_CODECS_API
 void  gst_h264_dpb_delete_unused    (GstH264Dpb * dpb);
 
 GST_CODECS_API
-void gst_h264_dpb_delete_outputed   (GstH264Dpb * dpb);
-
-GST_CODECS_API
-void  gst_h264_dpb_delete_by_poc    (GstH264Dpb * dpb,
-                                     gint poc);
-
-GST_CODECS_API
-gint  gst_h264_dpb_num_ref_pictures (GstH264Dpb * dpb);
+gint  gst_h264_dpb_num_ref_frames (GstH264Dpb * dpb);
 
 GST_CODECS_API
 void  gst_h264_dpb_mark_all_non_ref (GstH264Dpb * dpb);
@@ -187,22 +272,21 @@ GstH264Picture * gst_h264_dpb_get_short_ref_by_pic_num (GstH264Dpb * dpb,
                                                         gint pic_num);
 
 GST_CODECS_API
-GstH264Picture * gst_h264_dpb_get_long_ref_by_pic_num  (GstH264Dpb * dpb,
-                                                        gint pic_num);
+GstH264Picture * gst_h264_dpb_get_long_ref_by_long_term_pic_num (GstH264Dpb * dpb,
+                                                                 gint long_term_pic_num);
 
 GST_CODECS_API
 GstH264Picture * gst_h264_dpb_get_lowest_frame_num_short_ref (GstH264Dpb * dpb);
 
-GST_CODECS_API
-void  gst_h264_dpb_get_pictures_not_outputted  (GstH264Dpb * dpb,
-                                                GArray * out);
-
 GST_CODECS_API
 void  gst_h264_dpb_get_pictures_short_term_ref (GstH264Dpb * dpb,
+                                                gboolean include_non_existing,
+                                                gboolean include_second_field,
                                                 GArray * out);
 
 GST_CODECS_API
 void  gst_h264_dpb_get_pictures_long_term_ref  (GstH264Dpb * dpb,
+                                                gboolean include_second_field,
                                                 GArray * out);
 
 GST_CODECS_API
@@ -216,7 +300,30 @@ GST_CODECS_API
 gint  gst_h264_dpb_get_size   (GstH264Dpb * dpb);
 
 GST_CODECS_API
-gboolean gst_h264_dpb_is_full (GstH264Dpb * dpb);
+gboolean gst_h264_dpb_has_empty_frame_buffer   (GstH264Dpb * dpb);
+
+GST_CODECS_API
+gboolean gst_h264_dpb_needs_bump (GstH264Dpb * dpb,
+                                  GstH264Picture * to_insert,
+                                  GstH264DpbBumpMode latency_mode);
+
+GST_CODECS_API
+GstH264Picture * gst_h264_dpb_bump (GstH264Dpb * dpb,
+                                    gboolean drain);
+
+GST_CODECS_API
+void gst_h264_dpb_set_last_output (GstH264Dpb * dpb,
+                                   GstH264Picture * picture);
+
+GST_CODECS_API
+gboolean         gst_h264_dpb_perform_memory_management_control_operation (GstH264Dpb * dpb,
+                                                                           GstH264RefPicMarking *ref_pic_marking,
+                                                                           GstH264Picture * picture);
+
+/* Internal methods */
+void  gst_h264_picture_set_reference (GstH264Picture * picture,
+                                      GstH264PictureReference reference,
+                                      gboolean other_field);
 
 G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstH264Picture, gst_h264_picture_unref)
 
diff --git a/gst-libs/gst/codecs/gsth265decoder.c b/gst-libs/gst/codecs/gsth265decoder.c
index 033d9f26b..16d4122a2 100644
--- a/gst-libs/gst/codecs/gsth265decoder.c
+++ b/gst-libs/gst/codecs/gsth265decoder.c
@@ -54,6 +54,12 @@ struct _GstH265DecoderPrivate
 {
   gint width, height;
 
+  guint8 conformance_window_flag;
+  gint crop_rect_width;
+  gint crop_rect_height;
+  gint crop_rect_x;
+  gint crop_rect_y;
+
   /* input codec_data, if any */
   GstBuffer *codec_data;
   guint nal_length_size;
@@ -65,19 +71,30 @@ struct _GstH265DecoderPrivate
   GstH265Dpb *dpb;
   GstFlowReturn last_ret;
 
+  /* 0: frame or field-pair interlaced stream
+   * 1: alternating, single field interlaced stream.
+   * When equal to 1, picture timing SEI shall be present in every AU */
+  guint8 field_seq_flag;
+  guint8 progressive_source_flag;
+  guint8 interlaced_source_flag;
+
+  /* Updated/cleared per handle_frame() by using picture timeing SEI */
+  GstH265SEIPicStructType cur_pic_struct;
+  guint8 cur_source_scan_type;
+  guint8 cur_duplicate_flag;
+
   /* vps/sps/pps of the current slice */
   const GstH265VPS *active_vps;
   const GstH265SPS *active_sps;
   const GstH265PPS *active_pps;
 
   guint32 SpsMaxLatencyPictures;
-  gint32 WpOffsetHalfRangeC;
 
   /* Picture currently being processed/decoded */
   GstH265Picture *current_picture;
   GstVideoCodecFrame *current_frame;
 
-  /* Slice (slice header + nalu) currently being processed/decodec */
+  /* Slice (slice header + nalu) currently being processed/decoded */
   GstH265Slice current_slice;
   GstH265Slice prev_slice;
   GstH265Slice prev_independent_slice;
@@ -101,6 +118,12 @@ struct _GstH265DecoderPrivate
   gboolean associated_irap_NoRaslOutputFlag;
   gboolean new_bitstream;
   gboolean prev_nal_is_eos;
+
+  /* Reference picture lists, constructed for each slice */
+  gboolean process_ref_pic_lists;
+  GArray *ref_pic_list_tmp;
+  GArray *ref_pic_list0;
+  GArray *ref_pic_list1;
 };
 
 #define parent_class gst_h265_decoder_parent_class
@@ -110,6 +133,8 @@ G_DEFINE_ABSTRACT_TYPE_WITH_CODE (GstH265Decoder, gst_h265_decoder,
     GST_DEBUG_CATEGORY_INIT (gst_h265_decoder_debug, "h265decoder", 0,
         "H.265 Video Decoder"));
 
+static void gst_h265_decoder_finalize (GObject * object);
+
 static gboolean gst_h265_decoder_start (GstVideoDecoder * decoder);
 static gboolean gst_h265_decoder_stop (GstVideoDecoder * decoder);
 static gboolean gst_h265_decoder_set_format (GstVideoDecoder * decoder,
@@ -121,15 +146,18 @@ static GstFlowReturn gst_h265_decoder_handle_frame (GstVideoDecoder * decoder,
     GstVideoCodecFrame * frame);
 
 static gboolean gst_h265_decoder_finish_current_picture (GstH265Decoder * self);
-static void gst_h265_decoder_clear_dpb (GstH265Decoder * self);
-static gboolean
-gst_h265_decoder_output_all_remaining_pics (GstH265Decoder * self);
+static void gst_h265_decoder_clear_ref_pic_sets (GstH265Decoder * self);
+static void gst_h265_decoder_clear_dpb (GstH265Decoder * self, gboolean flush);
+static gboolean gst_h265_decoder_drain_internal (GstH265Decoder * self);
 static gboolean gst_h265_decoder_start_current_picture (GstH265Decoder * self);
 
 static void
 gst_h265_decoder_class_init (GstH265DecoderClass * klass)
 {
   GstVideoDecoderClass *decoder_class = GST_VIDEO_DECODER_CLASS (klass);
+  GObjectClass *object_class = G_OBJECT_CLASS (klass);
+
+  object_class->finalize = GST_DEBUG_FUNCPTR (gst_h265_decoder_finalize);
 
   decoder_class->start = GST_DEBUG_FUNCPTR (gst_h265_decoder_start);
   decoder_class->stop = GST_DEBUG_FUNCPTR (gst_h265_decoder_stop);
@@ -144,9 +172,33 @@ gst_h265_decoder_class_init (GstH265DecoderClass * klass)
 static void
 gst_h265_decoder_init (GstH265Decoder * self)
 {
+  GstH265DecoderPrivate *priv;
+
   gst_video_decoder_set_packetized (GST_VIDEO_DECODER (self), TRUE);
 
-  self->priv = gst_h265_decoder_get_instance_private (self);
+  self->priv = priv = gst_h265_decoder_get_instance_private (self);
+
+  priv->last_output_poc = G_MININT32;
+
+  priv->ref_pic_list_tmp = g_array_sized_new (FALSE, TRUE,
+      sizeof (GstH265Picture *), 32);
+  priv->ref_pic_list0 = g_array_sized_new (FALSE, TRUE,
+      sizeof (GstH265Picture *), 32);
+  priv->ref_pic_list1 = g_array_sized_new (FALSE, TRUE,
+      sizeof (GstH265Picture *), 32);
+}
+
+static void
+gst_h265_decoder_finalize (GObject * object)
+{
+  GstH265Decoder *self = GST_H265_DECODER (object);
+  GstH265DecoderPrivate *priv = self->priv;
+
+  g_array_unref (priv->ref_pic_list_tmp);
+  g_array_unref (priv->ref_pic_list0);
+  g_array_unref (priv->ref_pic_list1);
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
 }
 
 static gboolean
@@ -186,6 +238,8 @@ gst_h265_decoder_stop (GstVideoDecoder * decoder)
     priv->dpb = NULL;
   }
 
+  gst_h265_decoder_clear_ref_pic_sets (self);
+
   return TRUE;
 }
 
@@ -208,6 +262,25 @@ gst_h265_decoder_parse_vps (GstH265Decoder * self, GstH265NalUnit * nalu)
   return ret;
 }
 
+static gboolean
+gst_h265_decoder_is_crop_rect_changed (GstH265Decoder * self, GstH265SPS * sps)
+{
+  GstH265DecoderPrivate *priv = self->priv;
+
+  if (priv->conformance_window_flag != sps->conformance_window_flag)
+    return TRUE;
+  if (priv->crop_rect_width != sps->crop_rect_width)
+    return TRUE;
+  if (priv->crop_rect_height != sps->crop_rect_height)
+    return TRUE;
+  if (priv->crop_rect_x != sps->crop_rect_x)
+    return TRUE;
+  if (priv->crop_rect_y != sps->crop_rect_y)
+    return TRUE;
+
+  return FALSE;
+}
+
 static gboolean
 gst_h265_decoder_process_sps (GstH265Decoder * self, GstH265SPS * sps)
 {
@@ -217,8 +290,9 @@ gst_h265_decoder_process_sps (GstH265Decoder * self, GstH265SPS * sps)
   gint MaxLumaPS;
   const gint MaxDpbPicBuf = 6;
   gint PicSizeInSamplesY;
-  guint high_precision_offsets_enabled_flag = 0;
-  guint bitdepthC = 0;
+  guint8 field_seq_flag = 0;
+  guint8 progressive_source_flag = 0;
+  guint8 interlaced_source_flag = 0;
 
   /* A.4.1 */
   MaxLumaPS = 35651584;
@@ -234,15 +308,29 @@ gst_h265_decoder_process_sps (GstH265Decoder * self, GstH265SPS * sps)
 
   max_dpb_size = MIN (max_dpb_size, 16);
 
+  if (sps->vui_parameters_present_flag)
+    field_seq_flag = sps->vui_params.field_seq_flag;
+
+  progressive_source_flag = sps->profile_tier_level.progressive_source_flag;
+  interlaced_source_flag = sps->profile_tier_level.interlaced_source_flag;
+
   prev_max_dpb_size = gst_h265_dpb_get_max_num_pics (priv->dpb);
   if (priv->width != sps->width || priv->height != sps->height ||
-      prev_max_dpb_size != max_dpb_size) {
+      prev_max_dpb_size != max_dpb_size ||
+      priv->field_seq_flag != field_seq_flag ||
+      priv->progressive_source_flag != progressive_source_flag ||
+      priv->interlaced_source_flag != interlaced_source_flag ||
+      gst_h265_decoder_is_crop_rect_changed (self, sps)) {
     GstH265DecoderClass *klass = GST_H265_DECODER_GET_CLASS (self);
 
     GST_DEBUG_OBJECT (self,
-        "SPS updated, resolution: %dx%d -> %dx%d, dpb size: %d -> %d",
+        "SPS updated, resolution: %dx%d -> %dx%d, dpb size: %d -> %d, "
+        "field_seq_flag: %d -> %d, progressive_source_flag: %d -> %d, "
+        "interlaced_source_flag: %d -> %d",
         priv->width, priv->height, sps->width, sps->height,
-        prev_max_dpb_size, max_dpb_size);
+        prev_max_dpb_size, max_dpb_size, priv->field_seq_flag, field_seq_flag,
+        priv->progressive_source_flag, progressive_source_flag,
+        priv->interlaced_source_flag, interlaced_source_flag);
 
     g_assert (klass->new_sequence);
 
@@ -253,6 +341,14 @@ gst_h265_decoder_process_sps (GstH265Decoder * self, GstH265SPS * sps)
 
     priv->width = sps->width;
     priv->height = sps->height;
+    priv->conformance_window_flag = sps->conformance_window_flag;
+    priv->crop_rect_width = sps->crop_rect_width;
+    priv->crop_rect_height = sps->crop_rect_height;
+    priv->crop_rect_x = sps->crop_rect_x;
+    priv->crop_rect_y = sps->crop_rect_y;
+    priv->field_seq_flag = field_seq_flag;
+    priv->progressive_source_flag = progressive_source_flag;
+    priv->interlaced_source_flag = interlaced_source_flag;
 
     gst_h265_dpb_set_max_num_pics (priv->dpb, max_dpb_size);
   }
@@ -263,13 +359,6 @@ gst_h265_decoder_process_sps (GstH265Decoder * self, GstH265SPS * sps)
         sps->max_latency_increase_plus1[sps->max_sub_layers_minus1] - 1;
   }
 
-  /* Calculate WpOffsetHalfRangeC: (7-34)
-   * FIXME: We don't have parser API for sps_range_extension, so
-   * assuming high_precision_offsets_enabled_flag as zero */
-  bitdepthC = sps->bit_depth_chroma_minus8 + 8;
-  priv->WpOffsetHalfRangeC =
-      1 << (high_precision_offsets_enabled_flag ? (bitdepthC - 1) : 7);
-
   GST_DEBUG_OBJECT (self, "Set DPB max size %d", max_dpb_size);
 
   return TRUE;
@@ -321,6 +410,169 @@ gst_h265_decoder_parse_pps (GstH265Decoder * self, GstH265NalUnit * nalu)
   return TRUE;
 }
 
+static gboolean
+gst_h265_decoder_parse_sei (GstH265Decoder * self, GstH265NalUnit * nalu)
+{
+  GstH265DecoderPrivate *priv = self->priv;
+  GstH265ParserResult pres;
+  GArray *messages = NULL;
+  guint i;
+
+  pres = gst_h265_parser_parse_sei (priv->parser, nalu, &messages);
+  if (pres != GST_H265_PARSER_OK) {
+    GST_WARNING_OBJECT (self, "Failed to parse SEI, result %d", pres);
+
+    /* XXX: Ignore error from SEI parsing, it might be malformed bitstream,
+     * or our fault. But shouldn't be critical  */
+    g_clear_pointer (&messages, g_array_unref);
+    return TRUE;
+  }
+
+  for (i = 0; i < messages->len; i++) {
+    GstH265SEIMessage *sei = &g_array_index (messages, GstH265SEIMessage, i);
+
+    switch (sei->payloadType) {
+      case GST_H265_SEI_PIC_TIMING:
+        priv->cur_pic_struct = sei->payload.pic_timing.pic_struct;
+        priv->cur_source_scan_type = sei->payload.pic_timing.source_scan_type;
+        priv->cur_duplicate_flag = sei->payload.pic_timing.duplicate_flag;
+
+        GST_TRACE_OBJECT (self,
+            "Picture Timing SEI, pic_struct: %d, source_scan_type: %d, "
+            "duplicate_flag: %d", priv->cur_pic_struct,
+            priv->cur_source_scan_type, priv->cur_duplicate_flag);
+        break;
+      default:
+        break;
+    }
+  }
+
+  g_array_free (messages, TRUE);
+  GST_LOG_OBJECT (self, "SEI parsed");
+
+  return TRUE;
+}
+
+static void
+gst_h265_decoder_process_ref_pic_lists (GstH265Decoder * self,
+    GstH265Picture * curr_pic, GstH265Slice * slice,
+    GArray ** ref_pic_list0, GArray ** ref_pic_list1)
+{
+  GstH265DecoderPrivate *priv = self->priv;
+  GstH265RefPicListModification *ref_mod =
+      &slice->header.ref_pic_list_modification;
+  GstH265PPSSccExtensionParams *scc_ext =
+      &slice->header.pps->pps_scc_extension_params;
+  GArray *tmp_refs;
+  gint num_tmp_refs, i;
+
+  *ref_pic_list0 = priv->ref_pic_list0;
+  *ref_pic_list1 = priv->ref_pic_list1;
+
+  /* There is nothing to be done for I slices */
+  if (GST_H265_IS_I_SLICE (&slice->header))
+    return;
+
+  /* Inifinit loop prevention */
+  if (self->NumPocStCurrBefore == 0 && self->NumPocStCurrAfter == 0 &&
+      self->NumPocLtCurr == 0 && !scc_ext->pps_curr_pic_ref_enabled_flag) {
+    GST_WARNING_OBJECT (self,
+        "Expected references, got none, preventing infinit loop.");
+    return;
+  }
+
+  /* 8.3.4 Deriving l0 */
+  tmp_refs = priv->ref_pic_list_tmp;
+
+  /* (8-8)
+   * Deriving l0 consist of appending in loop RefPicSetStCurrBefore,
+   * RefPicSetStCurrAfter and RefPicSetLtCurr until NumRpsCurrTempList0 item
+   * has been reached.
+   */
+
+  /* NumRpsCurrTempList0 */
+  num_tmp_refs = MAX (slice->header.num_ref_idx_l0_active_minus1 + 1,
+      self->NumPicTotalCurr);
+
+  while (tmp_refs->len < num_tmp_refs) {
+    for (i = 0; i < self->NumPocStCurrBefore && tmp_refs->len < num_tmp_refs;
+        i++)
+      g_array_append_val (tmp_refs, self->RefPicSetStCurrBefore[i]);
+    for (i = 0; i < self->NumPocStCurrAfter && tmp_refs->len < num_tmp_refs;
+        i++)
+      g_array_append_val (tmp_refs, self->RefPicSetStCurrAfter[i]);
+    for (i = 0; i < self->NumPocLtCurr && tmp_refs->len < num_tmp_refs; i++)
+      g_array_append_val (tmp_refs, self->RefPicSetLtCurr[i]);
+    if (scc_ext->pps_curr_pic_ref_enabled_flag)
+      g_array_append_val (tmp_refs, curr_pic);
+  }
+
+  /* (8-9)
+   * If needed, apply the modificaiton base on the lookup table found in the
+   * slice header (list_entry_l0).
+   */
+  for (i = 0; i <= slice->header.num_ref_idx_l0_active_minus1; i++) {
+    GstH265Picture **tmp = (GstH265Picture **) tmp_refs->data;
+
+    if (ref_mod->ref_pic_list_modification_flag_l0)
+      g_array_append_val (*ref_pic_list0, tmp[ref_mod->list_entry_l0[i]]);
+    else
+      g_array_append_val (*ref_pic_list0, tmp[i]);
+  }
+
+  if (scc_ext->pps_curr_pic_ref_enabled_flag &&
+      !ref_mod->ref_pic_list_modification_flag_l0 &&
+      num_tmp_refs > (slice->header.num_ref_idx_l0_active_minus1 + 1)) {
+    g_array_index (*ref_pic_list0, GstH265Picture *,
+        slice->header.num_ref_idx_l0_active_minus1) = curr_pic;
+  }
+
+  g_array_set_size (tmp_refs, 0);
+
+  /* For P slices we only need l0 */
+  if (GST_H265_IS_P_SLICE (&slice->header))
+    return;
+
+  /* 8.3.4 Deriving l1 */
+  /* (8-10)
+   * Deriving l1 consist of appending in loop RefPicSetStCurrAfter,
+   * RefPicSetStCurrBefore and RefPicSetLtCurr until NumRpsCurrTempList0 item
+   * has been reached.
+   */
+
+  /* NumRpsCurrTempList1 */
+  num_tmp_refs = MAX (slice->header.num_ref_idx_l1_active_minus1 + 1,
+      self->NumPicTotalCurr);
+
+  while (tmp_refs->len < num_tmp_refs) {
+    for (i = 0; i < self->NumPocStCurrAfter && tmp_refs->len < num_tmp_refs;
+        i++)
+      g_array_append_val (tmp_refs, self->RefPicSetStCurrAfter[i]);
+    for (i = 0; i < self->NumPocStCurrBefore && tmp_refs->len < num_tmp_refs;
+        i++)
+      g_array_append_val (tmp_refs, self->RefPicSetStCurrBefore[i]);
+    for (i = 0; i < self->NumPocLtCurr && tmp_refs->len < num_tmp_refs; i++)
+      g_array_append_val (tmp_refs, self->RefPicSetLtCurr[i]);
+    if (scc_ext->pps_curr_pic_ref_enabled_flag)
+      g_array_append_val (tmp_refs, curr_pic);
+  }
+
+  /* (8-11)
+   * If needed, apply the modificaiton base on the lookup table found in the
+   * slice header (list_entry_l1).
+   */
+  for (i = 0; i <= slice->header.num_ref_idx_l1_active_minus1; i++) {
+    GstH265Picture **tmp = (GstH265Picture **) tmp_refs->data;
+
+    if (ref_mod->ref_pic_list_modification_flag_l1)
+      g_array_append_val (*ref_pic_list1, tmp[ref_mod->list_entry_l1[i]]);
+    else
+      g_array_append_val (*ref_pic_list1, tmp[i]);
+  }
+
+  g_array_set_size (tmp_refs, 0);
+}
+
 static gboolean
 gst_h265_decoder_decode_slice (GstH265Decoder * self)
 {
@@ -328,6 +580,9 @@ gst_h265_decoder_decode_slice (GstH265Decoder * self)
   GstH265DecoderPrivate *priv = self->priv;
   GstH265Slice *slice = &priv->current_slice;
   GstH265Picture *picture = priv->current_picture;
+  GArray *l0 = NULL;
+  GArray *l1 = NULL;
+  gboolean ret;
 
   if (!picture) {
     GST_ERROR_OBJECT (self, "No current picture");
@@ -336,7 +591,20 @@ gst_h265_decoder_decode_slice (GstH265Decoder * self)
 
   g_assert (klass->decode_slice);
 
-  return klass->decode_slice (self, picture, slice);
+  if (priv->process_ref_pic_lists) {
+    l0 = priv->ref_pic_list0;
+    l1 = priv->ref_pic_list1;
+    gst_h265_decoder_process_ref_pic_lists (self, picture, slice, &l0, &l1);
+  }
+
+  ret = klass->decode_slice (self, picture, slice, l0, l1);
+
+  if (priv->process_ref_pic_lists) {
+    g_array_set_size (l0, 0);
+    g_array_set_size (l1, 0);
+  }
+
+  return ret;
 }
 
 static gboolean
@@ -344,7 +612,6 @@ gst_h265_decoder_preprocess_slice (GstH265Decoder * self, GstH265Slice * slice)
 {
   GstH265DecoderPrivate *priv = self->priv;
   const GstH265SliceHdr *slice_hdr = &slice->header;
-  const GstH265NalUnit *nalu = &slice->nalu;
 
   if (priv->current_picture && slice_hdr->first_slice_segment_in_pic_flag) {
     GST_WARNING_OBJECT (self,
@@ -353,11 +620,6 @@ gst_h265_decoder_preprocess_slice (GstH265Decoder * self, GstH265Slice * slice)
     return FALSE;
   }
 
-  if (GST_H265_IS_NAL_TYPE_IDR (nalu->type)) {
-    GST_DEBUG_OBJECT (self, "IDR nalu, clear dpb");
-    gst_h265_decoder_drain (GST_VIDEO_DECODER (self));
-  }
-
   return TRUE;
 }
 
@@ -382,6 +644,18 @@ gst_h265_decoder_parse_slice (GstH265Decoder * self, GstH265NalUnit * nalu,
 
   priv->current_slice.nalu = *nalu;
 
+  if (priv->current_slice.header.dependent_slice_segment_flag) {
+    GstH265SliceHdr *slice_hdr = &priv->current_slice.header;
+    GstH265SliceHdr *indep_slice_hdr = &priv->prev_independent_slice.header;
+
+    memcpy (&slice_hdr->type, &indep_slice_hdr->type,
+        G_STRUCT_OFFSET (GstH265SliceHdr, num_entry_point_offsets) -
+        G_STRUCT_OFFSET (GstH265SliceHdr, type));
+  } else {
+    priv->prev_independent_slice = priv->current_slice;
+    memset (&priv->prev_independent_slice.nalu, 0, sizeof (GstH265NalUnit));
+  }
+
   if (!gst_h265_decoder_preprocess_slice (self, &priv->current_slice))
     return FALSE;
 
@@ -398,20 +672,19 @@ gst_h265_decoder_parse_slice (GstH265Decoder * self, GstH265NalUnit * nalu,
     /* This allows accessing the frame from the picture. */
     picture->system_frame_number = priv->current_frame->system_frame_number;
 
+    priv->current_picture = picture;
+    g_assert (priv->current_frame);
+
     if (klass->new_picture)
-      ret = klass->new_picture (self, picture);
+      ret = klass->new_picture (self, priv->current_frame, picture);
 
     if (!ret) {
       GST_ERROR_OBJECT (self, "subclass does not want accept new picture");
+      priv->current_picture = NULL;
       gst_h265_picture_unref (picture);
       return FALSE;
     }
 
-    priv->current_picture = picture;
-    gst_video_codec_frame_set_user_data (priv->current_frame,
-        gst_h265_picture_ref (priv->current_picture),
-        (GDestroyNotify) gst_h265_picture_unref);
-
     if (!gst_h265_decoder_start_current_picture (self)) {
       GST_ERROR_OBJECT (self, "start picture failed");
       return FALSE;
@@ -445,6 +718,10 @@ gst_h265_decoder_decode_nal (GstH265Decoder * self, GstH265NalUnit * nalu,
     case GST_H265_NAL_PPS:
       ret = gst_h265_decoder_parse_pps (self, nalu);
       break;
+    case GST_H265_NAL_PREFIX_SEI:
+    case GST_H265_NAL_SUFFIX_SEI:
+      ret = gst_h265_decoder_parse_sei (self, nalu);
+      break;
     case GST_H265_NAL_SLICE_TRAIL_N:
     case GST_H265_NAL_SLICE_TRAIL_R:
     case GST_H265_NAL_SLICE_TSA_N:
@@ -466,11 +743,9 @@ gst_h265_decoder_decode_nal (GstH265Decoder * self, GstH265NalUnit * nalu,
       priv->prev_nal_is_eos = FALSE;
       break;
     case GST_H265_NAL_EOB:
-      gst_h265_decoder_drain (GST_VIDEO_DECODER (self));
       priv->new_bitstream = TRUE;
       break;
     case GST_H265_NAL_EOS:
-      gst_h265_decoder_drain (GST_VIDEO_DECODER (self));
       priv->prev_nal_is_eos = TRUE;
       break;
     default:
@@ -688,7 +963,7 @@ gst_h265_decoder_flush (GstVideoDecoder * decoder)
 {
   GstH265Decoder *self = GST_H265_DECODER (decoder);
 
-  gst_h265_decoder_clear_dpb (self);
+  gst_h265_decoder_clear_dpb (self, TRUE);
 
   return TRUE;
 }
@@ -700,8 +975,8 @@ gst_h265_decoder_drain (GstVideoDecoder * decoder)
   GstH265DecoderPrivate *priv = self->priv;
 
   priv->last_ret = GST_FLOW_OK;
-  gst_h265_decoder_output_all_remaining_pics (self);
-  gst_h265_decoder_clear_dpb (self);
+  /* dpb will be cleared by this method */
+  gst_h265_decoder_drain_internal (self);
 
   return priv->last_ret;
 }
@@ -724,9 +999,6 @@ gst_h265_decoder_fill_picture_from_slice (GstH265Decoder * self,
       nalu->type <= GST_H265_NAL_SLICE_CRA_NUT)
     picture->RapPicFlag = TRUE;
 
-  /* FIXME: Use SEI header values */
-  picture->field = GST_H265_PICTURE_FIELD_FRAME;
-
   /* NoRaslOutputFlag == 1 if the current picture is
    * 1) an IDR picture
    * 2) a BLA picture
@@ -853,6 +1125,61 @@ gst_h265_decoder_calculate_poc (GstH265Decoder * self,
   return TRUE;
 }
 
+static gboolean
+gst_h265_decoder_set_buffer_flags (GstH265Decoder * self,
+    GstH265Picture * picture)
+{
+  GstH265DecoderPrivate *priv = self->priv;
+
+  switch (picture->pic_struct) {
+    case GST_H265_SEI_PIC_STRUCT_FRAME:
+      break;
+    case GST_H265_SEI_PIC_STRUCT_TOP_FIELD:
+    case GST_H265_SEI_PIC_STRUCT_TOP_PAIRED_PREVIOUS_BOTTOM:
+    case GST_H265_SEI_PIC_STRUCT_TOP_PAIRED_NEXT_BOTTOM:
+      if (!priv->field_seq_flag) {
+        GST_FIXME_OBJECT (self,
+            "top-field with field_seq_flag == 0, what does it mean?");
+      } else {
+        picture->buffer_flags = GST_VIDEO_BUFFER_FLAG_TOP_FIELD;
+      }
+      break;
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_FIELD:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_PAIRED_PREVIOUS_TOP:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_PAIRED_NEXT_TOP:
+      if (!priv->field_seq_flag) {
+        GST_FIXME_OBJECT (self,
+            "bottom-field with field_seq_flag == 0, what does it mean?");
+      } else {
+        picture->buffer_flags = GST_VIDEO_BUFFER_FLAG_BOTTOM_FIELD;
+      }
+      break;
+    case GST_H265_SEI_PIC_STRUCT_TOP_BOTTOM:
+      if (priv->field_seq_flag) {
+        GST_FIXME_OBJECT (self,
+            "TFF with field_seq_flag == 1, what does it mean?");
+      } else {
+        picture->buffer_flags =
+            GST_VIDEO_BUFFER_FLAG_INTERLACED | GST_VIDEO_BUFFER_FLAG_TFF;
+      }
+      break;
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_TOP:
+      if (priv->field_seq_flag) {
+        GST_FIXME_OBJECT (self,
+            "BFF with field_seq_flag == 1, what does it mean?");
+      } else {
+        picture->buffer_flags = GST_VIDEO_BUFFER_FLAG_INTERLACED;
+      }
+      break;
+    default:
+      GST_FIXME_OBJECT (self, "Unhandled picture time SEI pic_struct %d",
+          picture->pic_struct);
+      break;
+  }
+
+  return TRUE;
+}
+
 static gboolean
 gst_h265_decoder_init_current_picture (GstH265Decoder * self)
 {
@@ -867,6 +1194,12 @@ gst_h265_decoder_init_current_picture (GstH265Decoder * self)
           &priv->current_slice, priv->current_picture))
     return FALSE;
 
+  /* Use picture struct parsed from picture timing SEI */
+  priv->current_picture->pic_struct = priv->cur_pic_struct;
+  priv->current_picture->source_scan_type = priv->cur_source_scan_type;
+  priv->current_picture->duplicate_flag = priv->cur_duplicate_flag;
+  gst_h265_decoder_set_buffer_flags (self, priv->current_picture);
+
   return TRUE;
 }
 
@@ -887,13 +1220,9 @@ has_entry_in_rps (GstH265Picture * dpb_pic,
 }
 
 static void
-gst_h265_decoder_derive_and_mark_rps (GstH265Decoder * self,
-    GstH265Picture * picture, gint32 * CurrDeltaPocMsbPresentFlag,
-    gint32 * FollDeltaPocMsbPresentFlag)
+gst_h265_decoder_clear_ref_pic_sets (GstH265Decoder * self)
 {
-  GstH265DecoderPrivate *priv = self->priv;
   guint i;
-  GArray *dpb_array;
 
   for (i = 0; i < 16; i++) {
     gst_h265_picture_replace (&self->RefPicSetLtCurr[i], NULL);
@@ -902,6 +1231,18 @@ gst_h265_decoder_derive_and_mark_rps (GstH265Decoder * self,
     gst_h265_picture_replace (&self->RefPicSetStCurrAfter[i], NULL);
     gst_h265_picture_replace (&self->RefPicSetStFoll[i], NULL);
   }
+}
+
+static void
+gst_h265_decoder_derive_and_mark_rps (GstH265Decoder * self,
+    GstH265Picture * picture, gint32 * CurrDeltaPocMsbPresentFlag,
+    gint32 * FollDeltaPocMsbPresentFlag)
+{
+  GstH265DecoderPrivate *priv = self->priv;
+  guint i;
+  GArray *dpb_array;
+
+  gst_h265_decoder_clear_ref_pic_sets (self);
 
   /* (8-6) */
   for (i = 0; i < self->NumPocLtCurr; i++) {
@@ -1064,7 +1405,7 @@ gst_h265_decoder_prepare_rps (GstH265Decoder * self, const GstH265Slice * slice,
         numtotalcurr++;
     }
 
-    self->NumPocTotalCurr = numtotalcurr;
+    self->NumPicTotalCurr = numtotalcurr;
 
     /* The variable DeltaPocMsbCycleLt[i] is derived as follows: (7-38) */
     for (i = 0; i < num_lt_pics; i++) {
@@ -1101,7 +1442,7 @@ gst_h265_decoder_prepare_rps (GstH265Decoder * self, const GstH265Slice * slice,
   GST_LOG_OBJECT (self, "NumPocStFoll:       %d", self->NumPocStFoll);
   GST_LOG_OBJECT (self, "NumPocLtCurr:       %d", self->NumPocLtCurr);
   GST_LOG_OBJECT (self, "NumPocLtFoll:       %d", self->NumPocLtFoll);
-  GST_LOG_OBJECT (self, "NumPocTotalCurr:    %d", self->NumPocTotalCurr);
+  GST_LOG_OBJECT (self, "NumPicTotalCurr:    %d", self->NumPicTotalCurr);
 
   /* the derivation process for the RPS and the picture marking */
   gst_h265_decoder_derive_and_mark_rps (self, picture,
@@ -1110,23 +1451,16 @@ gst_h265_decoder_prepare_rps (GstH265Decoder * self, const GstH265Slice * slice,
   return TRUE;
 }
 
-static void
-gst_h265_decoder_clear_dpb (GstH265Decoder * self)
-{
-  GstH265DecoderPrivate *priv = self->priv;
-
-  gst_h265_dpb_clear (priv->dpb);
-  priv->last_output_poc = -1;
-}
-
 static void
 gst_h265_decoder_do_output_picture (GstH265Decoder * self,
     GstH265Picture * picture)
 {
   GstH265DecoderPrivate *priv = self->priv;
   GstH265DecoderClass *klass;
+  GstVideoCodecFrame *frame = NULL;
 
-  picture->outputted = TRUE;
+  GST_LOG_OBJECT (self, "Output picture %p (poc %d)", picture,
+      picture->pic_order_cnt);
 
   if (picture->pic_order_cnt < priv->last_output_poc) {
     GST_WARNING_OBJECT (self,
@@ -1136,55 +1470,62 @@ gst_h265_decoder_do_output_picture (GstH265Decoder * self,
 
   priv->last_output_poc = picture->pic_order_cnt;
 
+  frame = gst_video_decoder_get_frame (GST_VIDEO_DECODER (self),
+      picture->system_frame_number);
+
+  if (!frame) {
+    GST_ERROR_OBJECT (self,
+        "No available codec frame with frame number %d",
+        picture->system_frame_number);
+    priv->last_ret = GST_FLOW_ERROR;
+
+    gst_h265_picture_unref (picture);
+    return;
+  }
+
   klass = GST_H265_DECODER_GET_CLASS (self);
 
   g_assert (klass->output_picture);
-  priv->last_ret = klass->output_picture (self, picture);
-}
-
-static gint
-poc_asc_compare (const GstH265Picture * a, const GstH265Picture * b)
-{
-  return a->pic_order_cnt > b->pic_order_cnt;
+  priv->last_ret = klass->output_picture (self, frame, picture);
 }
 
-static gboolean
-gst_h265_decoder_output_all_remaining_pics (GstH265Decoder * self)
+static void
+gst_h265_decoder_clear_dpb (GstH265Decoder * self, gboolean flush)
 {
+  GstVideoDecoder *decoder = GST_VIDEO_DECODER (self);
   GstH265DecoderPrivate *priv = self->priv;
-  GList *to_output = NULL;
-  GList *iter;
-
-  gst_h265_dpb_get_pictures_not_outputted (priv->dpb, &to_output);
-
-  to_output = g_list_sort (to_output, (GCompareFunc) poc_asc_compare);
+  GstH265Picture *picture;
 
-  for (iter = to_output; iter; iter = g_list_next (iter)) {
-    GstH265Picture *picture = (GstH265Picture *) iter->data;
+  /* If we are not flushing now, videodecoder baseclass will hold
+   * GstVideoCodecFrame. Release frames manually */
+  if (!flush) {
+    while ((picture = gst_h265_dpb_bump (priv->dpb, TRUE)) != NULL) {
+      GstVideoCodecFrame *frame = gst_video_decoder_get_frame (decoder,
+          picture->system_frame_number);
 
-    GST_LOG_OBJECT (self, "Output picture %p (poc %d)", picture,
-        picture->pic_order_cnt);
-    gst_h265_decoder_do_output_picture (self, picture);
+      if (frame)
+        gst_video_decoder_release_frame (decoder, frame);
+      gst_h265_picture_unref (picture);
+    }
   }
 
-  if (to_output)
-    g_list_free_full (to_output, (GDestroyNotify) gst_h265_picture_unref);
-
-  return TRUE;
+  gst_h265_dpb_clear (priv->dpb);
+  priv->last_output_poc = G_MININT32;
 }
 
 static gboolean
-gst_h265_decoder_check_latency_count (GList * list, guint32 max_latency)
+gst_h265_decoder_drain_internal (GstH265Decoder * self)
 {
-  GList *iter;
+  GstH265DecoderPrivate *priv = self->priv;
+  GstH265Picture *picture;
 
-  for (iter = list; iter; iter = g_list_next (iter)) {
-    GstH265Picture *pic = (GstH265Picture *) iter->data;
-    if (!pic->outputted && pic->pic_latency_cnt >= max_latency)
-      return TRUE;
-  }
+  while ((picture = gst_h265_dpb_bump (priv->dpb, TRUE)) != NULL)
+    gst_h265_decoder_do_output_picture (self, picture);
 
-  return FALSE;
+  gst_h265_dpb_clear (priv->dpb);
+  priv->last_output_poc = G_MININT32;
+
+  return TRUE;
 }
 
 /* C.5.2.2 */
@@ -1195,7 +1536,10 @@ gst_h265_decoder_dpb_init (GstH265Decoder * self, const GstH265Slice * slice,
   GstH265DecoderPrivate *priv = self->priv;
   const GstH265SliceHdr *slice_hdr = &slice->header;
   const GstH265NalUnit *nalu = &slice->nalu;
+  const GstH265SPS *sps = priv->active_sps;
+  GstH265Picture *to_output;
 
+  /* C 3.2 */
   if (GST_H265_IS_NAL_TYPE_IRAP (nalu->type) && picture->NoRaslOutputFlag
       && !priv->new_bitstream) {
     if (nalu->type == GST_H265_NAL_SLICE_CRA_NUT)
@@ -1206,11 +1550,37 @@ gst_h265_decoder_dpb_init (GstH265Decoder * self, const GstH265Slice * slice,
 
     if (picture->NoOutputOfPriorPicsFlag) {
       GST_DEBUG_OBJECT (self, "Clear dpb");
-      gst_h265_decoder_drain (GST_VIDEO_DECODER (self));
+      gst_h265_decoder_clear_dpb (self, FALSE);
+    } else {
+      gst_h265_dpb_delete_unused (priv->dpb);
+      while ((to_output = gst_h265_dpb_bump (priv->dpb, FALSE)) != NULL)
+        gst_h265_decoder_do_output_picture (self, to_output);
+
+      if (gst_h265_dpb_get_size (priv->dpb) > 0) {
+        GST_WARNING_OBJECT (self, "IDR or BLA frame failed to clear the dpb, "
+            "there are still %d pictures in the dpb, last output poc is %d",
+            gst_h265_dpb_get_size (priv->dpb), priv->last_output_poc);
+      } else {
+        priv->last_output_poc = G_MININT32;
+      }
     }
   } else {
-    /* C 3.2 */
     gst_h265_dpb_delete_unused (priv->dpb);
+    while (gst_h265_dpb_needs_bump (priv->dpb,
+            sps->max_num_reorder_pics[sps->max_sub_layers_minus1],
+            priv->SpsMaxLatencyPictures,
+            sps->max_dec_pic_buffering_minus1[sps->max_sub_layers_minus1] +
+            1)) {
+      to_output = gst_h265_dpb_bump (priv->dpb, FALSE);
+
+      /* Something wrong... */
+      if (!to_output) {
+        GST_WARNING_OBJECT (self, "Bumping is needed but no picture to output");
+        break;
+      }
+
+      gst_h265_decoder_do_output_picture (self, to_output);
+    }
   }
 
   return TRUE;
@@ -1261,115 +1631,45 @@ static gboolean
 gst_h265_decoder_finish_picture (GstH265Decoder * self,
     GstH265Picture * picture)
 {
+  GstVideoDecoder *decoder = GST_VIDEO_DECODER (self);
   GstH265DecoderPrivate *priv = self->priv;
   const GstH265SPS *sps = priv->active_sps;
-  GList *not_outputted = NULL;
-  guint num_remaining;
-  GList *iter;
-#ifndef GST_DISABLE_GST_DEBUG
-  gint i;
-#endif
 
   GST_LOG_OBJECT (self,
       "Finishing picture %p (poc %d), entries in DPB %d",
       picture, picture->pic_order_cnt, gst_h265_dpb_get_size (priv->dpb));
 
-  /* Get all pictures that haven't been outputted yet */
-  gst_h265_dpb_get_pictures_not_outputted (priv->dpb, &not_outputted);
-
-  /* C.5.2.3 */
-  if (picture->output_flag) {
-    for (iter = not_outputted; iter; iter = g_list_next (iter)) {
-      GstH265Picture *other = GST_H265_PICTURE (iter->data);
-
-      if (!other->outputted)
-        other->pic_latency_cnt++;
-    }
-
-    picture->outputted = FALSE;
-    picture->pic_latency_cnt = 0;
-  } else {
-    picture->outputted = TRUE;
-  }
+  gst_h265_dpb_delete_unused (priv->dpb);
 
-  /* set pic as short_term_ref */
-  picture->ref = TRUE;
-  picture->long_term = FALSE;
+  /* This picture is decode only, drop corresponding frame */
+  if (!picture->output_flag) {
+    GstVideoCodecFrame *frame = gst_video_decoder_get_frame (decoder,
+        picture->system_frame_number);
 
-  /* Include the one we've just decoded */
-  if (picture->output_flag) {
-    not_outputted =
-        g_list_append (not_outputted, gst_h265_picture_ref (picture));
+    gst_video_decoder_release_frame (decoder, frame);
   }
 
-  /* Add to dpb and transfer ownership */
+  /* gst_h265_dpb_add() will take care of pic_latency_cnt increment and
+   * reference picture marking for this picture */
   gst_h265_dpb_add (priv->dpb, picture);
 
-  /* for debugging */
-#ifndef GST_DISABLE_GST_DEBUG
-  GST_TRACE_OBJECT (self, "Before sorting not outputted list");
-  i = 0;
-  for (iter = not_outputted; iter; iter = g_list_next (iter)) {
-    GstH265Picture *tmp = (GstH265Picture *) iter->data;
-
-    GST_TRACE_OBJECT (self,
-        "\t%dth picture %p (poc %d)", i, tmp, tmp->pic_order_cnt);
-    i++;
-  }
-#endif
-
-  /* Sort in output order */
-  not_outputted = g_list_sort (not_outputted, (GCompareFunc) poc_asc_compare);
-
-#ifndef GST_DISABLE_GST_DEBUG
-  GST_TRACE_OBJECT (self,
-      "After sorting not outputted list in poc ascending order");
-  i = 0;
-  for (iter = not_outputted; iter; iter = g_list_next (iter)) {
-    GstH265Picture *tmp = (GstH265Picture *) iter->data;
-
-    GST_TRACE_OBJECT (self,
-        "\t%dth picture %p (poc %d)", i, tmp, tmp->pic_order_cnt);
-    i++;
-  }
-#endif
-
-  /* Try to output as many pictures as we can. A picture can be output,
-   * if the number of decoded and not yet outputted pictures that would remain
-   * in DPB afterwards would at least be equal to max_num_reorder_frames.
-   * If the outputted picture is not a reference picture, it doesn't have
-   * to remain in the DPB and can be removed */
-  iter = not_outputted;
-  num_remaining = g_list_length (not_outputted);
-
-  while (num_remaining > sps->max_num_reorder_pics[sps->max_sub_layers_minus1]
-      || (num_remaining &&
-          sps->max_latency_increase_plus1[sps->max_sub_layers_minus1] &&
-          gst_h265_decoder_check_latency_count (iter,
-              priv->SpsMaxLatencyPictures))) {
-    GstH265Picture *to_output = GST_H265_PICTURE (iter->data);
-
-    GST_LOG_OBJECT (self,
-        "Output picture %p (poc %d)", to_output, to_output->pic_order_cnt);
-    gst_h265_decoder_do_output_picture (self, to_output);
-    if (!to_output->ref) {
-      /* Current picture hasn't been inserted into DPB yet, so don't remove it
-       * if we managed to output it immediately */
-      gint outputted_poc = to_output->pic_order_cnt;
-      if (outputted_poc != picture->pic_order_cnt) {
-        GST_LOG_OBJECT (self, "Delete picture %p (poc %d) from DPB",
-            to_output, to_output->pic_order_cnt);
-        gst_h265_dpb_delete_by_poc (priv->dpb, outputted_poc);
-      }
+  /* NOTE: As per C.5.2.2, bumping by sps_max_dec_pic_buffering_minus1 is
+   * applied only for the output and removal of pictures from the DPB before
+   * the decoding of the current picture. So pass zero here */
+  while (gst_h265_dpb_needs_bump (priv->dpb,
+          sps->max_num_reorder_pics[sps->max_sub_layers_minus1],
+          priv->SpsMaxLatencyPictures, 0)) {
+    GstH265Picture *to_output = gst_h265_dpb_bump (priv->dpb, FALSE);
+
+    /* Something wrong... */
+    if (!to_output) {
+      GST_WARNING_OBJECT (self, "Bumping is needed but no picture to output");
+      break;
     }
 
-    iter = g_list_next (iter);
-    num_remaining--;
+    gst_h265_decoder_do_output_picture (self, to_output);
   }
 
-  if (not_outputted)
-    g_list_free_full (not_outputted, (GDestroyNotify) gst_h265_picture_unref);
-
   return TRUE;
 }
 
@@ -1400,6 +1700,17 @@ gst_h265_decoder_finish_current_picture (GstH265Decoder * self)
   return TRUE;
 }
 
+static void
+gst_h265_decoder_reset_frame_state (GstH265Decoder * self)
+{
+  GstH265DecoderPrivate *priv = self->priv;
+
+  /* Clear picture struct information */
+  priv->cur_pic_struct = GST_H265_SEI_PIC_STRUCT_FRAME;
+  priv->cur_source_scan_type = 2;
+  priv->cur_duplicate_flag = 0;
+}
+
 static GstFlowReturn
 gst_h265_decoder_handle_frame (GstVideoDecoder * decoder,
     GstVideoCodecFrame * frame)
@@ -1420,7 +1731,14 @@ gst_h265_decoder_handle_frame (GstVideoDecoder * decoder,
   priv->current_frame = frame;
   priv->last_ret = GST_FLOW_OK;
 
-  gst_buffer_map (in_buf, &map, GST_MAP_READ);
+  gst_h265_decoder_reset_frame_state (self);
+
+  if (!gst_buffer_map (in_buf, &map, GST_MAP_READ)) {
+    GST_ELEMENT_ERROR (self, RESOURCE, READ,
+        ("Failed to map memory for reading"), (NULL));
+    return GST_FLOW_ERROR;
+  }
+
   if (priv->in_format == GST_H265_DECODER_FORMAT_HVC1 ||
       priv->in_format == GST_H265_DECODER_FORMAT_HEV1) {
     pres = gst_h265_parser_identify_nalu_hevc (priv->parser,
@@ -1466,8 +1784,48 @@ gst_h265_decoder_handle_frame (GstVideoDecoder * decoder,
     return priv->last_ret;
   }
 
-  gst_h265_decoder_finish_current_picture (self);
-  gst_video_codec_frame_unref (frame);
+  if (priv->current_picture) {
+    gst_h265_decoder_finish_current_picture (self);
+    gst_video_codec_frame_unref (frame);
+  } else {
+    /* This picture was dropped */
+    gst_video_decoder_release_frame (decoder, frame);
+  }
 
   return priv->last_ret;
 }
+
+/**
+ * gst_h265_decoder_set_process_ref_pic_lists:
+ * @decoder: a #GstH265Decoder
+ * @process: whether subclass is requiring reference picture modification process
+ *
+ * Called to en/disable reference picture modification process.
+ *
+ * Since: 1.20
+ */
+void
+gst_h265_decoder_set_process_ref_pic_lists (GstH265Decoder * decoder,
+    gboolean process)
+{
+  decoder->priv->process_ref_pic_lists = process;
+}
+
+/**
+ * gst_h265_decoder_get_picture:
+ * @decoder: a #GstH265Decoder
+ * @system_frame_number: a target system frame number of #GstH265Picture
+ *
+ * Retrive DPB and return a #GstH265Picture corresponding to
+ * the @system_frame_number
+ *
+ * Returns: (transfer full): a #GstH265Picture if successful, or %NULL otherwise
+ *
+ * Since: 1.20
+ */
+GstH265Picture *
+gst_h265_decoder_get_picture (GstH265Decoder * decoder,
+    guint32 system_frame_number)
+{
+  return gst_h265_dpb_get_picture (decoder->priv->dpb, system_frame_number);
+}
diff --git a/gst-libs/gst/codecs/gsth265decoder.h b/gst-libs/gst/codecs/gsth265decoder.h
index b688e278d..a45629d0a 100644
--- a/gst-libs/gst/codecs/gsth265decoder.h
+++ b/gst-libs/gst/codecs/gsth265decoder.h
@@ -64,7 +64,7 @@ struct _GstH265Decoder
   guint NumPocStFoll;
   guint NumPocLtCurr;
   guint NumPocLtFoll;
-  guint NumPocTotalCurr;
+  guint NumPicTotalCurr;
 
   /*< private >*/
   GstH265DecoderPrivate *priv;
@@ -87,9 +87,7 @@ struct _GstH265Decoder
  *                  Called per one #GstH265Picture to notify subclass to finish
  *                  decoding process for the #GstH265Picture
  * @output_picture: Called with a #GstH265Picture which is required to be outputted.
- *                  Subclass can retrieve parent #GstVideoCodecFrame by using
- *                  gst_video_decoder_get_frame() with system_frame_number
- *                  and the #GstVideoCodecFrame must be consumed by subclass via
+ *                  The #GstVideoCodecFrame must be consumed by subclass via
  *                  gst_video_decoder_{finish,drop,release}_frame().
  */
 struct _GstH265DecoderClass
@@ -99,8 +97,14 @@ struct _GstH265DecoderClass
   gboolean      (*new_sequence)     (GstH265Decoder * decoder,
                                      const GstH265SPS * sps,
                                      gint max_dpb_size);
-
+  /**
+   * GstH265Decoder:new_picture:
+   * @decoder: a #GstH265Decoder
+   * @frame: (transfer none): a #GstVideoCodecFrame
+   * @picture: (transfer none): a #GstH265Picture
+   */
   gboolean      (*new_picture)      (GstH265Decoder * decoder,
+                                     GstVideoCodecFrame * frame,
                                      GstH265Picture * picture);
 
   gboolean      (*start_picture)    (GstH265Decoder * decoder,
@@ -110,12 +114,20 @@ struct _GstH265DecoderClass
 
   gboolean      (*decode_slice)     (GstH265Decoder * decoder,
                                      GstH265Picture * picture,
-                                     GstH265Slice * slice);
+                                     GstH265Slice * slice,
+                                     GArray * ref_pic_list0,
+                                     GArray * ref_pic_list1);
 
   gboolean      (*end_picture)      (GstH265Decoder * decoder,
                                      GstH265Picture * picture);
-
+  /**
+   * GstH265Decoder:output_picture:
+   * @decoder: a #GstH265Decoder
+   * @frame: (transfer full): a #GstVideoCodecFrame
+   * @picture: (transfer full): a #GstH265Picture
+   */
   GstFlowReturn (*output_picture)   (GstH265Decoder * decoder,
+                                     GstVideoCodecFrame * frame,
                                      GstH265Picture * picture);
 
   /*< private >*/
@@ -127,6 +139,14 @@ G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstH265Decoder, gst_object_unref)
 GST_CODECS_API
 GType gst_h265_decoder_get_type (void);
 
+GST_CODECS_API
+void gst_h265_decoder_set_process_ref_pic_lists (GstH265Decoder * decoder,
+                                                 gboolean process);
+
+GST_CODECS_API
+GstH265Picture * gst_h265_decoder_get_picture   (GstH265Decoder * decoder,
+                                                 guint32 system_frame_number);
+
 G_END_DECLS
 
 #endif /* __GST_H265_DECODER_H__ */
diff --git a/gst-libs/gst/codecs/gsth265picture.c b/gst-libs/gst/codecs/gsth265picture.c
index 0c7fb8714..699ddb5dd 100644
--- a/gst-libs/gst/codecs/gsth265picture.c
+++ b/gst-libs/gst/codecs/gsth265picture.c
@@ -52,7 +52,11 @@ gst_h265_picture_new (void)
   pic = g_new0 (GstH265Picture, 1);
 
   pic->pts = GST_CLOCK_TIME_NONE;
-  pic->field = GST_H265_PICTURE_FIELD_FRAME;
+  pic->pic_struct = GST_H265_SEI_PIC_STRUCT_FRAME;
+  /* 0: interlaced, 1: progressive, 2: unspecified, 3: reserved, can be
+   * interpreted as 2 */
+  pic->source_scan_type = 2;
+  pic->duplicate_flag = 0;
 
   gst_mini_object_init (GST_MINI_OBJECT_CAST (pic), 0,
       GST_TYPE_H265_PICTURE, NULL, NULL,
@@ -105,6 +109,7 @@ struct _GstH265Dpb
 {
   GArray *pic_list;
   gint max_num_pics;
+  gint num_output_needed;
 };
 
 /**
@@ -187,6 +192,7 @@ gst_h265_dpb_clear (GstH265Dpb * dpb)
   g_return_if_fail (dpb != NULL);
 
   g_array_set_size (dpb->pic_list, 0);
+  dpb->num_output_needed = 0;
 }
 
 /**
@@ -194,7 +200,8 @@ gst_h265_dpb_clear (GstH265Dpb * dpb)
  * @dpb: a #GstH265Dpb
  * @picture: (transfer full): a #GstH265Picture
  *
- * Store the @picture
+ * Store the @picture and perform increase pic_latency_cnt as defined in
+ * "C.5.2.3 Additional bumping" process
  */
 void
 gst_h265_dpb_add (GstH265Dpb * dpb, GstH265Picture * picture)
@@ -202,6 +209,27 @@ gst_h265_dpb_add (GstH265Dpb * dpb, GstH265Picture * picture)
   g_return_if_fail (dpb != NULL);
   g_return_if_fail (GST_IS_H265_PICTURE (picture));
 
+  if (picture->output_flag) {
+    gint i;
+
+    for (i = 0; i < dpb->pic_list->len; i++) {
+      GstH265Picture *other =
+          g_array_index (dpb->pic_list, GstH265Picture *, i);
+
+      if (other->needed_for_output)
+        other->pic_latency_cnt++;
+    }
+
+    dpb->num_output_needed++;
+    picture->needed_for_output = TRUE;
+  } else {
+    picture->needed_for_output = FALSE;
+  }
+
+  /* C.3.4 */
+  picture->ref = TRUE;
+  picture->long_term = FALSE;
+
   g_array_append_val (dpb->pic_list, picture);
 }
 
@@ -209,7 +237,7 @@ gst_h265_dpb_add (GstH265Dpb * dpb, GstH265Picture * picture)
  * gst_h265_dpb_delete_unused:
  * @dpb: a #GstH265Dpb
  *
- * Delete already outputted and not referenced all pictures from dpb
+ * Delete not needed for output and not referenced all pictures from dpb
  */
 void
 gst_h265_dpb_delete_unused (GstH265Dpb * dpb)
@@ -222,7 +250,7 @@ gst_h265_dpb_delete_unused (GstH265Dpb * dpb)
     GstH265Picture *picture =
         g_array_index (dpb->pic_list, GstH265Picture *, i);
 
-    if (picture->outputted && !picture->ref) {
+    if (!picture->needed_for_output && !picture->ref) {
       GST_TRACE ("remove picture %p (poc %d) from dpb",
           picture, picture->pic_order_cnt);
       g_array_remove_index (dpb->pic_list, i);
@@ -231,33 +259,6 @@ gst_h265_dpb_delete_unused (GstH265Dpb * dpb)
   }
 }
 
-/**
- * gst_h265_dpb_delete_by_poc:
- * @dpb: a #GstH265Dpb
- * @poc: a poc of #GstH265Picture to remove
- *
- * Delete a #GstH265Dpb by @poc
- */
-void
-gst_h265_dpb_delete_by_poc (GstH265Dpb * dpb, gint poc)
-{
-  gint i;
-
-  g_return_if_fail (dpb != NULL);
-
-  for (i = 0; i < dpb->pic_list->len; i++) {
-    GstH265Picture *picture =
-        g_array_index (dpb->pic_list, GstH265Picture *, i);
-
-    if (picture->pic_order_cnt == poc) {
-      g_array_remove_index (dpb->pic_list, i);
-      return;
-    }
-  }
-
-  GST_WARNING ("Couldn't find picture with poc %d", poc);
-}
-
 /**
  * gst_h265_dpb_num_ref_pictures:
  * @dpb: a #GstH265Dpb
@@ -420,31 +421,6 @@ gst_h265_dpb_get_long_ref_by_poc (GstH265Dpb * dpb, gint poc)
   return NULL;
 }
 
-/**
- * gst_h265_dpb_get_pictures_not_outputted:
- * @dpb: a #GstH265Dpb
- * @out: (out) (element-type GstH265Picture) (transfer full): a list
- *   of #GstH265Dpb
- *
- * Retrieve all not-outputted pictures from @dpb
- */
-void
-gst_h265_dpb_get_pictures_not_outputted (GstH265Dpb * dpb, GList ** out)
-{
-  gint i;
-
-  g_return_if_fail (dpb != NULL);
-  g_return_if_fail (out != NULL);
-
-  for (i = 0; i < dpb->pic_list->len; i++) {
-    GstH265Picture *picture =
-        g_array_index (dpb->pic_list, GstH265Picture *, i);
-
-    if (!picture->outputted)
-      *out = g_list_append (*out, gst_h265_picture_ref (picture));
-  }
-}
-
 /**
  * gst_h265_dpb_get_pictures_all:
  * @dpb: a #GstH265Dpb
@@ -475,15 +451,178 @@ gst_h265_dpb_get_size (GstH265Dpb * dpb)
 }
 
 /**
- * gst_h265_dpb_is_full:
+ * gst_h265_dpb_get_picture:
  * @dpb: a #GstH265Dpb
+ * @system_frame_number The system frame number
+ *
+ * Returns: (transfer full): the picture identified with the specified
+ * @system_frame_number, or %NULL if DPB does not contain a #GstH265Picture
+ * corresponding to the @system_frame_number
  *
- * Return: %TRUE if @dpb is full
+ * Since: 1.20
+ */
+GstH265Picture *
+gst_h265_dpb_get_picture (GstH265Dpb * dpb, guint32 system_frame_number)
+{
+  gint i;
+
+  g_return_val_if_fail (dpb != NULL, NULL);
+
+  for (i = 0; i < dpb->pic_list->len; i++) {
+    GstH265Picture *picture =
+        g_array_index (dpb->pic_list, GstH265Picture *, i);
+
+    if (picture->system_frame_number == system_frame_number) {
+      gst_h265_picture_ref (picture);
+      return picture;
+    }
+  }
+
+  return NULL;
+}
+
+static gboolean
+gst_h265_dpb_check_latency_count (GstH265Dpb * dpb, guint32 max_latency)
+{
+  gint i;
+
+  for (i = 0; i < dpb->pic_list->len; i++) {
+    GstH265Picture *picture =
+        g_array_index (dpb->pic_list, GstH265Picture *, i);
+
+    if (!picture->needed_for_output)
+      continue;
+
+    if (picture->pic_latency_cnt >= max_latency)
+      return TRUE;
+  }
+
+  return FALSE;
+}
+
+/**
+ * gst_h265_dpb_needs_bump:
+ * @dpb: a #GstH265Dpb
+ * @max_num_reorder_pics: sps_max_num_reorder_pics[HighestTid]
+ * @max_latency_increase: SpsMaxLatencyPictures[HighestTid]
+ * @max_dec_pic_buffering: sps_max_dec_pic_buffering_minus1[HighestTid ] + 1
+ *   or zero if this shouldn't be used for bumping decision
+ *
+ * Returns: %TRUE if bumping is required
+ *
+ * Since: 1.20
  */
 gboolean
-gst_h265_dpb_is_full (GstH265Dpb * dpb)
+gst_h265_dpb_needs_bump (GstH265Dpb * dpb, guint max_num_reorder_pics,
+    guint max_latency_increase, guint max_dec_pic_buffering)
 {
-  g_return_val_if_fail (dpb != NULL, -1);
+  g_return_val_if_fail (dpb != NULL, FALSE);
+  g_assert (dpb->num_output_needed >= 0);
+
+  /* If DPB is full and there is no empty space to store current picture,
+   * need bumping.
+   * NOTE: current picture was added already by our decoding flow, so we
+   * need to do bumping until dpb->pic_list->len == dpb->max_num_pic
+   */
+  if (dpb->pic_list->len > dpb->max_num_pics) {
+    GST_TRACE ("No empty frame buffer, need bumping");
+    return TRUE;
+  }
+
+  /* C.5.2.3 */
+  if (dpb->num_output_needed > max_num_reorder_pics) {
+    GST_TRACE ("num_output_needed (%d) > max_num_reorder_pics (%d)",
+        dpb->num_output_needed, max_num_reorder_pics);
+    return TRUE;
+  }
+
+  if (dpb->num_output_needed && max_latency_increase &&
+      gst_h265_dpb_check_latency_count (dpb, max_latency_increase)) {
+    GST_TRACE ("has late picture, max_latency_increase: %d",
+        max_latency_increase);
+    return TRUE;
+  }
+
+  /* C.5.2.2 */
+  if (max_dec_pic_buffering && dpb->pic_list->len >= max_dec_pic_buffering) {
+    GST_TRACE ("dpb size (%d) >= max_dec_pic_buffering (%d)",
+        dpb->pic_list->len, max_dec_pic_buffering);
+    return TRUE;
+  }
+
+  return FALSE;
+}
+
+static gint
+gst_h265_dpb_get_lowest_output_needed_picture (GstH265Dpb * dpb,
+    GstH265Picture ** picture)
+{
+  gint i;
+  GstH265Picture *lowest = NULL;
+  gint index = -1;
+
+  *picture = NULL;
+
+  for (i = 0; i < dpb->pic_list->len; i++) {
+    GstH265Picture *picture =
+        g_array_index (dpb->pic_list, GstH265Picture *, i);
+
+    if (!picture->needed_for_output)
+      continue;
+
+    if (!lowest) {
+      lowest = picture;
+      index = i;
+      continue;
+    }
+
+    if (picture->pic_order_cnt < lowest->pic_order_cnt) {
+      lowest = picture;
+      index = i;
+    }
+  }
+
+  if (lowest)
+    *picture = gst_h265_picture_ref (lowest);
+
+  return index;
+}
+
+/**
+ * gst_h265_dpb_bump:
+ * @dpb: a #GstH265Dpb
+ * @drain: whether draining or not
+ *
+ * Perform bumping process as defined in C.5.2.4 "Bumping" process.
+ * If @drain is %TRUE, @dpb will remove a #GstH265Picture from internal array
+ * so that returned #GstH265Picture could hold the last reference of it
+ *
+ * Returns: (nullable) (transfer full): a #GstH265Picture which is needed to be
+ * outputted
+ *
+ * Since: 1.20
+ */
+GstH265Picture *
+gst_h265_dpb_bump (GstH265Dpb * dpb, gboolean drain)
+{
+  GstH265Picture *picture;
+  gint index;
+
+  g_return_val_if_fail (dpb != NULL, NULL);
+
+  /* C.5.2.4 "Bumping" process */
+  index = gst_h265_dpb_get_lowest_output_needed_picture (dpb, &picture);
+
+  if (!picture || index < 0)
+    return NULL;
+
+  picture->needed_for_output = FALSE;
+
+  dpb->num_output_needed--;
+  g_assert (dpb->num_output_needed >= 0);
+
+  if (!picture->ref || drain)
+    g_array_remove_index_fast (dpb->pic_list, index);
 
-  return dpb->pic_list->len >= dpb->max_num_pics;
+  return picture;
 }
diff --git a/gst-libs/gst/codecs/gsth265picture.h b/gst-libs/gst/codecs/gsth265picture.h
index 38dd5b362..5b007fd4d 100644
--- a/gst-libs/gst/codecs/gsth265picture.h
+++ b/gst-libs/gst/codecs/gsth265picture.h
@@ -27,8 +27,8 @@
 
 #include <gst/gst.h>
 #include <gst/codecs/codecs-prelude.h>
-
 #include <gst/codecparsers/gsth265parser.h>
+#include <gst/video/video.h>
 
 G_BEGIN_DECLS
 
@@ -50,15 +50,9 @@ struct _GstH265Slice
   GstH265NalUnit nalu;
 };
 
-typedef enum
-{
-  GST_H265_PICTURE_FIELD_FRAME,
-  GST_H265_PICTURE_FILED_TOP_FIELD,
-  GST_H265_PICTURE_FIELD_BOTTOM_FIELD,
-} GstH265PictureField;
-
 struct _GstH265Picture
 {
+  /*< private >*/
   GstMiniObject parent;
 
   GstH265SliceType type;
@@ -81,9 +75,14 @@ struct _GstH265Picture
 
   gboolean ref;
   gboolean long_term;
-  gboolean outputted;
+  gboolean needed_for_output;
 
-  GstH265PictureField field;
+  /* from picture timing SEI */
+  GstH265SEIPicStructType pic_struct;
+  guint8 source_scan_type;
+  guint8 duplicate_flag;
+
+  GstVideoBufferFlags buffer_flags;
 
   gpointer user_data;
   GDestroyNotify notify;
@@ -160,10 +159,6 @@ void  gst_h265_dpb_add              (GstH265Dpb * dpb,
 GST_CODECS_API
 void  gst_h265_dpb_delete_unused    (GstH265Dpb * dpb);
 
-GST_CODECS_API
-void  gst_h265_dpb_delete_by_poc    (GstH265Dpb * dpb,
-                                     gint poc);
-
 GST_CODECS_API
 gint  gst_h265_dpb_num_ref_pictures (GstH265Dpb * dpb);
 
@@ -187,17 +182,24 @@ GstH265Picture * gst_h265_dpb_get_long_ref_by_poc  (GstH265Dpb * dpb,
                                                     gint poc);
 
 GST_CODECS_API
-void  gst_h265_dpb_get_pictures_not_outputted  (GstH265Dpb * dpb,
-                                                GList ** out);
+GArray * gst_h265_dpb_get_pictures_all         (GstH265Dpb * dpb);
 
 GST_CODECS_API
-GArray * gst_h265_dpb_get_pictures_all         (GstH265Dpb * dpb);
+GstH265Picture * gst_h265_dpb_get_picture      (GstH265Dpb * dpb,
+                                                guint32 system_frame_number);
 
 GST_CODECS_API
 gint  gst_h265_dpb_get_size   (GstH265Dpb * dpb);
 
 GST_CODECS_API
-gboolean gst_h265_dpb_is_full (GstH265Dpb * dpb);
+gboolean gst_h265_dpb_needs_bump (GstH265Dpb * dpb,
+                                  guint max_num_reorder_pics,
+                                  guint max_latency_increase,
+                                  guint max_dec_pic_buffering);
+
+GST_CODECS_API
+GstH265Picture * gst_h265_dpb_bump (GstH265Dpb * dpb,
+                                    gboolean drain);
 
 G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstH265Picture, gst_h265_picture_unref)
 
diff --git a/sys/nvcodec/gstnvh264dec.c b/sys/nvcodec/gstnvh264dec.c
index 8105e7883..169e740a9 100644
--- a/sys/nvcodec/gstnvh264dec.c
+++ b/sys/nvcodec/gstnvh264dec.c
@@ -699,6 +699,8 @@ gst_nv_h264_dec_start_picture (GstH264Decoder * decoder,
     h264_params->dpb[i].PicIdx = -1;
 
   dpb_array = gst_h264_dpb_get_pictures_all (dpb);
+  g_return_val_if_fail (dpb_array != NULL, NULL);
+
   for (i = 0; i < dpb_array->len && i < G_N_ELEMENTS (h264_params->dpb); i++) {
     GstH264Picture *other = g_array_index (dpb_array, GstH264Picture *, i);
     GstNvDecoderFrame *other_frame;
diff --git a/sys/v4l2codecs/gstv4l2codecallocator.c b/sys/v4l2codecs/gstv4l2codecallocator.c
index d18e8bb70..e2886989c 100644
--- a/sys/v4l2codecs/gstv4l2codecallocator.c
+++ b/sys/v4l2codecs/gstv4l2codecallocator.c
@@ -90,7 +90,8 @@ gst_v4l2_codec_buffer_new (GstAllocator * allocator, GstV4l2Decoder * decoder,
   buf->index = index;
   buf->num_mems = num_mems;
   for (i = 0; i < buf->num_mems; i++) {
-    GstMemory *mem = gst_dmabuf_allocator_alloc (allocator, fds[i], sizes[i]);
+    GstMemory *mem = gst_fd_allocator_alloc (allocator, fds[i], sizes[i],
+        GST_FD_MEMORY_FLAG_KEEP_MAPPED);
     gst_memory_resize (mem, offsets[i], sizes[i] - offsets[i]);
 
     GST_MINI_OBJECT (mem)->dispose = gst_v4l2_codec_allocator_release;
diff --git a/sys/v4l2codecs/gstv4l2codecalphadecodebin.c b/sys/v4l2codecs/gstv4l2codecalphadecodebin.c
new file mode 100644
index 000000000..72927d820
--- /dev/null
+++ b/sys/v4l2codecs/gstv4l2codecalphadecodebin.c
@@ -0,0 +1,231 @@
+/* GStreamer
+ * Copyright (C) <2021> Collabora Ltd.
+ *   Author: Daniel Almeida <daniel.almeida@collabora.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include <gst/pbutils/pbutils.h>
+
+#include "gstv4l2codecalphadecodebin.h"
+#include "gstv4l2decoder.h"
+
+GST_DEBUG_CATEGORY_STATIC (v4l2_codecalphadecodebin_debug);
+#define GST_CAT_DEFAULT (v4l2_codecalphadecodebin_debug)
+
+typedef struct
+{
+  GstBin parent;
+
+  gboolean constructed;
+  const gchar *missing_element;
+} GstV4l2CodecAlphaDecodeBinPrivate;
+
+#define gst_v4l2_codec_alpha_decode_bin_parent_class parent_class
+G_DEFINE_ABSTRACT_TYPE_WITH_CODE (GstV4l2CodecAlphaDecodeBin,
+    gst_v4l2_codec_alpha_decode_bin, GST_TYPE_BIN,
+    G_ADD_PRIVATE (GstV4l2CodecAlphaDecodeBin);
+    GST_DEBUG_CATEGORY_INIT (v4l2_codecalphadecodebin_debug,
+        "v4l2codecs-alphadecodebin", 0, "V4L2 stateless alpha decode bin"));
+
+
+static GstStaticPadTemplate gst_alpha_decode_bin_src_template =
+GST_STATIC_PAD_TEMPLATE ("src",
+    GST_PAD_SRC,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS ("ANY")
+    );
+
+static gboolean
+gst_v4l2_codec_alpha_decode_bin_open (GstV4l2CodecAlphaDecodeBin * self)
+{
+  GstV4l2CodecAlphaDecodeBinPrivate *priv =
+      gst_v4l2_codec_alpha_decode_bin_get_instance_private (self);
+
+  if (priv->missing_element) {
+    gst_element_post_message (GST_ELEMENT (self),
+        gst_missing_element_message_new (GST_ELEMENT (self),
+            priv->missing_element));
+  } else if (!priv->constructed) {
+    GST_ELEMENT_ERROR (self, CORE, FAILED,
+        ("Failed to construct alpha decoder pipeline."), (NULL));
+  }
+
+  return priv->constructed;
+}
+
+static GstStateChangeReturn
+gst_v4l2_codec_alpha_decode_bin_change_state (GstElement * element,
+    GstStateChange transition)
+{
+  GstV4l2CodecAlphaDecodeBin *self = GST_V4L2_CODEC_ALPHA_DECODE_BIN (element);
+
+  switch (transition) {
+    case GST_STATE_CHANGE_NULL_TO_READY:
+      if (!gst_v4l2_codec_alpha_decode_bin_open (self))
+        return GST_STATE_CHANGE_FAILURE;
+      break;
+    default:
+      break;
+  }
+
+  return GST_ELEMENT_CLASS (parent_class)->change_state (element, transition);
+}
+
+static void
+gst_v4l2_codec_alpha_decode_bin_constructed (GObject * obj)
+{
+  GstV4l2CodecAlphaDecodeBin *self = GST_V4L2_CODEC_ALPHA_DECODE_BIN (obj);
+  GstV4l2CodecAlphaDecodeBinPrivate *priv =
+      gst_v4l2_codec_alpha_decode_bin_get_instance_private (self);
+  GstV4l2CodecAlphaDecodeBinClass *klass =
+      GST_V4L2_CODEC_ALPHA_DECODE_BIN_GET_CLASS (self);
+  GstPad *src_gpad, *sink_gpad;
+  GstPad *src_pad = NULL, *sink_pad = NULL;
+  GstElement *alphademux = NULL;
+  GstElement *queue = NULL;
+  GstElement *alpha_queue = NULL;
+  GstElement *decoder = NULL;
+  GstElement *alpha_decoder = NULL;
+  GstElement *alphacombine = NULL;
+
+  /* setup ghost pads */
+  sink_gpad = gst_ghost_pad_new_no_target_from_template ("sink",
+      gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), "sink"));
+  gst_element_add_pad (GST_ELEMENT (self), sink_gpad);
+
+  src_gpad = gst_ghost_pad_new_no_target_from_template ("src",
+      gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), "src"));
+  gst_element_add_pad (GST_ELEMENT (self), src_gpad);
+
+  /* create elements */
+  alphademux = gst_element_factory_make ("codecalphademux", NULL);
+  if (!alphademux) {
+    priv->missing_element = "codecalphademux";
+    goto cleanup;
+  }
+
+  queue = gst_element_factory_make ("queue", NULL);
+  alpha_queue = gst_element_factory_make ("queue", NULL);
+  if (!queue || !alpha_queue) {
+    priv->missing_element = "queue";
+    goto cleanup;
+  }
+
+  decoder = gst_element_factory_make (klass->decoder_name, "maindec");
+  if (!decoder) {
+    priv->missing_element = klass->decoder_name;
+    goto cleanup;
+  }
+
+  alpha_decoder = gst_element_factory_make (klass->decoder_name, "alphadec");
+  if (!alpha_decoder) {
+    priv->missing_element = klass->decoder_name;
+    goto cleanup;
+  }
+
+  /* We disable QoS on decoders because we need to maintain frame pairing in
+   * order for alphacombine to work. */
+  g_object_set (decoder, "qos", FALSE, NULL);
+  g_object_set (alpha_decoder, "qos", FALSE, NULL);
+
+  alphacombine = gst_element_factory_make ("alphacombine", NULL);
+  if (!alphacombine) {
+    priv->missing_element = "alphacombine";
+    goto cleanup;
+  }
+
+  gst_bin_add_many (GST_BIN (self), alphademux, queue, alpha_queue, decoder,
+      alpha_decoder, alphacombine, NULL);
+
+  /* link elements */
+  sink_pad = gst_element_get_static_pad (alphademux, "sink");
+  gst_ghost_pad_set_target (GST_GHOST_PAD (sink_gpad), sink_pad);
+  gst_clear_object (&sink_pad);
+
+  gst_element_link_pads (alphademux, "src", queue, "sink");
+  gst_element_link_pads (queue, "src", decoder, "sink");
+  gst_element_link_pads (decoder, "src", alphacombine, "sink");
+
+  gst_element_link_pads (alphademux, "alpha", alpha_queue, "sink");
+  gst_element_link_pads (alpha_queue, "src", alpha_decoder, "sink");
+  gst_element_link_pads (alpha_decoder, "src", alphacombine, "alpha");
+
+  src_pad = gst_element_get_static_pad (alphacombine, "src");
+  gst_ghost_pad_set_target (GST_GHOST_PAD (src_gpad), src_pad);
+  gst_object_unref (src_pad);
+
+  g_object_set (queue, "max-size-bytes", 0, "max-size-time", 0,
+      "max-size-buffers", 1, NULL);
+  g_object_set (alpha_queue, "max-size-bytes", 0, "max-size-time", 0,
+      "max-size-buffers", 1, NULL);
+
+  /* signal success, we will handle this in NULL->READY transition */
+  priv->constructed = TRUE;
+  return;
+
+cleanup:
+  gst_clear_object (&alphademux);
+  gst_clear_object (&queue);
+  gst_clear_object (&alpha_queue);
+  gst_clear_object (&decoder);
+  gst_clear_object (&alpha_decoder);
+  gst_clear_object (&alphacombine);
+
+  G_OBJECT_CLASS (parent_class)->constructed (obj);
+}
+
+static void
+gst_v4l2_codec_alpha_decode_bin_class_init (GstV4l2CodecAlphaDecodeBinClass *
+    klass)
+{
+  GstElementClass *element_class = (GstElementClass *) klass;
+  GObjectClass *obj_class = (GObjectClass *) klass;
+
+  /* This is needed to access the subclass class instance, otherwise we cannot
+   * read the class parameters */
+  obj_class->constructed = gst_v4l2_codec_alpha_decode_bin_constructed;
+
+  gst_element_class_add_static_pad_template (element_class,
+      &gst_alpha_decode_bin_src_template);
+  element_class->change_state =
+      GST_DEBUG_FUNCPTR (gst_v4l2_codec_alpha_decode_bin_change_state);
+
+  /* let's make the doc generator happy */
+  gst_type_mark_as_plugin_api (GST_TYPE_V4L2_CODEC_ALPHA_DECODE_BIN, 0);
+}
+
+static void
+gst_v4l2_codec_alpha_decode_bin_init (GstV4l2CodecAlphaDecodeBin * self)
+{
+}
+
+void
+gst_v4l2_codec_alpha_decode_bin_register (GstPlugin * plugin,
+    GClassInitFunc class_init, gconstpointer class_data,
+    const gchar * element_name_tmpl, GstV4l2CodecDevice * device, guint rank)
+{
+  /* TODO check that we have compatible src format */
+
+  gst_v4l2_decoder_register (plugin,
+      GST_TYPE_V4L2_CODEC_ALPHA_DECODE_BIN, class_init, class_data, NULL,
+      element_name_tmpl, device,
+      rank + GST_V4L2_CODEC_ALPHA_DECODE_BIN_RANK_OFFSET, NULL);
+}
diff --git a/sys/v4l2codecs/gstv4l2codecalphadecodebin.h b/sys/v4l2codecs/gstv4l2codecalphadecodebin.h
new file mode 100644
index 000000000..e6728cb38
--- /dev/null
+++ b/sys/v4l2codecs/gstv4l2codecalphadecodebin.h
@@ -0,0 +1,57 @@
+/* GStreamer
+ * Copyright (C) <2021> Collabora Ltd.
+ *   Author: Daniel Almeida <daniel.almeida@collabora.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef __GST_V4L2_CODEC_ALPHA_DECODE_BIN_H__
+#define __GST_V4L2_CODEC_ALPHA_DECODE_BIN_H__
+
+#include <gst/gst.h>
+#include <gstv4l2decoder.h>
+
+/* When wrapping, use the original rank plus this offset. The ad-hoc rules is
+ * that hardware implementation will use PRIMARY+1 or +2 to override the
+ * software decoder, so the offset must be large enough to jump over those.
+ * This should also be small enough so that a marginal (64) or secondary
+ * wrapper does not cross the PRIMARY line.
+ */
+#define GST_V4L2_CODEC_ALPHA_DECODE_BIN_RANK_OFFSET 10
+
+G_BEGIN_DECLS
+
+#define GST_TYPE_V4L2_CODEC_ALPHA_DECODE_BIN (gst_v4l2_codec_alpha_decode_bin_get_type())
+G_DECLARE_DERIVABLE_TYPE (GstV4l2CodecAlphaDecodeBin,
+    gst_v4l2_codec_alpha_decode_bin, GST, V4L2_CODEC_ALPHA_DECODE_BIN, GstBin);
+
+struct _GstV4l2CodecAlphaDecodeBinClass
+{
+  GstBinClass parent_class;
+  gchar *decoder_name;
+};
+
+void gst_v4l2_codec_alpha_decode_bin_register (GstPlugin * plugin,
+                                               GClassInitFunc class_init,
+                                               gconstpointer class_data,
+                                               const gchar * element_name_tmpl, 
+                                               GstV4l2CodecDevice * device,
+                                               guint rank);
+
+
+
+G_END_DECLS
+#endif /* __GST_V4L2_CODEC_ALPHA_DECODE_BIN_H__ */
diff --git a/sys/v4l2codecs/gstv4l2codech264dec.c b/sys/v4l2codecs/gstv4l2codech264dec.c
index 4f40af413..b9942860b 100644
--- a/sys/v4l2codecs/gstv4l2codech264dec.c
+++ b/sys/v4l2codecs/gstv4l2codech264dec.c
@@ -24,7 +24,13 @@
 #include "gstv4l2codecallocator.h"
 #include "gstv4l2codech264dec.h"
 #include "gstv4l2codecpool.h"
-#include "linux/h264-ctrls.h"
+#include "linux/v4l2-controls.h"
+
+#define KERNEL_VERSION(a,b,c) (((a) << 16) + ((b) << 8) + (c))
+
+#define V4L2_MIN_KERNEL_VER_MAJOR 5
+#define V4L2_MIN_KERNEL_VER_MINOR 11
+#define V4L2_MIN_KERNEL_VERSION KERNEL_VERSION(V4L2_MIN_KERNEL_VER_MAJOR, V4L2_MIN_KERNEL_VER_MINOR, 0)
 
 GST_DEBUG_CATEGORY_STATIC (v4l2_h264dec_debug);
 #define GST_CAT_DEFAULT v4l2_h264dec_debug
@@ -60,6 +66,8 @@ struct _GstV4l2CodecH264Dec
   gint coded_height;
   guint bitdepth;
   guint chroma_format_idc;
+  guint num_slices;
+  gboolean first_slice;
 
   GstV4l2CodecAllocator *sink_allocator;
   GstV4l2CodecAllocator *src_allocator;
@@ -67,16 +75,20 @@ struct _GstV4l2CodecH264Dec
   gint min_pool_size;
   gboolean has_videometa;
   gboolean need_negotiation;
+  gboolean interlaced;
+  gboolean need_sequence;
   gboolean copy_frames;
+  gboolean scaling_matrix_present;
 
   struct v4l2_ctrl_h264_sps sps;
   struct v4l2_ctrl_h264_pps pps;
   struct v4l2_ctrl_h264_scaling_matrix scaling_matrix;
   struct v4l2_ctrl_h264_decode_params decode_params;
+  struct v4l2_ctrl_h264_pred_weights pred_weight;
   GArray *slice_params;
 
-  enum v4l2_mpeg_video_h264_decode_mode decode_mode;
-  enum v4l2_mpeg_video_h264_start_code start_code;
+  enum v4l2_stateless_h264_decode_mode decode_mode;
+  enum v4l2_stateless_h264_start_code start_code;
 
   GstMemory *bitstream;
   GstMapInfo bitstream_map;
@@ -91,33 +103,85 @@ G_DEFINE_ABSTRACT_TYPE_WITH_CODE (GstV4l2CodecH264Dec,
 static gboolean
 is_frame_based (GstV4l2CodecH264Dec * self)
 {
-  return self->decode_mode == V4L2_MPEG_VIDEO_H264_DECODE_MODE_FRAME_BASED;
+  return self->decode_mode == V4L2_STATELESS_H264_DECODE_MODE_FRAME_BASED;
 }
 
 static gboolean
 is_slice_based (GstV4l2CodecH264Dec * self)
 {
-  return self->decode_mode == V4L2_MPEG_VIDEO_H264_DECODE_MODE_SLICE_BASED;
+  return self->decode_mode == V4L2_STATELESS_H264_DECODE_MODE_SLICE_BASED;
 }
 
 static gboolean
 needs_start_codes (GstV4l2CodecH264Dec * self)
 {
-  return self->start_code == V4L2_MPEG_VIDEO_H264_START_CODE_ANNEX_B;
+  return self->start_code == V4L2_STATELESS_H264_START_CODE_ANNEX_B;
 }
 
 
+static gboolean
+gst_v4l2_decoder_h264_api_check (GstV4l2CodecH264Dec * self)
+{
+  guint i, ret_size;
+  /* *INDENT-OFF* */
+  struct
+  {
+    unsigned int id;
+    unsigned int size;
+  } controls[] = {
+    {
+      .id = V4L2_CID_STATELESS_H264_SPS,
+      .size = sizeof(struct v4l2_ctrl_h264_sps),
+    }, {
+      .id = V4L2_CID_STATELESS_H264_PPS,
+      .size = sizeof(struct v4l2_ctrl_h264_pps),
+    }, {
+      .id = V4L2_CID_STATELESS_H264_SCALING_MATRIX,
+      .size = sizeof(struct v4l2_ctrl_h264_scaling_matrix),
+    }, {
+      .id = V4L2_CID_STATELESS_H264_DECODE_PARAMS,
+      .size = sizeof(struct v4l2_ctrl_h264_decode_params),
+    }, {
+      .id = V4L2_CID_STATELESS_H264_SLICE_PARAMS,
+      .size = sizeof(struct v4l2_ctrl_h264_slice_params),
+    }, {
+      .id = V4L2_CID_STATELESS_H264_PRED_WEIGHTS,
+      .size = sizeof(struct v4l2_ctrl_h264_pred_weights),
+    }
+  };
+  /* *INDENT-ON* */
+
+  /*
+   * Compatibility check: make sure the pointer controls are
+   * the right size.
+   */
+  for (i = 0; i < G_N_ELEMENTS (controls); i++) {
+    if (gst_v4l2_decoder_query_control_size (self->decoder, controls[i].id,
+            &ret_size) && ret_size != controls[i].size) {
+      GST_ELEMENT_ERROR (self, RESOURCE, OPEN_READ_WRITE,
+          ("H264 API mismatch!"),
+          ("%d control size mismatch: got %d bytes but %d expected.",
+              controls[i].id, ret_size, controls[i].size));
+      return FALSE;
+    }
+  }
+
+  return TRUE;
+}
+
 static gboolean
 gst_v4l2_codec_h264_dec_open (GstVideoDecoder * decoder)
 {
   GstV4l2CodecH264Dec *self = GST_V4L2_CODEC_H264_DEC (decoder);
+  guint version;
+
   /* *INDENT-OFF* */
   struct v4l2_ext_control control[] = {
     {
-      .id = V4L2_CID_MPEG_VIDEO_H264_DECODE_MODE,
+      .id = V4L2_CID_STATELESS_H264_DECODE_MODE,
     },
     {
-      .id = V4L2_CID_MPEG_VIDEO_H264_START_CODE,
+      .id = V4L2_CID_STATELESS_H264_START_CODE,
     },
   };
   /* *INDENT-ON* */
@@ -129,6 +193,20 @@ gst_v4l2_codec_h264_dec_open (GstVideoDecoder * decoder)
     return FALSE;
   }
 
+  version = gst_v4l2_decoder_get_version (self->decoder);
+  if (version < V4L2_MIN_KERNEL_VERSION)
+    GST_WARNING_OBJECT (self,
+        "V4L2 API v%u.%u too old, at least v%u.%u required",
+        (version >> 16) & 0xff, (version >> 8) & 0xff,
+        V4L2_MIN_KERNEL_VER_MAJOR, V4L2_MIN_KERNEL_VER_MINOR);
+
+  if (!gst_v4l2_decoder_h264_api_check (self)) {
+    GST_ELEMENT_ERROR (self, RESOURCE, OPEN_READ_WRITE,
+        ("Failed to open H264 decoder"),
+        ("gst_v4l2_decoder_h264_api_check() failed"));
+    return FALSE;
+  }
+
   if (!gst_v4l2_decoder_get_controls (self->decoder, control,
           G_N_ELEMENTS (control))) {
     GST_ELEMENT_ERROR (self, RESOURCE, OPEN_READ_WRITE,
@@ -229,7 +307,7 @@ gst_v4l2_codec_h264_dec_negotiate (GstVideoDecoder * decoder)
   /* *INDENT-OFF* */
   struct v4l2_ext_control control[] = {
     {
-      .id = V4L2_CID_MPEG_VIDEO_H264_SPS,
+      .id = V4L2_CID_STATELESS_H264_SPS,
       .ptr = &self->sps,
       .size = sizeof (self->sps),
     },
@@ -295,6 +373,9 @@ gst_v4l2_codec_h264_dec_negotiate (GstVideoDecoder * decoder)
       self->vinfo.finfo->format, self->display_width,
       self->display_height, h264dec->input_state);
 
+  if (self->interlaced)
+    self->output_state->info.interlace_mode = GST_VIDEO_INTERLACE_MODE_MIXED;
+
   self->output_state->caps = gst_video_info_to_caps (&self->output_state->info);
 
   if (GST_VIDEO_DECODER_CLASS (parent_class)->negotiate (decoder)) {
@@ -323,7 +404,7 @@ gst_v4l2_codec_h264_dec_decide_allocation (GstVideoDecoder * decoder,
     GstQuery * query)
 {
   GstV4l2CodecH264Dec *self = GST_V4L2_CODEC_H264_DEC (decoder);
-  guint min = 0;
+  guint min = 0, num_bitstream;
 
   self->has_videometa = gst_query_find_allocation_meta (query,
       GST_VIDEO_META_API_TYPE, NULL);
@@ -334,10 +415,13 @@ gst_v4l2_codec_h264_dec_decide_allocation (GstVideoDecoder * decoder,
   if (gst_query_get_n_allocation_pools (query) > 0)
     gst_query_parse_nth_allocation_pool (query, 0, NULL, NULL, &min, NULL);
 
-  min = MAX (2, min);
+  min = MAX (8, min);
+
+  num_bitstream = 1 +
+      MAX (8, gst_v4l2_decoder_get_render_delay (self->decoder));
 
   self->sink_allocator = gst_v4l2_codec_allocator_new (self->decoder,
-      GST_PAD_SINK, self->min_pool_size + 2);
+      GST_PAD_SINK, num_bitstream);
   self->src_allocator = gst_v4l2_codec_allocator_new (self->decoder,
       GST_PAD_SRC, self->min_pool_size + min + 4);
   self->src_pool = gst_v4l2_codec_pool_new (self->src_allocator, &self->vinfo);
@@ -413,7 +497,7 @@ gst_v4l2_codec_h264_dec_fill_pps (GstV4l2CodecH264Dec * self, GstH264PPS * pps)
         | (pps->constrained_intra_pred_flag ? V4L2_H264_PPS_FLAG_CONSTRAINED_INTRA_PRED : 0)
         | (pps->redundant_pic_cnt_present_flag ? V4L2_H264_PPS_FLAG_REDUNDANT_PIC_CNT_PRESENT : 0)
         | (pps->transform_8x8_mode_flag ? V4L2_H264_PPS_FLAG_TRANSFORM_8X8_MODE : 0)
-        | (pps->pic_scaling_matrix_present_flag ? V4L2_H264_PPS_FLAG_PIC_SCALING_MATRIX_PRESENT : 0),
+        | (self->scaling_matrix_present ? V4L2_H264_PPS_FLAG_SCALING_MATRIX_PRESENT : 0),
   };
   /* *INDENT-ON* */
 }
@@ -446,26 +530,59 @@ gst_v4l2_codec_h264_dec_fill_decoder_params (GstV4l2CodecH264Dec * self,
     GstH264SliceHdr * slice_hdr, GstH264Picture * picture, GstH264Dpb * dpb)
 {
   GArray *refs = gst_h264_dpb_get_pictures_all (dpb);
-  gint i;
+  gint i, entry_id = 0;
 
   /* *INDENT-OFF* */
   self->decode_params = (struct v4l2_ctrl_h264_decode_params) {
-    .num_slices = 0,            /* will be incremented as we receive slices */
     .nal_ref_idc = picture->nal_ref_idc,
-    .top_field_order_cnt = picture->top_field_order_cnt,
-    .bottom_field_order_cnt = picture->bottom_field_order_cnt,
-    .flags = picture->idr ? V4L2_H264_DECODE_PARAM_FLAG_IDR_PIC : 0,
+    .frame_num = slice_hdr->frame_num,
+    .idr_pic_id = slice_hdr->idr_pic_id,
+    .pic_order_cnt_lsb = slice_hdr->pic_order_cnt_lsb,
+    .delta_pic_order_cnt_bottom = slice_hdr->delta_pic_order_cnt_bottom,
+    .delta_pic_order_cnt0 = slice_hdr->delta_pic_order_cnt[0],
+    .delta_pic_order_cnt1 = slice_hdr->delta_pic_order_cnt[1],
+    .dec_ref_pic_marking_bit_size = slice_hdr->dec_ref_pic_marking.bit_size,
+    .pic_order_cnt_bit_size = slice_hdr->pic_order_cnt_bit_size,
+    .slice_group_change_cycle = slice_hdr->slice_group_change_cycle,
+    .flags = (picture->idr ? V4L2_H264_DECODE_PARAM_FLAG_IDR_PIC : 0) |
+             (slice_hdr->field_pic_flag ? V4L2_H264_DECODE_PARAM_FLAG_FIELD_PIC : 0) |
+             (slice_hdr->bottom_field_flag ? V4L2_H264_DECODE_PARAM_FLAG_BOTTOM_FIELD : 0),
   };
 
+  switch (picture->field) {
+    case GST_H264_PICTURE_FIELD_FRAME:
+      self->decode_params.top_field_order_cnt = picture->top_field_order_cnt;
+      self->decode_params.bottom_field_order_cnt =
+        picture->bottom_field_order_cnt;
+      break;
+    case GST_H264_PICTURE_FIELD_TOP_FIELD:
+      self->decode_params.top_field_order_cnt = picture->top_field_order_cnt;
+      self->decode_params.bottom_field_order_cnt = 0;
+      break;
+    case GST_H264_PICTURE_FIELD_BOTTOM_FIELD:
+      self->decode_params.top_field_order_cnt = 0;
+      self->decode_params.bottom_field_order_cnt =
+          picture->bottom_field_order_cnt;
+      break;
+  }
+
+  g_return_val_if_fail (refs != NULL, NULL);
+
   for (i = 0; i < refs->len; i++) {
     GstH264Picture *ref_pic = g_array_index (refs, GstH264Picture *, i);
     gint pic_num = ref_pic->pic_num;
+    struct v4l2_h264_dpb_entry *entry;
 
-    /* Unwrap pic_num */
-    if (pic_num < 0)
-      pic_num += slice_hdr->max_pic_num;
+    /* Skip non-reference as they are not useful to decoding */
+    if (!GST_H264_PICTURE_IS_REF (ref_pic))
+      continue;
 
-    self->decode_params.dpb[i] = (struct v4l2_h264_dpb_entry) {
+    /* The second field picture will be handled differently */
+    if (ref_pic->second_field)
+      continue;
+
+    entry = &self->decode_params.dpb[entry_id++];
+    *entry = (struct v4l2_h264_dpb_entry) {
       /*
        * The reference is multiplied by 1000 because it's wassed as micro
        * seconds and this TS is nanosecond.
@@ -473,18 +590,102 @@ gst_v4l2_codec_h264_dec_fill_decoder_params (GstV4l2CodecH264Dec * self,
       .reference_ts = (guint64) ref_pic->system_frame_number * 1000,
       .frame_num = ref_pic->frame_num,
       .pic_num = pic_num,
-      .top_field_order_cnt = ref_pic->pic_order_cnt,
-      .bottom_field_order_cnt = ref_pic->bottom_field_order_cnt,
       .flags = V4L2_H264_DPB_ENTRY_FLAG_VALID
-          | (ref_pic->ref ? V4L2_H264_DPB_ENTRY_FLAG_ACTIVE : 0)
-          | (ref_pic->long_term ? V4L2_H264_DPB_ENTRY_FLAG_LONG_TERM : 0),
+          | (GST_H264_PICTURE_IS_REF (ref_pic) ? V4L2_H264_DPB_ENTRY_FLAG_ACTIVE : 0)
+          | (GST_H264_PICTURE_IS_LONG_TERM_REF (ref_pic) ? V4L2_H264_DPB_ENTRY_FLAG_LONG_TERM : 0),
     };
+
+    switch (ref_pic->field) {
+      case GST_H264_PICTURE_FIELD_FRAME:
+        entry->top_field_order_cnt = ref_pic->top_field_order_cnt;
+        entry->bottom_field_order_cnt = ref_pic->bottom_field_order_cnt;
+        entry->fields = V4L2_H264_FRAME_REF;
+        break;
+      case GST_H264_PICTURE_FIELD_TOP_FIELD:
+        entry->top_field_order_cnt = ref_pic->top_field_order_cnt;
+        entry->fields = V4L2_H264_TOP_FIELD_REF;
+
+        if (ref_pic->other_field) {
+          entry->bottom_field_order_cnt =
+              ref_pic->other_field->bottom_field_order_cnt;
+          entry->fields |= V4L2_H264_BOTTOM_FIELD_REF;
+        } else {
+          entry->flags |= V4L2_H264_DPB_ENTRY_FLAG_FIELD;
+        }
+        break;
+      case GST_H264_PICTURE_FIELD_BOTTOM_FIELD:
+        entry->bottom_field_order_cnt = ref_pic->bottom_field_order_cnt;
+        entry->fields = V4L2_H264_BOTTOM_FIELD_REF;
+
+        if (ref_pic->other_field) {
+          entry->top_field_order_cnt =
+            ref_pic->other_field->top_field_order_cnt;
+          entry->fields |= V4L2_H264_TOP_FIELD_REF;
+        } else {
+          entry->flags |= V4L2_H264_DPB_ENTRY_FLAG_FIELD;
+        }
+        break;
+    }
   }
   /* *INDENT-ON* */
 
   g_array_unref (refs);
 }
 
+static void
+gst_v4l2_codec_h264_dec_fill_pred_weight (GstV4l2CodecH264Dec * self,
+    GstH264SliceHdr * slice_hdr)
+{
+  gint i, j;
+
+  /* *INDENT-OFF* */
+  self->pred_weight = (struct v4l2_ctrl_h264_pred_weights) {
+    .luma_log2_weight_denom = slice_hdr->pred_weight_table.luma_log2_weight_denom,
+    .chroma_log2_weight_denom = slice_hdr->pred_weight_table.chroma_log2_weight_denom,
+  };
+  /* *INDENT-ON* */
+
+  for (i = 0; i <= slice_hdr->num_ref_idx_l0_active_minus1; i++) {
+    self->pred_weight.weight_factors[0].luma_weight[i] =
+        slice_hdr->pred_weight_table.luma_weight_l0[i];
+    self->pred_weight.weight_factors[0].luma_offset[i] =
+        slice_hdr->pred_weight_table.luma_offset_l0[i];
+  }
+
+  if (slice_hdr->pps->sequence->chroma_array_type != 0) {
+    for (i = 0; i <= slice_hdr->num_ref_idx_l0_active_minus1; i++) {
+      for (j = 0; j < 2; j++) {
+        self->pred_weight.weight_factors[0].chroma_weight[i][j] =
+            slice_hdr->pred_weight_table.chroma_weight_l0[i][j];
+        self->pred_weight.weight_factors[0].chroma_offset[i][j] =
+            slice_hdr->pred_weight_table.chroma_offset_l0[i][j];
+      }
+    }
+  }
+
+  /* Skip l1 if this is not a B-Frames. */
+  if (slice_hdr->type % 5 != GST_H264_B_SLICE)
+    return;
+
+  for (i = 0; i <= slice_hdr->num_ref_idx_l1_active_minus1; i++) {
+    self->pred_weight.weight_factors[1].luma_weight[i] =
+        slice_hdr->pred_weight_table.luma_weight_l1[i];
+    self->pred_weight.weight_factors[1].luma_offset[i] =
+        slice_hdr->pred_weight_table.luma_offset_l1[i];
+  }
+
+  if (slice_hdr->pps->sequence->chroma_array_type != 0) {
+    for (i = 0; i <= slice_hdr->num_ref_idx_l1_active_minus1; i++) {
+      for (j = 0; j < 2; j++) {
+        self->pred_weight.weight_factors[1].chroma_weight[i][j] =
+            slice_hdr->pred_weight_table.chroma_weight_l1[i][j];
+        self->pred_weight.weight_factors[1].chroma_offset[i][j] =
+            slice_hdr->pred_weight_table.chroma_offset_l1[i][j];
+      }
+    }
+  }
+}
+
 static guint
 get_slice_header_bit_size (GstH264Slice * slice)
 {
@@ -492,17 +693,30 @@ get_slice_header_bit_size (GstH264Slice * slice)
       - 8 * slice->header.n_emulation_prevention_bytes;
 }
 
+static void
+gst_v4l2_codec_h246_dec_complete_slice_params (GstV4l2CodecH264Dec * self,
+    GstH264Slice * slice)
+{
+  gint n = self->num_slices - 1;
+  struct v4l2_ctrl_h264_slice_params *params;
+
+  params =
+      &g_array_index (self->slice_params, struct v4l2_ctrl_h264_slice_params,
+      n);
+
+  params->next_slice_first_mb = slice->header.first_mb_in_slice;
+}
+
 static void
 gst_v4l2_codec_h264_dec_fill_slice_params (GstV4l2CodecH264Dec * self,
     GstH264Slice * slice)
 {
-  gint n = self->decode_params.num_slices++;
+  gint n = self->num_slices++;
   gsize slice_size = slice->nalu.size;
   struct v4l2_ctrl_h264_slice_params *params;
-  gint i, j;
 
   /* Ensure array is large enough */
-  if (self->slice_params->len < self->decode_params.num_slices)
+  if (self->slice_params->len < self->num_slices)
     g_array_set_size (self->slice_params, self->slice_params->len * 2);
 
   if (needs_start_codes (self))
@@ -511,26 +725,11 @@ gst_v4l2_codec_h264_dec_fill_slice_params (GstV4l2CodecH264Dec * self,
   /* *INDENT-OFF* */
   params = &g_array_index (self->slice_params, struct v4l2_ctrl_h264_slice_params, n);
   *params = (struct v4l2_ctrl_h264_slice_params) {
-    .size = slice_size,
-    .start_byte_offset = self->bitstream_map.size,
     .header_bit_size = get_slice_header_bit_size (slice),
     .first_mb_in_slice = slice->header.first_mb_in_slice,
     .slice_type = slice->header.type % 5,
-    .pic_parameter_set_id = slice->header.pps->id,
     .colour_plane_id = slice->header.colour_plane_id,
     .redundant_pic_cnt = slice->header.redundant_pic_cnt,
-    .frame_num = slice->header.frame_num,
-    .idr_pic_id = slice->header.idr_pic_id,
-    .pic_order_cnt_lsb = slice->header.pic_order_cnt_lsb,
-    .delta_pic_order_cnt_bottom = slice->header.delta_pic_order_cnt_bottom,
-    .delta_pic_order_cnt0 = slice->header.delta_pic_order_cnt[0],
-    .delta_pic_order_cnt1 = slice->header.delta_pic_order_cnt[1],
-    .pred_weight_table = (struct v4l2_h264_pred_weight_table) {
-      .luma_log2_weight_denom = slice->header.pred_weight_table.luma_log2_weight_denom,
-      .chroma_log2_weight_denom = slice->header.pred_weight_table.chroma_log2_weight_denom,
-    },
-    .dec_ref_pic_marking_bit_size = slice->header.dec_ref_pic_marking.bit_size,
-    .pic_order_cnt_bit_size = slice->header.pic_order_cnt_bit_size,
     .cabac_init_idc = slice->header.cabac_init_idc,
     .slice_qp_delta = slice->header.slice_qp_delta,
     .slice_qs_delta = slice->header.slice_qs_delta,
@@ -539,54 +738,10 @@ gst_v4l2_codec_h264_dec_fill_slice_params (GstV4l2CodecH264Dec * self,
     .slice_beta_offset_div2 = slice->header.slice_beta_offset_div2,
     .num_ref_idx_l0_active_minus1 = slice->header.num_ref_idx_l0_active_minus1,
     .num_ref_idx_l1_active_minus1 = slice->header.num_ref_idx_l1_active_minus1,
-    .slice_group_change_cycle = slice->header.slice_group_change_cycle,
-
-    .flags = (slice->header.field_pic_flag ? V4L2_H264_SLICE_FLAG_FIELD_PIC : 0) |
-             (slice->header.bottom_field_flag ? V4L2_H264_SLICE_FLAG_BOTTOM_FIELD : 0) |
-             (slice->header.direct_spatial_mv_pred_flag ? V4L2_H264_SLICE_FLAG_DIRECT_SPATIAL_MV_PRED : 0) |
+    .flags = (slice->header.direct_spatial_mv_pred_flag ? V4L2_H264_SLICE_FLAG_DIRECT_SPATIAL_MV_PRED : 0) |
              (slice->header.sp_for_switch_flag ? V4L2_H264_SLICE_FLAG_SP_FOR_SWITCH : 0),
   };
   /* *INDENT-ON* */
-
-  for (i = 0; i <= slice->header.num_ref_idx_l0_active_minus1; i++) {
-    params->pred_weight_table.weight_factors[0].luma_weight[i] =
-        slice->header.pred_weight_table.luma_weight_l0[i];
-    params->pred_weight_table.weight_factors[0].luma_offset[i] =
-        slice->header.pred_weight_table.luma_offset_l0[i];
-  }
-
-  if (slice->header.pps->sequence->chroma_array_type != 0) {
-    for (i = 0; i <= slice->header.num_ref_idx_l0_active_minus1; i++) {
-      for (j = 0; j < 2; j++) {
-        params->pred_weight_table.weight_factors[0].chroma_weight[i][j] =
-            slice->header.pred_weight_table.chroma_weight_l0[i][j];
-        params->pred_weight_table.weight_factors[0].chroma_offset[i][j] =
-            slice->header.pred_weight_table.chroma_offset_l0[i][j];
-      }
-    }
-  }
-
-  /* Skip l1 if this is not a B-Frames. */
-  if (slice->header.type % 5 != GST_H264_B_SLICE)
-    return;
-
-  for (i = 0; i <= slice->header.num_ref_idx_l0_active_minus1; i++) {
-    params->pred_weight_table.weight_factors[0].luma_weight[i] =
-        slice->header.pred_weight_table.luma_weight_l0[i];
-    params->pred_weight_table.weight_factors[0].luma_offset[i] =
-        slice->header.pred_weight_table.luma_offset_l0[i];
-  }
-
-  if (slice->header.pps->sequence->chroma_array_type != 0) {
-    for (i = 0; i <= slice->header.num_ref_idx_l1_active_minus1; i++) {
-      for (j = 0; j < 2; j++) {
-        params->pred_weight_table.weight_factors[1].chroma_weight[i][j] =
-            slice->header.pred_weight_table.chroma_weight_l1[i][j];
-        params->pred_weight_table.weight_factors[1].chroma_offset[i][j] =
-            slice->header.pred_weight_table.chroma_offset_l1[i][j];
-      }
-    }
-  }
 }
 
 static guint8
@@ -600,6 +755,10 @@ lookup_dpb_index (struct v4l2_h264_dpb_entry dpb[16], GstH264Picture * ref_pic)
   if (!ref_pic)
     return 0xff;
 
+  /* DPB entries only stores first field in a merged fashion */
+  if (ref_pic->second_field && ref_pic->other_field)
+    ref_pic = ref_pic->other_field;
+
   ref_ts = (guint64) ref_pic->system_frame_number * 1000;
   for (i = 0; i < 16; i++) {
     if (dpb[i].flags & V4L2_H264_DPB_ENTRY_FLAG_ACTIVE
@@ -610,9 +769,30 @@ lookup_dpb_index (struct v4l2_h264_dpb_entry dpb[16], GstH264Picture * ref_pic)
   return 0xff;
 }
 
+static guint
+_get_v4l2_fields_ref (GstH264Picture * ref_pic, gboolean merge)
+{
+  if (merge && ref_pic->other_field)
+    return V4L2_H264_FRAME_REF;
+
+  switch (ref_pic->field) {
+    case GST_H264_PICTURE_FIELD_FRAME:
+      return V4L2_H264_FRAME_REF;
+      break;
+    case GST_H264_PICTURE_FIELD_TOP_FIELD:
+      return V4L2_H264_TOP_FIELD_REF;
+      break;
+    case GST_H264_PICTURE_FIELD_BOTTOM_FIELD:
+      return V4L2_H264_BOTTOM_FIELD_REF;
+      break;
+  }
+
+  return V4L2_H264_FRAME_REF;
+}
+
 static void
 gst_v4l2_codec_h264_dec_fill_references (GstV4l2CodecH264Dec * self,
-    GArray * ref_pic_list0, GArray * ref_pic_list1)
+    gboolean cur_is_frame, GArray * ref_pic_list0, GArray * ref_pic_list1)
 {
   struct v4l2_ctrl_h264_slice_params *slice_params;
   gint i;
@@ -628,15 +808,19 @@ gst_v4l2_codec_h264_dec_fill_references (GstV4l2CodecH264Dec * self,
   for (i = 0; i < ref_pic_list0->len; i++) {
     GstH264Picture *ref_pic =
         g_array_index (ref_pic_list0, GstH264Picture *, i);
-    slice_params->ref_pic_list0[i] =
+    slice_params->ref_pic_list0[i].index =
         lookup_dpb_index (self->decode_params.dpb, ref_pic);
+    slice_params->ref_pic_list0[i].fields =
+        _get_v4l2_fields_ref (ref_pic, cur_is_frame);
   }
 
   for (i = 0; i < ref_pic_list1->len; i++) {
     GstH264Picture *ref_pic =
         g_array_index (ref_pic_list1, GstH264Picture *, i);
-    slice_params->ref_pic_list1[i] =
+    slice_params->ref_pic_list1[i].index =
         lookup_dpb_index (self->decode_params.dpb, ref_pic);
+    slice_params->ref_pic_list1[i].fields =
+        _get_v4l2_fields_ref (ref_pic, cur_is_frame);
   }
 }
 
@@ -648,6 +832,7 @@ gst_v4l2_codec_h264_dec_new_sequence (GstH264Decoder * decoder,
   gint crop_width = sps->width;
   gint crop_height = sps->height;
   gboolean negotiation_needed = FALSE;
+  gboolean interlaced;
 
   if (self->vinfo.finfo->format == GST_VIDEO_FORMAT_UNKNOWN)
     negotiation_needed = TRUE;
@@ -676,6 +861,14 @@ gst_v4l2_codec_h264_dec_new_sequence (GstH264Decoder * decoder,
         self->coded_width, self->coded_height);
   }
 
+  interlaced = !sps->frame_mbs_only_flag;
+  if (self->interlaced != interlaced) {
+    self->interlaced = interlaced;
+
+    negotiation_needed = TRUE;
+    GST_INFO_OBJECT (self, "Interlaced mode changed to %d", interlaced);
+  }
+
   if (self->bitdepth != sps->bit_depth_luma_minus8 + 8) {
     self->bitdepth = sps->bit_depth_luma_minus8 + 8;
     negotiation_needed = TRUE;
@@ -690,6 +883,7 @@ gst_v4l2_codec_h264_dec_new_sequence (GstH264Decoder * decoder,
   }
 
   gst_v4l2_codec_h264_dec_fill_sequence (self, sps);
+  self->need_sequence = TRUE;
 
   if (negotiation_needed) {
     self->need_negotiation = TRUE;
@@ -757,6 +951,8 @@ gst_v4l2_codec_h264_dec_start_picture (GstH264Decoder * decoder,
 {
   GstV4l2CodecH264Dec *self = GST_V4L2_CODEC_H264_DEC (decoder);
 
+  usleep (3000);
+
   /* FIXME base class should not call us if negotiation failed */
   if (!self->sink_allocator)
     return FALSE;
@@ -764,13 +960,24 @@ gst_v4l2_codec_h264_dec_start_picture (GstH264Decoder * decoder,
   if (!gst_v4l2_codec_h264_dec_ensure_bitstream (self))
     return FALSE;
 
+  /*
+   * Scaling matrix is present if there's one provided
+   * by either the SPS or the PPS. This flag must be
+   * set to true or false, before filling the PPS V4L2 control.
+   */
+  self->scaling_matrix_present =
+      slice->header.pps->sequence->scaling_matrix_present_flag ||
+      slice->header.pps->pic_scaling_matrix_present_flag;
+
   gst_v4l2_codec_h264_dec_fill_pps (self, slice->header.pps);
-  gst_v4l2_codec_h264_dec_fill_scaling_matrix (self, slice->header.pps);
+
+  if (self->scaling_matrix_present)
+    gst_v4l2_codec_h264_dec_fill_scaling_matrix (self, slice->header.pps);
+
   gst_v4l2_codec_h264_dec_fill_decoder_params (self, &slice->header, picture,
       dpb);
 
-  if (is_frame_based (self))
-    gst_v4l2_codec_h264_dec_fill_slice_params (self, slice);
+  self->first_slice = TRUE;
 
   return TRUE;
 }
@@ -823,24 +1030,6 @@ fail:
   return FALSE;
 }
 
-static gboolean
-gst_v4l2_codec_h264_dec_wait (GstV4l2CodecH264Dec * self,
-    GstV4l2Request * request)
-{
-  gint ret = gst_v4l2_request_poll (request, GST_SECOND);
-  if (ret == 0) {
-    GST_ELEMENT_ERROR (self, STREAM, DECODE,
-        ("Decoding frame took too long"), (NULL));
-    return FALSE;
-  } else if (ret < 0) {
-    GST_ELEMENT_ERROR (self, STREAM, DECODE,
-        ("Decoding request failed: %s", g_strerror (errno)), (NULL));
-    return FALSE;
-  }
-
-  return TRUE;
-}
-
 static GstFlowReturn
 gst_v4l2_codec_h264_dec_output_picture (GstH264Decoder * decoder,
     GstVideoCodecFrame * frame, GstH264Picture * picture)
@@ -848,40 +1037,29 @@ gst_v4l2_codec_h264_dec_output_picture (GstH264Decoder * decoder,
   GstV4l2CodecH264Dec *self = GST_V4L2_CODEC_H264_DEC (decoder);
   GstVideoDecoder *vdec = GST_VIDEO_DECODER (decoder);
   GstV4l2Request *request = gst_h264_picture_get_user_data (picture);
-  guint32 frame_num;
-  GstH264Picture *other_pic;
-  GstV4l2Request *other_request;
+  gint ret;
 
   GST_DEBUG_OBJECT (self, "Output picture %u", picture->system_frame_number);
 
-  if (gst_v4l2_request_is_done (request))
-    goto finish_frame;
-
-  if (!gst_v4l2_codec_h264_dec_wait (self, request))
+  ret = gst_v4l2_request_set_done (request);
+  if (ret == 0) {
+    GST_ELEMENT_ERROR (self, STREAM, DECODE,
+        ("Decoding frame %u took too long", picture->system_frame_number),
+        (NULL));
+    goto error;
+  } else if (ret < 0) {
+    GST_ELEMENT_ERROR (self, STREAM, DECODE,
+        ("Decoding request failed: %s", g_strerror (errno)), (NULL));
     goto error;
-
-  while (TRUE) {
-    if (!gst_v4l2_decoder_dequeue_src (self->decoder, &frame_num)) {
-      GST_ELEMENT_ERROR (self, STREAM, DECODE,
-          ("Decoder did not produce a frame"), (NULL));
-      goto error;
-    }
-
-    if (frame_num == picture->system_frame_number)
-      break;
-
-    other_pic = gst_h264_decoder_get_picture (decoder, frame_num);
-    if (other_pic) {
-      other_request = gst_h264_picture_get_user_data (other_pic);
-      gst_v4l2_request_set_done (other_request);
-      gst_h264_picture_unref (other_pic);
-    }
   }
-
-finish_frame:
-  gst_v4l2_request_set_done (request);
   g_return_val_if_fail (frame->output_buffer, GST_FLOW_ERROR);
 
+  if (gst_v4l2_request_failed (request)) {
+    GST_ELEMENT_ERROR (self, STREAM, DECODE,
+        ("Failed to decode frame %u", picture->system_frame_number), (NULL));
+    goto error;
+  }
+
   /* Hold on reference buffers for the rest of the picture lifetime */
   gst_h264_picture_set_user_data (picture,
       gst_buffer_ref (frame->output_buffer), (GDestroyNotify) gst_buffer_unref);
@@ -910,7 +1088,7 @@ gst_v4l2_codec_h264_dec_reset_picture (GstV4l2CodecH264Dec * self)
     self->bitstream_map = (GstMapInfo) GST_MAP_INFO_INIT;
   }
 
-  self->decode_params.num_slices = 0;
+  self->num_slices = 0;
 }
 
 static gboolean
@@ -934,14 +1112,6 @@ gst_v4l2_codec_h264_dec_ensure_output_buffer (GstV4l2CodecH264Dec * self,
     return FALSE;
   }
 
-  if (!gst_v4l2_decoder_queue_src_buffer (self->decoder, buffer,
-          frame->system_frame_number)) {
-    GST_ELEMENT_ERROR (self, RESOURCE, WRITE,
-        ("Driver did not accept the picture buffer."), (NULL));
-    gst_buffer_unref (buffer);
-    return FALSE;
-  }
-
   frame->output_buffer = buffer;
   return TRUE;
 }
@@ -950,97 +1120,118 @@ static gboolean
 gst_v4l2_codec_h264_dec_submit_bitstream (GstV4l2CodecH264Dec * self,
     GstH264Picture * picture, guint flags)
 {
-  GstVideoCodecFrame *frame;
-  GstV4l2Request *prev_request, *request;
+  GstV4l2Request *prev_request, *request = NULL;
   gsize bytesused;
   gboolean ret = FALSE;
+  guint count = 0;
 
   /* *INDENT-OFF* */
+  /* Reserve space for controls */
   struct v4l2_ext_control control[] = {
-    {
-      .id = V4L2_CID_MPEG_VIDEO_H264_SPS,
-      .ptr = &self->sps,
-      .size = sizeof (self->sps),
-    },
-    {
-      .id = V4L2_CID_MPEG_VIDEO_H264_PPS,
-      .ptr = &self->pps,
-      .size = sizeof (self->pps),
-    },
-    {
-      .id = V4L2_CID_MPEG_VIDEO_H264_SCALING_MATRIX,
-      .ptr = &self->scaling_matrix,
-      .size = sizeof (self->scaling_matrix),
-    },
-    {
-      .id = V4L2_CID_MPEG_VIDEO_H264_SLICE_PARAMS,
-      .ptr = self->slice_params->data,
-      .size = g_array_get_element_size (self->slice_params)
-              * self->decode_params.num_slices,
-    },
-    {
-      .id = V4L2_CID_MPEG_VIDEO_H264_DECODE_PARAMS,
-      .ptr = &self->decode_params,
-      .size = sizeof (self->decode_params),
-    },
+    { }, /* SPS */
+    { }, /* PPS */
+    { }, /* DECODE_PARAMS */
+    { }, /* SLICE_PARAMS */
+    { }, /* SCALING_MATRIX */
+    { }, /* PRED_WEIGHTS */
   };
   /* *INDENT-ON* */
 
-  request = gst_v4l2_decoder_alloc_request (self->decoder);
+  prev_request = gst_h264_picture_get_user_data (picture);
+
+  bytesused = self->bitstream_map.size;
+  gst_memory_unmap (self->bitstream, &self->bitstream_map);
+  self->bitstream_map = (GstMapInfo) GST_MAP_INFO_INIT;
+  gst_memory_resize (self->bitstream, 0, bytesused);
+
+  if (prev_request) {
+    request = gst_v4l2_decoder_alloc_sub_request (self->decoder, prev_request,
+        self->bitstream);
+  } else {
+    GstVideoCodecFrame *frame;
+
+    frame = gst_video_decoder_get_frame (GST_VIDEO_DECODER (self),
+        picture->system_frame_number);
+    g_return_val_if_fail (frame, FALSE);
+
+    if (!gst_v4l2_codec_h264_dec_ensure_output_buffer (self, frame))
+      goto done;
+
+    request = gst_v4l2_decoder_alloc_request (self->decoder,
+        picture->system_frame_number, self->bitstream, frame->output_buffer);
+
+    gst_video_codec_frame_unref (frame);
+  }
+
   if (!request) {
     GST_ELEMENT_ERROR (self, RESOURCE, NO_SPACE_LEFT,
         ("Failed to allocate a media request object."), (NULL));
     goto done;
   }
 
+  if (self->need_sequence) {
+    control[count].id = V4L2_CID_STATELESS_H264_SPS;
+    control[count].ptr = &self->sps;
+    control[count].size = sizeof (self->sps);
+    count++;
+    self->need_sequence = FALSE;
+  }
 
-  frame = gst_video_decoder_get_frame (GST_VIDEO_DECODER (self),
-      picture->system_frame_number);
-  g_return_val_if_fail (frame, FALSE);
-
-  if (!gst_v4l2_codec_h264_dec_ensure_output_buffer (self, frame))
-    goto done;
+  if (self->first_slice) {
+    control[count].id = V4L2_CID_STATELESS_H264_PPS;
+    control[count].ptr = &self->pps;
+    control[count].size = sizeof (self->pps);
+    count++;
+
+    if (self->scaling_matrix_present) {
+      control[count].id = V4L2_CID_STATELESS_H264_SCALING_MATRIX;
+      control[count].ptr = &self->scaling_matrix;
+      control[count].size = sizeof (self->scaling_matrix);
+      count++;
+    }
 
-  gst_video_codec_frame_unref (frame);
+    control[count].id = V4L2_CID_STATELESS_H264_DECODE_PARAMS;
+    control[count].ptr = &self->decode_params;
+    control[count].size = sizeof (self->decode_params);
+    count++;
 
-  if (!gst_v4l2_decoder_set_controls (self->decoder, request, control,
-          G_N_ELEMENTS (control))) {
-    GST_ELEMENT_ERROR (self, RESOURCE, WRITE,
-        ("Driver did not accept the bitstream parameters."), (NULL));
-    goto done;
+    self->first_slice = FALSE;
   }
 
-  bytesused = self->bitstream_map.size;
-  gst_memory_unmap (self->bitstream, &self->bitstream_map);
-  self->bitstream_map = (GstMapInfo) GST_MAP_INFO_INIT;
+  /* If it's not slice-based then it doesn't support per-slice controls. */
+  if (is_slice_based (self)) {
+    control[count].id = V4L2_CID_STATELESS_H264_SLICE_PARAMS;
+    control[count].ptr = self->slice_params->data;
+    control[count].size = g_array_get_element_size (self->slice_params)
+        * self->num_slices;
+    count++;
+
+    control[count].id = V4L2_CID_STATELESS_H264_PRED_WEIGHTS;
+    control[count].ptr = &self->pred_weight;
+    control[count].size = sizeof (self->pred_weight);
+    count++;
+  }
 
-  if (!gst_v4l2_decoder_queue_sink_mem (self->decoder, request, self->bitstream,
-          picture->system_frame_number, bytesused, flags)) {
+  if (!gst_v4l2_decoder_set_controls (self->decoder, request, control, count)) {
     GST_ELEMENT_ERROR (self, RESOURCE, WRITE,
-        ("Driver did not accept the bitstream data."), (NULL));
+        ("Driver did not accept the bitstream parameters."), (NULL));
     goto done;
   }
 
-  if (!gst_v4l2_request_queue (request)) {
+  if (!gst_v4l2_request_queue (request, flags)) {
     GST_ELEMENT_ERROR (self, RESOURCE, WRITE,
         ("Driver did not accept the decode request."), (NULL));
     goto done;
   }
 
-  prev_request = gst_h264_picture_get_user_data (picture);
-  if (prev_request) {
-    if (!gst_v4l2_codec_h264_dec_wait (self, prev_request))
-      goto done;
-    gst_v4l2_request_set_done (prev_request);
-  }
-
   gst_h264_picture_set_user_data (picture, g_steal_pointer (&request),
-      (GDestroyNotify) gst_v4l2_request_free);
+      (GDestroyNotify) gst_v4l2_request_unref);
   ret = TRUE;
 
 done:
   if (request)
-    gst_v4l2_request_free (request);
+    gst_v4l2_request_unref (request);
+
   gst_v4l2_codec_h264_dec_reset_picture (self);
 
   return ret;
@@ -1060,6 +1251,9 @@ gst_v4l2_codec_h264_dec_decode_slice (GstH264Decoder * decoder,
     if (self->bitstream_map.size) {
       /* In slice mode, we submit the pending slice asking the accelerator to
        * hold on the picture */
+
+      gst_v4l2_codec_h246_dec_complete_slice_params (self, slice);
+
       if (!gst_v4l2_codec_h264_dec_submit_bitstream (self, picture,
               V4L2_BUF_FLAG_M2M_HOLD_CAPTURE_BUF)
           || !gst_v4l2_codec_h264_dec_ensure_bitstream (self))
@@ -1067,8 +1261,9 @@ gst_v4l2_codec_h264_dec_decode_slice (GstH264Decoder * decoder,
     }
 
     gst_v4l2_codec_h264_dec_fill_slice_params (self, slice);
-    gst_v4l2_codec_h264_dec_fill_references (self, ref_pic_list0,
-        ref_pic_list1);
+    gst_v4l2_codec_h264_dec_fill_pred_weight (self, &slice->header);
+    gst_v4l2_codec_h264_dec_fill_references (self,
+        GST_H264_PICTURE_IS_FRAME (picture), ref_pic_list0, ref_pic_list1);
   }
 
   bitstream_data = self->bitstream_map.data + self->bitstream_map.size;
@@ -1093,6 +1288,10 @@ gst_v4l2_codec_h264_dec_decode_slice (GstH264Decoder * decoder,
       slice->nalu.size);
   self->bitstream_map.size += nal_size;
 
+  for (int i = 0; i < 16; i++) {
+    GST_DEBUG ("%02x ", bitstream_data[i]);
+  }
+
   return TRUE;
 }
 
@@ -1101,7 +1300,55 @@ gst_v4l2_codec_h264_dec_end_picture (GstH264Decoder * decoder,
     GstH264Picture * picture)
 {
   GstV4l2CodecH264Dec *self = GST_V4L2_CODEC_H264_DEC (decoder);
-  return gst_v4l2_codec_h264_dec_submit_bitstream (self, picture, 0);
+  guint flags = 0;
+
+  /* Hold on the output frame if this is first field of a pair */
+  if (picture->field != GST_H264_PICTURE_FIELD_FRAME && !picture->second_field)
+    flags = V4L2_BUF_FLAG_M2M_HOLD_CAPTURE_BUF;
+
+  return gst_v4l2_codec_h264_dec_submit_bitstream (self, picture, flags);
+}
+
+static gboolean
+gst_v4l2_codec_h264_dec_new_field_picture (GstH264Decoder * decoder,
+    const GstH264Picture * first_field, GstH264Picture * second_field)
+{
+  GstV4l2CodecH264Dec *self = GST_V4L2_CODEC_H264_DEC (decoder);
+  GstV4l2Request *request =
+      gst_h264_picture_get_user_data ((GstH264Picture *) first_field);
+
+  if (!request) {
+    GST_WARNING_OBJECT (self,
+        "First picture does not have an associated request");
+    return TRUE;
+  }
+
+  GST_DEBUG_OBJECT (self, "Assigned request %p to second field.", request);
+
+  /* Associate the previous request with the new picture so that
+   * submit_bitstream can create sub-request */
+  gst_h264_picture_set_user_data (second_field, gst_v4l2_request_ref (request),
+      (GDestroyNotify) gst_v4l2_request_unref);
+
+  return TRUE;
+}
+
+static guint
+gst_v4l2_codec_h264_dec_get_preferred_output_delay (GstH264Decoder * decoder,
+    gboolean live)
+{
+  GstV4l2CodecH264Dec *self = GST_V4L2_CODEC_H264_DEC (decoder);
+  guint delay;
+
+  if (live)
+    delay = 0;
+  else
+    /* Just one for now, perhaps we can make this configurable in the future. */
+    delay = 1;
+
+  gst_v4l2_decoder_set_render_delay (self->decoder, delay);
+
+  return delay;
 }
 
 static void
@@ -1260,17 +1507,39 @@ gst_v4l2_codec_h264_dec_subclass_init (GstV4l2CodecH264DecClass * klass,
       GST_DEBUG_FUNCPTR (gst_v4l2_codec_h264_dec_decode_slice);
   h264decoder_class->end_picture =
       GST_DEBUG_FUNCPTR (gst_v4l2_codec_h264_dec_end_picture);
+  h264decoder_class->new_field_picture =
+      GST_DEBUG_FUNCPTR (gst_v4l2_codec_h264_dec_new_field_picture);
+  h264decoder_class->get_preferred_output_delay =
+      GST_DEBUG_FUNCPTR (gst_v4l2_codec_h264_dec_get_preferred_output_delay);
 
   klass->device = device;
   gst_v4l2_decoder_install_properties (gobject_class, PROP_LAST, device);
 }
 
 void
-gst_v4l2_codec_h264_dec_register (GstPlugin * plugin,
+gst_v4l2_codec_h264_dec_register (GstPlugin * plugin, GstV4l2Decoder * decoder,
     GstV4l2CodecDevice * device, guint rank)
 {
-  gst_v4l2_decoder_register (plugin, GST_TYPE_V4L2_CODEC_H264_DEC,
+  GstCaps *src_caps;
+
+  if (!gst_v4l2_decoder_set_sink_fmt (decoder, V4L2_PIX_FMT_H264_SLICE,
+          320, 240, 8))
+    return;
+  src_caps = gst_v4l2_decoder_enum_src_formats (decoder);
+
+  if (gst_caps_is_empty (src_caps)) {
+    GST_WARNING ("Not registering H264 decoder since it produces no "
+        "supported format");
+    goto done;
+  }
+
+  gst_v4l2_decoder_register (plugin,
+      GST_TYPE_V4L2_CODEC_H264_DEC,
       (GClassInitFunc) gst_v4l2_codec_h264_dec_subclass_init,
+      gst_mini_object_ref (GST_MINI_OBJECT (device)),
       (GInstanceInitFunc) gst_v4l2_codec_h264_dec_subinit,
-      "v4l2sl%sh264dec", device, rank);
+      "v4l2sl%sh264dec", device, rank, NULL);
+
+done:
+  gst_caps_unref (src_caps);
 }
diff --git a/sys/v4l2codecs/gstv4l2codech264dec.h b/sys/v4l2codecs/gstv4l2codech264dec.h
index ccce690e4..f327311fc 100644
--- a/sys/v4l2codecs/gstv4l2codech264dec.h
+++ b/sys/v4l2codecs/gstv4l2codech264dec.h
@@ -45,6 +45,7 @@ struct _GstV4l2CodecH264DecClass
 
 GType gst_v4l2_codec_h264_dec_get_type (void);
 void  gst_v4l2_codec_h264_dec_register (GstPlugin * plugin,
+                                        GstV4l2Decoder * decoder,
                                         GstV4l2CodecDevice * device,
                                         guint rank);
 
diff --git a/sys/v4l2codecs/gstv4l2decoder.c b/sys/v4l2codecs/gstv4l2decoder.c
index 8c2e93874..290dd14d4 100644
--- a/sys/v4l2codecs/gstv4l2decoder.c
+++ b/sys/v4l2codecs/gstv4l2decoder.c
@@ -29,6 +29,7 @@
 #include "linux/videodev2.h"
 
 #include <fcntl.h>
+#include <sys/ioctl.h>
 #include <sys/stat.h>
 #include <sys/types.h>
 #include <unistd.h>
@@ -47,12 +48,22 @@ enum
 
 struct _GstV4l2Request
 {
+  /* non-thread safe */
+  gint ref_count;
+
   GstV4l2Decoder *decoder;
   gint fd;
+  guint32 frame_num;
   GstMemory *bitstream;
+  GstBuffer *pic_buf;
   GstPoll *poll;
   GstPollFD pollfd;
+
+  /* request state */
   gboolean pending;
+  gboolean failed;
+  gboolean hold_pic_buf;
+  gboolean sub_request;
 };
 
 struct _GstV4l2Decoder
@@ -64,6 +75,7 @@ struct _GstV4l2Decoder
   gint video_fd;
   GstQueueArray *request_pool;
   GstQueueArray *pending_requests;
+  guint version;
 
   enum v4l2_buf_type src_buf_type;
   enum v4l2_buf_type sink_buf_type;
@@ -72,12 +84,15 @@ struct _GstV4l2Decoder
   /* properties */
   gchar *media_device;
   gchar *video_device;
+  guint render_delay;
 };
 
 G_DEFINE_TYPE_WITH_CODE (GstV4l2Decoder, gst_v4l2_decoder, GST_TYPE_OBJECT,
     GST_DEBUG_CATEGORY_INIT (v4l2_decoder_debug, "v4l2codecs-decoder", 0,
         "V4L2 stateless decoder helper"));
 
+static void gst_v4l2_request_free (GstV4l2Request * request);
+
 static guint32
 direction_to_buffer_type (GstV4l2Decoder * self, GstPadDirection direction)
 {
@@ -135,6 +150,12 @@ gst_v4l2_decoder_new (GstV4l2CodecDevice * device)
   return gst_object_ref_sink (decoder);
 }
 
+guint
+gst_v4l2_decoder_get_version (GstV4l2Decoder * self)
+{
+  return self->version;
+}
+
 gboolean
 gst_v4l2_decoder_open (GstV4l2Decoder * self)
 {
@@ -163,6 +184,8 @@ gst_v4l2_decoder_open (GstV4l2Decoder * self)
     return FALSE;
   }
 
+  self->version = querycap.version;
+
   if (querycap.capabilities & V4L2_CAP_DEVICE_CAPS)
     capabilities = querycap.device_caps;
   else
@@ -192,6 +215,9 @@ gst_v4l2_decoder_close (GstV4l2Decoder * self)
 {
   GstV4l2Request *request;
 
+  while ((request = gst_queue_array_pop_head (self->pending_requests)))
+    gst_v4l2_request_unref (request);
+
   while ((request = gst_queue_array_pop_head (self->request_pool)))
     gst_v4l2_request_free (request);
 
@@ -225,16 +251,18 @@ gst_v4l2_decoder_streamon (GstV4l2Decoder * self, GstPadDirection direction)
 gboolean
 gst_v4l2_decoder_streamoff (GstV4l2Decoder * self, GstPadDirection direction)
 {
-  GstV4l2Request *pending_req;
   guint32 type = direction_to_buffer_type (self, direction);
   gint ret;
 
   if (direction == GST_PAD_SRC) {
+    GstV4l2Request *pending_req;
+
     /* STREAMOFF have the effect of cancelling all requests and unqueuing all
      * buffers, so clear the pending request list */
     while ((pending_req = gst_queue_array_pop_head (self->pending_requests))) {
       g_clear_pointer (&pending_req->bitstream, gst_memory_unref);
       pending_req->pending = FALSE;
+      gst_v4l2_request_unref (pending_req);
     }
   }
 
@@ -530,12 +558,12 @@ gst_v4l2_decoder_export_buffer (GstV4l2Decoder * self,
   return TRUE;
 }
 
-gboolean
+static gboolean
 gst_v4l2_decoder_queue_sink_mem (GstV4l2Decoder * self,
-    GstV4l2Request * request, GstMemory * mem, guint32 frame_num,
-    gsize bytesused, guint flags)
+    GstV4l2Request * request, GstMemory * mem, guint32 frame_num, guint flags)
 {
   gint ret;
+  gsize bytesused = gst_memory_get_sizes (mem, NULL, NULL);
   struct v4l2_plane plane = {
     .bytesused = bytesused,
   };
@@ -563,14 +591,11 @@ gst_v4l2_decoder_queue_sink_mem (GstV4l2Decoder * self,
     return FALSE;
   }
 
-  request->bitstream = gst_memory_ref (mem);
-
   return TRUE;
 }
 
-gboolean
-gst_v4l2_decoder_queue_src_buffer (GstV4l2Decoder * self, GstBuffer * buffer,
-    guint32 frame_num)
+static gboolean
+gst_v4l2_decoder_queue_src_buffer (GstV4l2Decoder * self, GstBuffer * buffer)
 {
   gint i, ret;
   struct v4l2_plane planes[GST_VIDEO_MAX_PLANES];
@@ -606,7 +631,7 @@ gst_v4l2_decoder_queue_src_buffer (GstV4l2Decoder * self, GstBuffer * buffer,
   return TRUE;
 }
 
-gboolean
+static gboolean
 gst_v4l2_decoder_dequeue_sink (GstV4l2Decoder * self)
 {
   gint ret;
@@ -632,7 +657,7 @@ gst_v4l2_decoder_dequeue_sink (GstV4l2Decoder * self)
   return TRUE;
 }
 
-gboolean
+static gboolean
 gst_v4l2_decoder_dequeue_src (GstV4l2Decoder * self, guint32 * out_frame_num)
 {
   gint ret;
@@ -662,7 +687,7 @@ gst_v4l2_decoder_dequeue_src (GstV4l2Decoder * self, guint32 * out_frame_num)
 
 gboolean
 gst_v4l2_decoder_set_controls (GstV4l2Decoder * self, GstV4l2Request * request,
-    struct v4l2_ext_control * control, guint count)
+    struct v4l2_ext_control *control, guint count)
 {
   gint ret;
   struct v4l2_ext_controls controls = {
@@ -684,7 +709,7 @@ gst_v4l2_decoder_set_controls (GstV4l2Decoder * self, GstV4l2Request * request,
 
 gboolean
 gst_v4l2_decoder_get_controls (GstV4l2Decoder * self,
-    struct v4l2_ext_control * control, guint count)
+    struct v4l2_ext_control *control, guint count)
 {
   gint ret;
   struct v4l2_ext_controls controls = {
@@ -702,6 +727,29 @@ gst_v4l2_decoder_get_controls (GstV4l2Decoder * self,
   return TRUE;
 }
 
+gboolean
+gst_v4l2_decoder_query_control_size (GstV4l2Decoder * self,
+    unsigned int control_id, unsigned int *control_size)
+{
+  gint ret;
+  struct v4l2_query_ext_ctrl control = {
+    .id = control_id,
+  };
+
+  *control_size = 0;
+
+  ret = ioctl (self->video_fd, VIDIOC_QUERY_EXT_CTRL, &control);
+  if (ret < 0)
+    /*
+     * It's not an error if a control is not supported by this driver.
+     * Return false but don't print any error.
+     */
+    return FALSE;
+
+  *control_size = control.elem_size;
+  return TRUE;
+}
+
 void
 gst_v4l2_decoder_install_properties (GObjectClass * gobject_class,
     gint prop_offset, GstV4l2CodecDevice * device)
@@ -765,10 +813,27 @@ gst_v4l2_decoder_get_property (GObject * object, guint prop_id,
   }
 }
 
+/**
+ * gst_v4l2_decoder_register:
+ * @plugin: a #GstPlugin
+ * @dec_type: A #GType for the codec
+ * @class_init: The #GClassInitFunc for #dec_type
+ * @instance_init: The #GInstanceInitFunc for #dec_type
+ * @element_name_tmpl: A string to use for the first codec found and as a template for the next ones.
+ * @device: (transfer full) A #GstV4l2CodecDevice
+ * @rank: The rank to use for the element
+ * @class_data: (nullable) (transfer full) A #gpointer to pass as class_data, set to @device if null
+ * @element_name (nullable) (out) Sets the pointer to the new element name
+ *
+ * Registers a decoder element as a subtype of @dec_type for @plugin.
+ * Will create a different sub_types for each subsequent @decoder of the
+ * same type.
+ */
 void
 gst_v4l2_decoder_register (GstPlugin * plugin,
-    GType dec_type, GClassInitFunc class_init, GInstanceInitFunc instance_init,
-    const gchar * element_name_tmpl, GstV4l2CodecDevice * device, guint rank)
+    GType dec_type, GClassInitFunc class_init, gconstpointer class_data,
+    GInstanceInitFunc instance_init, const gchar * element_name_tmpl,
+    GstV4l2CodecDevice * device, guint rank, gchar ** element_name)
 {
   GTypeQuery type_query;
   GTypeInfo type_info = { 0, };
@@ -780,9 +845,11 @@ gst_v4l2_decoder_register (GstPlugin * plugin,
   type_info.class_size = type_query.class_size;
   type_info.instance_size = type_query.instance_size;
   type_info.class_init = class_init;
-  type_info.class_data = gst_mini_object_ref (GST_MINI_OBJECT (device));
+  type_info.class_data = class_data;
   type_info.instance_init = instance_init;
-  GST_MINI_OBJECT_FLAG_SET (device, GST_MINI_OBJECT_FLAG_MAY_BE_LEAKED);
+
+  if (class_data == device)
+    GST_MINI_OBJECT_FLAG_SET (device, GST_MINI_OBJECT_FLAG_MAY_BE_LEAKED);
 
   /* The first decoder to be registered should use a constant name, like
    * v4l2slvp8dec, for any additional decoders, we create unique names. Decoder
@@ -800,14 +867,81 @@ gst_v4l2_decoder_register (GstPlugin * plugin,
 
   subtype = g_type_register_static (dec_type, type_name, &type_info, 0);
 
-  if (!gst_element_register (plugin, type_name, rank, subtype))
+  if (!gst_element_register (plugin, type_name, rank, subtype)) {
     GST_WARNING ("Failed to register plugin '%s'", type_name);
+    g_free (type_name);
+    type_name = NULL;
+  }
 
-  g_free (type_name);
+  if (element_name)
+    *element_name = type_name;
+  else
+    g_free (type_name);
 }
 
+/*
+ * gst_v4l2_decoder_alloc_request:
+ * @self a #GstV4l2Decoder pointer
+ * @frame_num: Used as a timestamp to identify references
+ * @bitstream the #GstMemory that holds the bitstream data
+ * @pic_buf the #GstBuffer holding the decoded picture
+ *
+ * Allocate a Linux media request file descriptor. This request wrapper will
+ * hold a reference to the requested bitstream memory to decoded and the
+ * picture buffer this request will decode to. This will be used for
+ * transparent management of the V4L2 queues.
+ *
+ * Returns: a new #GstV4l2Request
+ */
+GstV4l2Request *
+gst_v4l2_decoder_alloc_request (GstV4l2Decoder * self, guint32 frame_num,
+    GstMemory * bitstream, GstBuffer * pic_buf)
+{
+  GstV4l2Request *request = gst_queue_array_pop_head (self->request_pool);
+  gint ret;
+
+  if (!request) {
+    request = g_new0 (GstV4l2Request, 1);
+
+    ret = ioctl (self->media_fd, MEDIA_IOC_REQUEST_ALLOC, &request->fd);
+    if (ret < 0) {
+      GST_ERROR_OBJECT (self, "MEDIA_IOC_REQUEST_ALLOC failed: %s",
+          g_strerror (errno));
+      return NULL;
+    }
+
+    request->poll = gst_poll_new (FALSE);
+    gst_poll_fd_init (&request->pollfd);
+    request->pollfd.fd = request->fd;
+    gst_poll_add_fd (request->poll, &request->pollfd);
+    gst_poll_fd_ctl_pri (request->poll, &request->pollfd, TRUE);
+  }
+
+  request->decoder = g_object_ref (self);
+  request->bitstream = gst_memory_ref (bitstream);
+  request->pic_buf = gst_buffer_ref (pic_buf);
+  request->frame_num = frame_num;
+  request->ref_count = 1;
+
+  return request;
+}
+
+/*
+ * gst_v4l2_decoder_alloc_sub_request:
+ * @self a #GstV4l2Decoder pointer
+ * @prev_request the #GstV4l2Request this request continue
+ * @bitstream the #GstMemory that holds the bitstream data
+ *
+ * Allocate a Linux media request file descriptor. Similar to
+ * gst_v4l2_decoder_alloc_request(), but used when a request is the
+ * continuation of the decoding of the same picture. This is notably the case
+ * for subsequent slices or for second field of a frame.
+ *
+ * Returns: a new #GstV4l2Request
+ */
 GstV4l2Request *
-gst_v4l2_decoder_alloc_request (GstV4l2Decoder * self)
+gst_v4l2_decoder_alloc_sub_request (GstV4l2Decoder * self,
+    GstV4l2Request * prev_request, GstMemory * bitstream)
 {
   GstV4l2Request *request = gst_queue_array_pop_head (self->request_pool);
   gint ret;
@@ -830,24 +964,85 @@ gst_v4l2_decoder_alloc_request (GstV4l2Decoder * self)
   }
 
   request->decoder = g_object_ref (self);
+  request->bitstream = gst_memory_ref (bitstream);
+  request->pic_buf = gst_buffer_ref (prev_request->pic_buf);
+  request->frame_num = prev_request->frame_num;
+  request->sub_request = TRUE;
+  request->ref_count = 1;
+
   return request;
 }
 
+/**
+ * gst_v4l2_decoder_set_render_delay:
+ * @self: a #GstV4l2Decoder pointer
+ * @delay: The expected render delay
+ *
+ * The decoder will adjust the number of allowed concurrent request in order
+ * to allow this delay. The same number of concurrent bitstream buffer will be
+ * used, so make sure to adjust the number of bitstream buffer.
+ *
+ * For per-slice decoder, this is the maximum number of pending slice, so the
+ * render backlog in frame may be less then the render delay.
+ */
 void
+gst_v4l2_decoder_set_render_delay (GstV4l2Decoder * self, guint delay)
+{
+  self->render_delay = delay;
+}
+
+/**
+ * gst_v4l2_decoder_get_render_delay:
+ * @self: a #GstV4l2Decoder pointer
+ *
+ * This function is used to avoid storing the render delay in multiple places.
+ *
+ * Returns: The currently configured render delay.
+ */
+guint
+gst_v4l2_decoder_get_render_delay (GstV4l2Decoder * self)
+{
+  return self->render_delay;
+}
+
+GstV4l2Request *
+gst_v4l2_request_ref (GstV4l2Request * request)
+{
+  request->ref_count++;
+  return request;
+}
+
+static void
 gst_v4l2_request_free (GstV4l2Request * request)
+{
+  GstV4l2Decoder *decoder = request->decoder;
+
+  request->decoder = NULL;
+  close (request->fd);
+  gst_poll_free (request->poll);
+  g_free (request);
+
+  if (decoder)
+    g_object_unref (decoder);
+}
+
+void
+gst_v4l2_request_unref (GstV4l2Request * request)
 {
   GstV4l2Decoder *decoder = request->decoder;
   gint ret;
 
-  if (!decoder) {
-    close (request->fd);
-    gst_poll_free (request->poll);
-    g_free (request);
+  g_return_if_fail (request->ref_count > 0);
+
+  if (--request->ref_count > 0)
     return;
-  }
 
   g_clear_pointer (&request->bitstream, gst_memory_unref);
-  request->decoder = NULL;
+  g_clear_pointer (&request->pic_buf, gst_buffer_unref);
+  request->frame_num = G_MAXUINT32;
+  request->failed = FALSE;
+  request->hold_pic_buf = FALSE;
+  request->sub_request = FALSE;
 
   if (request->pending) {
     gint idx;
@@ -859,7 +1054,6 @@ gst_v4l2_request_free (GstV4l2Request * request)
       gst_queue_array_drop_element (decoder->pending_requests, idx);
 
     gst_v4l2_request_free (request);
-    g_object_unref (decoder);
     return;
   }
 
@@ -870,68 +1064,106 @@ gst_v4l2_request_free (GstV4l2Request * request)
     GST_ERROR_OBJECT (request->decoder, "MEDIA_REQUEST_IOC_REINIT failed: %s",
         g_strerror (errno));
     gst_v4l2_request_free (request);
-    g_object_unref (decoder);
     return;
   }
 
   gst_queue_array_push_tail (decoder->request_pool, request);
-  g_object_unref (decoder);
+  g_clear_object (&request->decoder);
 }
 
 gboolean
-gst_v4l2_request_queue (GstV4l2Request * request)
+gst_v4l2_request_queue (GstV4l2Request * request, guint flags)
 {
+  GstV4l2Decoder *decoder = request->decoder;
   gint ret;
+  guint max_pending;
+
+  GST_TRACE_OBJECT (decoder, "Queuing request %p.", request);
+
+  if (!gst_v4l2_decoder_queue_sink_mem (decoder, request,
+          request->bitstream, request->frame_num, flags)) {
+    GST_ERROR_OBJECT (decoder, "Driver did not accept the bitstream data.");
+    return FALSE;
+  }
 
-  GST_TRACE_OBJECT (request->decoder, "Queuing request %p.", request);
+  if (!request->sub_request &&
+      !gst_v4l2_decoder_queue_src_buffer (decoder, request->pic_buf)) {
+    GST_ERROR_OBJECT (decoder, "Driver did not accept the picture buffer.");
+    return FALSE;
+  }
 
   ret = ioctl (request->fd, MEDIA_REQUEST_IOC_QUEUE, NULL);
   if (ret < 0) {
-    GST_ERROR_OBJECT (request->decoder, "MEDIA_REQUEST_IOC_QUEUE, failed: %s",
+    GST_ERROR_OBJECT (decoder, "MEDIA_REQUEST_IOC_QUEUE, failed: %s",
         g_strerror (errno));
     return FALSE;
   }
 
+  if (flags & V4L2_BUF_FLAG_M2M_HOLD_CAPTURE_BUF)
+    request->hold_pic_buf = TRUE;
+
   request->pending = TRUE;
-  gst_queue_array_push_tail (request->decoder->pending_requests, request);
+  gst_queue_array_push_tail (decoder->pending_requests,
+      gst_v4l2_request_ref (request));
+
+  max_pending = MAX (1, decoder->render_delay);
+
+  if (gst_queue_array_get_length (decoder->pending_requests) > max_pending) {
+    GstV4l2Request *pending_req;
+
+    pending_req = gst_queue_array_peek_head (decoder->pending_requests);
+    gst_v4l2_request_set_done (pending_req);
+  }
 
   return TRUE;
 }
 
 gint
-gst_v4l2_request_poll (GstV4l2Request * request, GstClockTime timeout)
-{
-  return gst_poll_wait (request->poll, timeout);
-}
-
-void
 gst_v4l2_request_set_done (GstV4l2Request * request)
 {
-  if (request->bitstream) {
-    GstV4l2Decoder *dec = request->decoder;
-    GstV4l2Request *pending_req;
+  GstV4l2Decoder *decoder = request->decoder;
+  GstV4l2Request *pending_req = NULL;
+  gint ret;
 
-    while ((pending_req = gst_queue_array_pop_head (dec->pending_requests))) {
-      gst_v4l2_decoder_dequeue_sink (request->decoder);
-      g_clear_pointer (&pending_req->bitstream, gst_memory_unref);
+  if (!request->pending)
+    return 1;
 
-      if (pending_req == request)
-        break;
-    }
+  ret = gst_poll_wait (request->poll, GST_SECOND);
+  if (ret <= 0)
+    return ret;
 
-    /* Pending request should always be found in the fifo */
-    if (pending_req != request) {
-      g_warning ("Pending request not found in the pending list.");
-      gst_v4l2_decoder_dequeue_sink (request->decoder);
-      g_clear_pointer (&pending_req->bitstream, gst_memory_unref);
+  while ((pending_req = gst_queue_array_pop_head (decoder->pending_requests))) {
+    gst_v4l2_decoder_dequeue_sink (decoder);
+    g_clear_pointer (&pending_req->bitstream, gst_memory_unref);
+
+    if (!pending_req->hold_pic_buf) {
+      guint32 frame_num = G_MAXUINT32;
+
+      if (!gst_v4l2_decoder_dequeue_src (decoder, &frame_num)) {
+        pending_req->failed = TRUE;
+      } else if (frame_num != pending_req->frame_num) {
+        GST_WARNING_OBJECT (decoder,
+            "Requested frame %u, but driver returned frame %u.",
+            pending_req->frame_num, frame_num);
+        pending_req->failed = TRUE;
+      }
     }
+
+    pending_req->pending = FALSE;
+    gst_v4l2_request_unref (pending_req);
+
+    if (pending_req == request)
+      break;
   }
 
-  request->pending = FALSE;
+  /* Pending request must be in the pending request list */
+  g_assert (pending_req == request);
+
+  return ret;
 }
 
 gboolean
-gst_v4l2_request_is_done (GstV4l2Request * request)
+gst_v4l2_request_failed (GstV4l2Request * request)
 {
-  return !request->pending;
+  return request->failed;
 }
diff --git a/sys/v4l2codecs/gstv4l2decoder.h b/sys/v4l2codecs/gstv4l2decoder.h
index 0d32e31c5..ce50c09c1 100644
--- a/sys/v4l2codecs/gstv4l2decoder.h
+++ b/sys/v4l2codecs/gstv4l2decoder.h
@@ -35,6 +35,8 @@ typedef struct _GstV4l2Request GstV4l2Request;
 
 GstV4l2Decoder *  gst_v4l2_decoder_new (GstV4l2CodecDevice * device);
 
+guint             gst_v4l2_decoder_get_version (GstV4l2Decoder * self);
+
 gboolean          gst_v4l2_decoder_open (GstV4l2Decoder * decoder);
 
 gboolean          gst_v4l2_decoder_close (GstV4l2Decoder * decoder);
@@ -72,22 +74,6 @@ gboolean          gst_v4l2_decoder_export_buffer (GstV4l2Decoder * self,
                                                   gsize * offsets,
                                                   guint *num_fds);
 
-gboolean          gst_v4l2_decoder_queue_sink_mem (GstV4l2Decoder * self,
-                                                   GstV4l2Request * request,
-                                                   GstMemory * mem,
-                                                   guint32 frame_num,
-                                                   gsize bytesused,
-                                                   guint flags);
-
-gboolean          gst_v4l2_decoder_dequeue_sink (GstV4l2Decoder * self);
-
-gboolean          gst_v4l2_decoder_queue_src_buffer (GstV4l2Decoder * self,
-                                                     GstBuffer * buffer,
-                                                     guint32 frame_num);
-
-gboolean          gst_v4l2_decoder_dequeue_src (GstV4l2Decoder * self,
-                                                guint32 *out_frame_num);
-
 gboolean          gst_v4l2_decoder_set_controls (GstV4l2Decoder * self,
                                                  GstV4l2Request * request,
                                                  struct v4l2_ext_control *control,
@@ -97,6 +83,10 @@ gboolean          gst_v4l2_decoder_get_controls (GstV4l2Decoder * self,
                                                  struct v4l2_ext_control * control,
                                                  guint count);
 
+gboolean          gst_v4l2_decoder_query_control_size (GstV4l2Decoder * self,
+                                                 unsigned int control_id,
+						 unsigned int *control_size);
+
 void              gst_v4l2_decoder_install_properties (GObjectClass * gobject_class,
                                                        gint prop_offset,
                                                        GstV4l2CodecDevice * device);
@@ -110,22 +100,41 @@ void              gst_v4l2_decoder_get_property (GObject * object, guint prop_id
 void              gst_v4l2_decoder_register (GstPlugin * plugin,
                                              GType dec_type,
                                              GClassInitFunc class_init,
+                                             gconstpointer class_data,
                                              GInstanceInitFunc instance_init,
                                              const gchar *element_name_tmpl,
                                              GstV4l2CodecDevice * device,
-                                             guint rank);
+                                             guint rank,
+                                             gchar ** element_name);
+
+GstV4l2Request   *gst_v4l2_decoder_alloc_request (GstV4l2Decoder * self,
+                                                  guint32 frame_num,
+                                                  GstMemory *bitstream,
+                                                  GstBuffer * pic_buf);
+
+GstV4l2Request   *gst_v4l2_decoder_alloc_sub_request (GstV4l2Decoder * self,
+                                                      GstV4l2Request * prev_request,
+                                                      GstMemory *bitstream);
+
+void              gst_v4l2_decoder_set_render_delay (GstV4l2Decoder * self,
+                                                     guint delay);
+
+guint             gst_v4l2_decoder_get_render_delay (GstV4l2Decoder * self);
+
 
-GstV4l2Request   *gst_v4l2_decoder_alloc_request (GstV4l2Decoder * self);
+GstV4l2Request *  gst_v4l2_request_ref (GstV4l2Request * request);
 
-void              gst_v4l2_request_free (GstV4l2Request * request);
+void              gst_v4l2_request_unref (GstV4l2Request * request);
 
-gboolean          gst_v4l2_request_queue (GstV4l2Request * request);
+gboolean          gst_v4l2_request_queue (GstV4l2Request * request,
+                                          guint flags);
 
-gint              gst_v4l2_request_poll (GstV4l2Request * request, GstClockTime timeout);
+gint              gst_v4l2_request_poll (GstV4l2Request * request,
+                                         GstClockTime timeout);
 
-void              gst_v4l2_request_set_done (GstV4l2Request * request);
+gint              gst_v4l2_request_set_done (GstV4l2Request * request);
 
-gboolean          gst_v4l2_request_is_done (GstV4l2Request * request);
+gboolean          gst_v4l2_request_failed (GstV4l2Request * request);
 
 G_END_DECLS
 
diff --git a/sys/v4l2codecs/linux/h264-ctrls.h b/sys/v4l2codecs/linux/h264-ctrls.h
deleted file mode 100644
index 58aac28ad..000000000
--- a/sys/v4l2codecs/linux/h264-ctrls.h
+++ /dev/null
@@ -1,212 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*
- * These are the H.264 state controls for use with stateless H.264
- * codec drivers.
- *
- * It turns out that these structs are not stable yet and will undergo
- * more changes. So keep them private until they are stable and ready to
- * become part of the official public API.
- */
-
-#ifndef _H264_CTRLS_H_
-#define _H264_CTRLS_H_
-
-#include "linux/videodev2.h"
-
-/* Our pixel format isn't stable at the moment */
-#define V4L2_PIX_FMT_H264_SLICE v4l2_fourcc('S', '2', '6', '4') /* H264 parsed slices */
-
-/*
- * This is put insanely high to avoid conflicting with controls that
- * would be added during the phase where those controls are not
- * stable. It should be fixed eventually.
- */
-#define V4L2_CID_MPEG_VIDEO_H264_SPS		(V4L2_CID_MPEG_BASE+1000)
-#define V4L2_CID_MPEG_VIDEO_H264_PPS		(V4L2_CID_MPEG_BASE+1001)
-#define V4L2_CID_MPEG_VIDEO_H264_SCALING_MATRIX	(V4L2_CID_MPEG_BASE+1002)
-#define V4L2_CID_MPEG_VIDEO_H264_SLICE_PARAMS	(V4L2_CID_MPEG_BASE+1003)
-#define V4L2_CID_MPEG_VIDEO_H264_DECODE_PARAMS	(V4L2_CID_MPEG_BASE+1004)
-#define V4L2_CID_MPEG_VIDEO_H264_DECODE_MODE	(V4L2_CID_MPEG_BASE+1005)
-#define V4L2_CID_MPEG_VIDEO_H264_START_CODE	(V4L2_CID_MPEG_BASE+1006)
-
-/* enum v4l2_ctrl_type type values */
-#define V4L2_CTRL_TYPE_H264_SPS			0x0110
-#define V4L2_CTRL_TYPE_H264_PPS			0x0111
-#define V4L2_CTRL_TYPE_H264_SCALING_MATRIX	0x0112
-#define V4L2_CTRL_TYPE_H264_SLICE_PARAMS	0x0113
-#define V4L2_CTRL_TYPE_H264_DECODE_PARAMS	0x0114
-
-enum v4l2_mpeg_video_h264_decode_mode {
-	V4L2_MPEG_VIDEO_H264_DECODE_MODE_SLICE_BASED,
-	V4L2_MPEG_VIDEO_H264_DECODE_MODE_FRAME_BASED,
-};
-
-enum v4l2_mpeg_video_h264_start_code {
-	V4L2_MPEG_VIDEO_H264_START_CODE_NONE,
-	V4L2_MPEG_VIDEO_H264_START_CODE_ANNEX_B,
-};
-
-#define V4L2_H264_SPS_CONSTRAINT_SET0_FLAG			0x01
-#define V4L2_H264_SPS_CONSTRAINT_SET1_FLAG			0x02
-#define V4L2_H264_SPS_CONSTRAINT_SET2_FLAG			0x04
-#define V4L2_H264_SPS_CONSTRAINT_SET3_FLAG			0x08
-#define V4L2_H264_SPS_CONSTRAINT_SET4_FLAG			0x10
-#define V4L2_H264_SPS_CONSTRAINT_SET5_FLAG			0x20
-
-#define V4L2_H264_SPS_FLAG_SEPARATE_COLOUR_PLANE		0x01
-#define V4L2_H264_SPS_FLAG_QPPRIME_Y_ZERO_TRANSFORM_BYPASS	0x02
-#define V4L2_H264_SPS_FLAG_DELTA_PIC_ORDER_ALWAYS_ZERO		0x04
-#define V4L2_H264_SPS_FLAG_GAPS_IN_FRAME_NUM_VALUE_ALLOWED	0x08
-#define V4L2_H264_SPS_FLAG_FRAME_MBS_ONLY			0x10
-#define V4L2_H264_SPS_FLAG_MB_ADAPTIVE_FRAME_FIELD		0x20
-#define V4L2_H264_SPS_FLAG_DIRECT_8X8_INFERENCE			0x40
-
-struct v4l2_ctrl_h264_sps {
-	__u8 profile_idc;
-	__u8 constraint_set_flags;
-	__u8 level_idc;
-	__u8 seq_parameter_set_id;
-	__u8 chroma_format_idc;
-	__u8 bit_depth_luma_minus8;
-	__u8 bit_depth_chroma_minus8;
-	__u8 log2_max_frame_num_minus4;
-	__u8 pic_order_cnt_type;
-	__u8 log2_max_pic_order_cnt_lsb_minus4;
-	__u8 max_num_ref_frames;
-	__u8 num_ref_frames_in_pic_order_cnt_cycle;
-	__s32 offset_for_ref_frame[255];
-	__s32 offset_for_non_ref_pic;
-	__s32 offset_for_top_to_bottom_field;
-	__u16 pic_width_in_mbs_minus1;
-	__u16 pic_height_in_map_units_minus1;
-	__u32 flags;
-};
-
-#define V4L2_H264_PPS_FLAG_ENTROPY_CODING_MODE				0x0001
-#define V4L2_H264_PPS_FLAG_BOTTOM_FIELD_PIC_ORDER_IN_FRAME_PRESENT	0x0002
-#define V4L2_H264_PPS_FLAG_WEIGHTED_PRED				0x0004
-#define V4L2_H264_PPS_FLAG_DEBLOCKING_FILTER_CONTROL_PRESENT		0x0008
-#define V4L2_H264_PPS_FLAG_CONSTRAINED_INTRA_PRED			0x0010
-#define V4L2_H264_PPS_FLAG_REDUNDANT_PIC_CNT_PRESENT			0x0020
-#define V4L2_H264_PPS_FLAG_TRANSFORM_8X8_MODE				0x0040
-#define V4L2_H264_PPS_FLAG_PIC_SCALING_MATRIX_PRESENT			0x0080
-
-struct v4l2_ctrl_h264_pps {
-	__u8 pic_parameter_set_id;
-	__u8 seq_parameter_set_id;
-	__u8 num_slice_groups_minus1;
-	__u8 num_ref_idx_l0_default_active_minus1;
-	__u8 num_ref_idx_l1_default_active_minus1;
-	__u8 weighted_bipred_idc;
-	__s8 pic_init_qp_minus26;
-	__s8 pic_init_qs_minus26;
-	__s8 chroma_qp_index_offset;
-	__s8 second_chroma_qp_index_offset;
-	__u16 flags;
-};
-
-struct v4l2_ctrl_h264_scaling_matrix {
-	__u8 scaling_list_4x4[6][16];
-	__u8 scaling_list_8x8[6][64];
-};
-
-struct v4l2_h264_weight_factors {
-	__s16 luma_weight[32];
-	__s16 luma_offset[32];
-	__s16 chroma_weight[32][2];
-	__s16 chroma_offset[32][2];
-};
-
-struct v4l2_h264_pred_weight_table {
-	__u16 luma_log2_weight_denom;
-	__u16 chroma_log2_weight_denom;
-	struct v4l2_h264_weight_factors weight_factors[2];
-};
-
-#define V4L2_H264_SLICE_TYPE_P				0
-#define V4L2_H264_SLICE_TYPE_B				1
-#define V4L2_H264_SLICE_TYPE_I				2
-#define V4L2_H264_SLICE_TYPE_SP				3
-#define V4L2_H264_SLICE_TYPE_SI				4
-
-#define V4L2_H264_SLICE_FLAG_FIELD_PIC			0x01
-#define V4L2_H264_SLICE_FLAG_BOTTOM_FIELD		0x02
-#define V4L2_H264_SLICE_FLAG_DIRECT_SPATIAL_MV_PRED	0x04
-#define V4L2_H264_SLICE_FLAG_SP_FOR_SWITCH		0x08
-
-struct v4l2_ctrl_h264_slice_params {
-	/* Size in bytes, including header */
-	__u32 size;
-
-	/* Offset in bytes to the start of slice in the OUTPUT buffer. */
-	__u32 start_byte_offset;
-
-	/* Offset in bits to slice_data() from the beginning of this slice. */
-	__u32 header_bit_size;
-
-	__u16 first_mb_in_slice;
-	__u8 slice_type;
-	__u8 pic_parameter_set_id;
-	__u8 colour_plane_id;
-	__u8 redundant_pic_cnt;
-	__u16 frame_num;
-	__u16 idr_pic_id;
-	__u16 pic_order_cnt_lsb;
-	__s32 delta_pic_order_cnt_bottom;
-	__s32 delta_pic_order_cnt0;
-	__s32 delta_pic_order_cnt1;
-
-	struct v4l2_h264_pred_weight_table pred_weight_table;
-	/* Size in bits of dec_ref_pic_marking() syntax element. */
-	__u32 dec_ref_pic_marking_bit_size;
-	/* Size in bits of pic order count syntax. */
-	__u32 pic_order_cnt_bit_size;
-
-	__u8 cabac_init_idc;
-	__s8 slice_qp_delta;
-	__s8 slice_qs_delta;
-	__u8 disable_deblocking_filter_idc;
-	__s8 slice_alpha_c0_offset_div2;
-	__s8 slice_beta_offset_div2;
-	__u8 num_ref_idx_l0_active_minus1;
-	__u8 num_ref_idx_l1_active_minus1;
-	__u32 slice_group_change_cycle;
-
-	/*
-	 * Entries on each list are indices into
-	 * v4l2_ctrl_h264_decode_params.dpb[].
-	 */
-	__u8 ref_pic_list0[32];
-	__u8 ref_pic_list1[32];
-
-	__u32 flags;
-};
-
-#define V4L2_H264_DPB_ENTRY_FLAG_VALID		0x01
-#define V4L2_H264_DPB_ENTRY_FLAG_ACTIVE		0x02
-#define V4L2_H264_DPB_ENTRY_FLAG_LONG_TERM	0x04
-#define V4L2_H264_DPB_ENTRY_FLAG_FIELD		0x08
-#define V4L2_H264_DPB_ENTRY_FLAG_BOTTOM_FIELD	0x10
-
-struct v4l2_h264_dpb_entry {
-	__u64 reference_ts;
-	__u16 frame_num;
-	__u16 pic_num;
-	/* Note that field is indicated by v4l2_buffer.field */
-	__s32 top_field_order_cnt;
-	__s32 bottom_field_order_cnt;
-	__u32 flags; /* V4L2_H264_DPB_ENTRY_FLAG_* */
-};
-
-#define V4L2_H264_DECODE_PARAM_FLAG_IDR_PIC	0x01
-
-struct v4l2_ctrl_h264_decode_params {
-	struct v4l2_h264_dpb_entry dpb[16];
-	__u16 num_slices;
-	__u16 nal_ref_idc;
-	__s32 top_field_order_cnt;
-	__s32 bottom_field_order_cnt;
-	__u32 flags; /* V4L2_H264_DECODE_PARAM_FLAG_* */
-};
-
-#endif
diff --git a/sys/v4l2codecs/linux/media.h b/sys/v4l2codecs/linux/media.h
index 42ca51fc4..1d32f3e60 100644
--- a/sys/v4l2codecs/linux/media.h
+++ b/sys/v4l2codecs/linux/media.h
@@ -22,9 +22,9 @@
 
 #ifndef __KERNEL__
 #include <stdint.h>
-#define __user
 #endif
-#include "linux/types-compat.h"
+#include <linux/ioctl.h>
+#include <linux/types.h>
 
 struct media_device_info {
 	char driver[16];
@@ -127,6 +127,7 @@ struct media_device_info {
 #define MEDIA_ENT_F_PROC_VIDEO_STATISTICS	(MEDIA_ENT_F_BASE + 0x4006)
 #define MEDIA_ENT_F_PROC_VIDEO_ENCODER		(MEDIA_ENT_F_BASE + 0x4007)
 #define MEDIA_ENT_F_PROC_VIDEO_DECODER		(MEDIA_ENT_F_BASE + 0x4008)
+#define MEDIA_ENT_F_PROC_VIDEO_ISP		(MEDIA_ENT_F_BASE + 0x4009)
 
 /*
  * Switch and bridge entity functions
@@ -236,9 +237,9 @@ struct media_link_desc {
 struct media_links_enum {
 	__u32 entity;
 	/* Should have enough room for pads elements */
-	struct media_pad_desc __user *pads;
+	struct media_pad_desc *pads;
 	/* Should have enough room for links elements */
-	struct media_link_desc __user *links;
+	struct media_link_desc *links;
 	__u32 reserved[4];
 };
 
diff --git a/sys/v4l2codecs/linux/types-compat.h b/sys/v4l2codecs/linux/types-compat.h
index 10d8c300e..e2502f3bd 100644
--- a/sys/v4l2codecs/linux/types-compat.h
+++ b/sys/v4l2codecs/linux/types-compat.h
@@ -24,7 +24,7 @@
 #ifndef __TYPES_COMPAT_H__
 #define __TYPES_COMPAT_H__
 
-#define __user
+#define __inline__ inline
 
 #ifdef   __linux__
 #include <linux/types.h>
diff --git a/sys/v4l2codecs/linux/v4l2-common.h b/sys/v4l2codecs/linux/v4l2-common.h
index 408f631e7..c06c31515 100644
--- a/sys/v4l2codecs/linux/v4l2-common.h
+++ b/sys/v4l2codecs/linux/v4l2-common.h
@@ -92,7 +92,6 @@ struct v4l2_edid {
 	__u8  *edid;
 };
 
-#ifndef __KERNEL__
 /* Backward compatibility target definitions --- to be removed. */
 #define V4L2_SEL_TGT_CROP_ACTIVE	V4L2_SEL_TGT_CROP
 #define V4L2_SEL_TGT_COMPOSE_ACTIVE	V4L2_SEL_TGT_COMPOSE
@@ -105,6 +104,5 @@ struct v4l2_edid {
 #define V4L2_SUBDEV_SEL_FLAG_SIZE_GE	V4L2_SEL_FLAG_GE
 #define V4L2_SUBDEV_SEL_FLAG_SIZE_LE	V4L2_SEL_FLAG_LE
 #define V4L2_SUBDEV_SEL_FLAG_KEEP_CONFIG V4L2_SEL_FLAG_KEEP_CONFIG
-#endif
 
 #endif /* __V4L2_COMMON__ */
diff --git a/sys/v4l2codecs/linux/v4l2-controls.h b/sys/v4l2codecs/linux/v4l2-controls.h
index 0983def4c..84f6431ad 100644
--- a/sys/v4l2codecs/linux/v4l2-controls.h
+++ b/sys/v4l2codecs/linux/v4l2-controls.h
@@ -54,7 +54,7 @@
 
 /* Control classes */
 #define V4L2_CTRL_CLASS_USER		0x00980000	/* Old-style 'user' controls */
-#define V4L2_CTRL_CLASS_MPEG		0x00990000	/* MPEG-compression controls */
+#define V4L2_CTRL_CLASS_CODEC		0x00990000	/* Stateful codec controls */
 #define V4L2_CTRL_CLASS_CAMERA		0x009a0000	/* Camera class controls */
 #define V4L2_CTRL_CLASS_FM_TX		0x009b0000	/* FM Modulator controls */
 #define V4L2_CTRL_CLASS_FLASH		0x009c0000	/* Camera flash controls */
@@ -65,6 +65,7 @@
 #define V4L2_CTRL_CLASS_FM_RX		0x00a10000	/* FM Receiver controls */
 #define V4L2_CTRL_CLASS_RF_TUNER	0x00a20000	/* RF tuner controls */
 #define V4L2_CTRL_CLASS_DETECT		0x00a30000	/* Detection controls */
+#define V4L2_CTRL_CLASS_CODEC_STATELESS 0x00a40000	/* Stateless codecs controls */
 
 /* User-class control IDs */
 
@@ -198,15 +199,26 @@ enum v4l2_colorfx {
  */
 #define V4L2_CID_USER_ATMEL_ISC_BASE		(V4L2_CID_USER_BASE + 0x10c0)
 
+/*
+ * The base for the CODA driver controls.
+ * We reserve 16 controls for this driver.
+ */
+#define V4L2_CID_USER_CODA_BASE			(V4L2_CID_USER_BASE + 0x10e0)
+/*
+ * The base for MIPI CCS driver controls.
+ * We reserve 128 controls for this driver.
+ */
+#define V4L2_CID_USER_CCS_BASE			(V4L2_CID_USER_BASE + 0x10f0)
+
 /* MPEG-class control IDs */
 /* The MPEG controls are applicable to all codec controls
  * and the 'MPEG' part of the define is historical */
 
-#define V4L2_CID_MPEG_BASE			(V4L2_CTRL_CLASS_MPEG | 0x900)
-#define V4L2_CID_MPEG_CLASS			(V4L2_CTRL_CLASS_MPEG | 1)
+#define V4L2_CID_CODEC_BASE			(V4L2_CTRL_CLASS_CODEC | 0x900)
+#define V4L2_CID_CODEC_CLASS			(V4L2_CTRL_CLASS_CODEC | 1)
 
 /*  MPEG streams, specific to multiplexed streams */
-#define V4L2_CID_MPEG_STREAM_TYPE		(V4L2_CID_MPEG_BASE+0)
+#define V4L2_CID_MPEG_STREAM_TYPE		(V4L2_CID_CODEC_BASE+0)
 enum v4l2_mpeg_stream_type {
 	V4L2_MPEG_STREAM_TYPE_MPEG2_PS   = 0, /* MPEG-2 program stream */
 	V4L2_MPEG_STREAM_TYPE_MPEG2_TS   = 1, /* MPEG-2 transport stream */
@@ -215,26 +227,26 @@ enum v4l2_mpeg_stream_type {
 	V4L2_MPEG_STREAM_TYPE_MPEG1_VCD  = 4, /* MPEG-1 VCD-compatible stream */
 	V4L2_MPEG_STREAM_TYPE_MPEG2_SVCD = 5, /* MPEG-2 SVCD-compatible stream */
 };
-#define V4L2_CID_MPEG_STREAM_PID_PMT		(V4L2_CID_MPEG_BASE+1)
-#define V4L2_CID_MPEG_STREAM_PID_AUDIO		(V4L2_CID_MPEG_BASE+2)
-#define V4L2_CID_MPEG_STREAM_PID_VIDEO		(V4L2_CID_MPEG_BASE+3)
-#define V4L2_CID_MPEG_STREAM_PID_PCR		(V4L2_CID_MPEG_BASE+4)
-#define V4L2_CID_MPEG_STREAM_PES_ID_AUDIO	(V4L2_CID_MPEG_BASE+5)
-#define V4L2_CID_MPEG_STREAM_PES_ID_VIDEO	(V4L2_CID_MPEG_BASE+6)
-#define V4L2_CID_MPEG_STREAM_VBI_FMT		(V4L2_CID_MPEG_BASE+7)
+#define V4L2_CID_MPEG_STREAM_PID_PMT		(V4L2_CID_CODEC_BASE+1)
+#define V4L2_CID_MPEG_STREAM_PID_AUDIO		(V4L2_CID_CODEC_BASE+2)
+#define V4L2_CID_MPEG_STREAM_PID_VIDEO		(V4L2_CID_CODEC_BASE+3)
+#define V4L2_CID_MPEG_STREAM_PID_PCR		(V4L2_CID_CODEC_BASE+4)
+#define V4L2_CID_MPEG_STREAM_PES_ID_AUDIO	(V4L2_CID_CODEC_BASE+5)
+#define V4L2_CID_MPEG_STREAM_PES_ID_VIDEO	(V4L2_CID_CODEC_BASE+6)
+#define V4L2_CID_MPEG_STREAM_VBI_FMT		(V4L2_CID_CODEC_BASE+7)
 enum v4l2_mpeg_stream_vbi_fmt {
 	V4L2_MPEG_STREAM_VBI_FMT_NONE = 0,  /* No VBI in the MPEG stream */
 	V4L2_MPEG_STREAM_VBI_FMT_IVTV = 1,  /* VBI in private packets, IVTV format */
 };
 
 /*  MPEG audio controls specific to multiplexed streams  */
-#define V4L2_CID_MPEG_AUDIO_SAMPLING_FREQ	(V4L2_CID_MPEG_BASE+100)
+#define V4L2_CID_MPEG_AUDIO_SAMPLING_FREQ	(V4L2_CID_CODEC_BASE+100)
 enum v4l2_mpeg_audio_sampling_freq {
 	V4L2_MPEG_AUDIO_SAMPLING_FREQ_44100 = 0,
 	V4L2_MPEG_AUDIO_SAMPLING_FREQ_48000 = 1,
 	V4L2_MPEG_AUDIO_SAMPLING_FREQ_32000 = 2,
 };
-#define V4L2_CID_MPEG_AUDIO_ENCODING		(V4L2_CID_MPEG_BASE+101)
+#define V4L2_CID_MPEG_AUDIO_ENCODING		(V4L2_CID_CODEC_BASE+101)
 enum v4l2_mpeg_audio_encoding {
 	V4L2_MPEG_AUDIO_ENCODING_LAYER_1 = 0,
 	V4L2_MPEG_AUDIO_ENCODING_LAYER_2 = 1,
@@ -242,7 +254,7 @@ enum v4l2_mpeg_audio_encoding {
 	V4L2_MPEG_AUDIO_ENCODING_AAC     = 3,
 	V4L2_MPEG_AUDIO_ENCODING_AC3     = 4,
 };
-#define V4L2_CID_MPEG_AUDIO_L1_BITRATE		(V4L2_CID_MPEG_BASE+102)
+#define V4L2_CID_MPEG_AUDIO_L1_BITRATE		(V4L2_CID_CODEC_BASE+102)
 enum v4l2_mpeg_audio_l1_bitrate {
 	V4L2_MPEG_AUDIO_L1_BITRATE_32K  = 0,
 	V4L2_MPEG_AUDIO_L1_BITRATE_64K  = 1,
@@ -259,7 +271,7 @@ enum v4l2_mpeg_audio_l1_bitrate {
 	V4L2_MPEG_AUDIO_L1_BITRATE_416K = 12,
 	V4L2_MPEG_AUDIO_L1_BITRATE_448K = 13,
 };
-#define V4L2_CID_MPEG_AUDIO_L2_BITRATE		(V4L2_CID_MPEG_BASE+103)
+#define V4L2_CID_MPEG_AUDIO_L2_BITRATE		(V4L2_CID_CODEC_BASE+103)
 enum v4l2_mpeg_audio_l2_bitrate {
 	V4L2_MPEG_AUDIO_L2_BITRATE_32K  = 0,
 	V4L2_MPEG_AUDIO_L2_BITRATE_48K  = 1,
@@ -276,7 +288,7 @@ enum v4l2_mpeg_audio_l2_bitrate {
 	V4L2_MPEG_AUDIO_L2_BITRATE_320K = 12,
 	V4L2_MPEG_AUDIO_L2_BITRATE_384K = 13,
 };
-#define V4L2_CID_MPEG_AUDIO_L3_BITRATE		(V4L2_CID_MPEG_BASE+104)
+#define V4L2_CID_MPEG_AUDIO_L3_BITRATE		(V4L2_CID_CODEC_BASE+104)
 enum v4l2_mpeg_audio_l3_bitrate {
 	V4L2_MPEG_AUDIO_L3_BITRATE_32K  = 0,
 	V4L2_MPEG_AUDIO_L3_BITRATE_40K  = 1,
@@ -293,34 +305,34 @@ enum v4l2_mpeg_audio_l3_bitrate {
 	V4L2_MPEG_AUDIO_L3_BITRATE_256K = 12,
 	V4L2_MPEG_AUDIO_L3_BITRATE_320K = 13,
 };
-#define V4L2_CID_MPEG_AUDIO_MODE		(V4L2_CID_MPEG_BASE+105)
+#define V4L2_CID_MPEG_AUDIO_MODE		(V4L2_CID_CODEC_BASE+105)
 enum v4l2_mpeg_audio_mode {
 	V4L2_MPEG_AUDIO_MODE_STEREO       = 0,
 	V4L2_MPEG_AUDIO_MODE_JOINT_STEREO = 1,
 	V4L2_MPEG_AUDIO_MODE_DUAL         = 2,
 	V4L2_MPEG_AUDIO_MODE_MONO         = 3,
 };
-#define V4L2_CID_MPEG_AUDIO_MODE_EXTENSION	(V4L2_CID_MPEG_BASE+106)
+#define V4L2_CID_MPEG_AUDIO_MODE_EXTENSION	(V4L2_CID_CODEC_BASE+106)
 enum v4l2_mpeg_audio_mode_extension {
 	V4L2_MPEG_AUDIO_MODE_EXTENSION_BOUND_4  = 0,
 	V4L2_MPEG_AUDIO_MODE_EXTENSION_BOUND_8  = 1,
 	V4L2_MPEG_AUDIO_MODE_EXTENSION_BOUND_12 = 2,
 	V4L2_MPEG_AUDIO_MODE_EXTENSION_BOUND_16 = 3,
 };
-#define V4L2_CID_MPEG_AUDIO_EMPHASIS		(V4L2_CID_MPEG_BASE+107)
+#define V4L2_CID_MPEG_AUDIO_EMPHASIS		(V4L2_CID_CODEC_BASE+107)
 enum v4l2_mpeg_audio_emphasis {
 	V4L2_MPEG_AUDIO_EMPHASIS_NONE         = 0,
 	V4L2_MPEG_AUDIO_EMPHASIS_50_DIV_15_uS = 1,
 	V4L2_MPEG_AUDIO_EMPHASIS_CCITT_J17    = 2,
 };
-#define V4L2_CID_MPEG_AUDIO_CRC			(V4L2_CID_MPEG_BASE+108)
+#define V4L2_CID_MPEG_AUDIO_CRC			(V4L2_CID_CODEC_BASE+108)
 enum v4l2_mpeg_audio_crc {
 	V4L2_MPEG_AUDIO_CRC_NONE  = 0,
 	V4L2_MPEG_AUDIO_CRC_CRC16 = 1,
 };
-#define V4L2_CID_MPEG_AUDIO_MUTE		(V4L2_CID_MPEG_BASE+109)
-#define V4L2_CID_MPEG_AUDIO_AAC_BITRATE		(V4L2_CID_MPEG_BASE+110)
-#define V4L2_CID_MPEG_AUDIO_AC3_BITRATE		(V4L2_CID_MPEG_BASE+111)
+#define V4L2_CID_MPEG_AUDIO_MUTE		(V4L2_CID_CODEC_BASE+109)
+#define V4L2_CID_MPEG_AUDIO_AAC_BITRATE		(V4L2_CID_CODEC_BASE+110)
+#define V4L2_CID_MPEG_AUDIO_AC3_BITRATE		(V4L2_CID_CODEC_BASE+111)
 enum v4l2_mpeg_audio_ac3_bitrate {
 	V4L2_MPEG_AUDIO_AC3_BITRATE_32K  = 0,
 	V4L2_MPEG_AUDIO_AC3_BITRATE_40K  = 1,
@@ -342,7 +354,7 @@ enum v4l2_mpeg_audio_ac3_bitrate {
 	V4L2_MPEG_AUDIO_AC3_BITRATE_576K = 17,
 	V4L2_MPEG_AUDIO_AC3_BITRATE_640K = 18,
 };
-#define V4L2_CID_MPEG_AUDIO_DEC_PLAYBACK	(V4L2_CID_MPEG_BASE+112)
+#define V4L2_CID_MPEG_AUDIO_DEC_PLAYBACK	(V4L2_CID_CODEC_BASE+112)
 enum v4l2_mpeg_audio_dec_playback {
 	V4L2_MPEG_AUDIO_DEC_PLAYBACK_AUTO	    = 0,
 	V4L2_MPEG_AUDIO_DEC_PLAYBACK_STEREO	    = 1,
@@ -351,79 +363,79 @@ enum v4l2_mpeg_audio_dec_playback {
 	V4L2_MPEG_AUDIO_DEC_PLAYBACK_MONO	    = 4,
 	V4L2_MPEG_AUDIO_DEC_PLAYBACK_SWAPPED_STEREO = 5,
 };
-#define V4L2_CID_MPEG_AUDIO_DEC_MULTILINGUAL_PLAYBACK (V4L2_CID_MPEG_BASE+113)
+#define V4L2_CID_MPEG_AUDIO_DEC_MULTILINGUAL_PLAYBACK (V4L2_CID_CODEC_BASE+113)
 
 /*  MPEG video controls specific to multiplexed streams */
-#define V4L2_CID_MPEG_VIDEO_ENCODING		(V4L2_CID_MPEG_BASE+200)
+#define V4L2_CID_MPEG_VIDEO_ENCODING		(V4L2_CID_CODEC_BASE+200)
 enum v4l2_mpeg_video_encoding {
 	V4L2_MPEG_VIDEO_ENCODING_MPEG_1     = 0,
 	V4L2_MPEG_VIDEO_ENCODING_MPEG_2     = 1,
 	V4L2_MPEG_VIDEO_ENCODING_MPEG_4_AVC = 2,
 };
-#define V4L2_CID_MPEG_VIDEO_ASPECT		(V4L2_CID_MPEG_BASE+201)
+#define V4L2_CID_MPEG_VIDEO_ASPECT		(V4L2_CID_CODEC_BASE+201)
 enum v4l2_mpeg_video_aspect {
 	V4L2_MPEG_VIDEO_ASPECT_1x1     = 0,
 	V4L2_MPEG_VIDEO_ASPECT_4x3     = 1,
 	V4L2_MPEG_VIDEO_ASPECT_16x9    = 2,
 	V4L2_MPEG_VIDEO_ASPECT_221x100 = 3,
 };
-#define V4L2_CID_MPEG_VIDEO_B_FRAMES		(V4L2_CID_MPEG_BASE+202)
-#define V4L2_CID_MPEG_VIDEO_GOP_SIZE		(V4L2_CID_MPEG_BASE+203)
-#define V4L2_CID_MPEG_VIDEO_GOP_CLOSURE		(V4L2_CID_MPEG_BASE+204)
-#define V4L2_CID_MPEG_VIDEO_PULLDOWN		(V4L2_CID_MPEG_BASE+205)
-#define V4L2_CID_MPEG_VIDEO_BITRATE_MODE	(V4L2_CID_MPEG_BASE+206)
+#define V4L2_CID_MPEG_VIDEO_B_FRAMES		(V4L2_CID_CODEC_BASE+202)
+#define V4L2_CID_MPEG_VIDEO_GOP_SIZE		(V4L2_CID_CODEC_BASE+203)
+#define V4L2_CID_MPEG_VIDEO_GOP_CLOSURE		(V4L2_CID_CODEC_BASE+204)
+#define V4L2_CID_MPEG_VIDEO_PULLDOWN		(V4L2_CID_CODEC_BASE+205)
+#define V4L2_CID_MPEG_VIDEO_BITRATE_MODE	(V4L2_CID_CODEC_BASE+206)
 enum v4l2_mpeg_video_bitrate_mode {
 	V4L2_MPEG_VIDEO_BITRATE_MODE_VBR = 0,
 	V4L2_MPEG_VIDEO_BITRATE_MODE_CBR = 1,
-};
-#define V4L2_CID_MPEG_VIDEO_BITRATE		(V4L2_CID_MPEG_BASE+207)
-#define V4L2_CID_MPEG_VIDEO_BITRATE_PEAK	(V4L2_CID_MPEG_BASE+208)
-#define V4L2_CID_MPEG_VIDEO_TEMPORAL_DECIMATION (V4L2_CID_MPEG_BASE+209)
-#define V4L2_CID_MPEG_VIDEO_MUTE		(V4L2_CID_MPEG_BASE+210)
-#define V4L2_CID_MPEG_VIDEO_MUTE_YUV		(V4L2_CID_MPEG_BASE+211)
-#define V4L2_CID_MPEG_VIDEO_DECODER_SLICE_INTERFACE		(V4L2_CID_MPEG_BASE+212)
-#define V4L2_CID_MPEG_VIDEO_DECODER_MPEG4_DEBLOCK_FILTER	(V4L2_CID_MPEG_BASE+213)
-#define V4L2_CID_MPEG_VIDEO_CYCLIC_INTRA_REFRESH_MB		(V4L2_CID_MPEG_BASE+214)
-#define V4L2_CID_MPEG_VIDEO_FRAME_RC_ENABLE			(V4L2_CID_MPEG_BASE+215)
-#define V4L2_CID_MPEG_VIDEO_HEADER_MODE				(V4L2_CID_MPEG_BASE+216)
+	V4L2_MPEG_VIDEO_BITRATE_MODE_CQ  = 2,
+};
+#define V4L2_CID_MPEG_VIDEO_BITRATE		(V4L2_CID_CODEC_BASE+207)
+#define V4L2_CID_MPEG_VIDEO_BITRATE_PEAK	(V4L2_CID_CODEC_BASE+208)
+#define V4L2_CID_MPEG_VIDEO_TEMPORAL_DECIMATION (V4L2_CID_CODEC_BASE+209)
+#define V4L2_CID_MPEG_VIDEO_MUTE		(V4L2_CID_CODEC_BASE+210)
+#define V4L2_CID_MPEG_VIDEO_MUTE_YUV		(V4L2_CID_CODEC_BASE+211)
+#define V4L2_CID_MPEG_VIDEO_DECODER_SLICE_INTERFACE		(V4L2_CID_CODEC_BASE+212)
+#define V4L2_CID_MPEG_VIDEO_DECODER_MPEG4_DEBLOCK_FILTER	(V4L2_CID_CODEC_BASE+213)
+#define V4L2_CID_MPEG_VIDEO_CYCLIC_INTRA_REFRESH_MB		(V4L2_CID_CODEC_BASE+214)
+#define V4L2_CID_MPEG_VIDEO_FRAME_RC_ENABLE			(V4L2_CID_CODEC_BASE+215)
+#define V4L2_CID_MPEG_VIDEO_HEADER_MODE				(V4L2_CID_CODEC_BASE+216)
 enum v4l2_mpeg_video_header_mode {
 	V4L2_MPEG_VIDEO_HEADER_MODE_SEPARATE			= 0,
 	V4L2_MPEG_VIDEO_HEADER_MODE_JOINED_WITH_1ST_FRAME	= 1,
 
 };
-#define V4L2_CID_MPEG_VIDEO_MAX_REF_PIC			(V4L2_CID_MPEG_BASE+217)
-#define V4L2_CID_MPEG_VIDEO_MB_RC_ENABLE		(V4L2_CID_MPEG_BASE+218)
-#define V4L2_CID_MPEG_VIDEO_MULTI_SLICE_MAX_BYTES	(V4L2_CID_MPEG_BASE+219)
-#define V4L2_CID_MPEG_VIDEO_MULTI_SLICE_MAX_MB		(V4L2_CID_MPEG_BASE+220)
-#define V4L2_CID_MPEG_VIDEO_MULTI_SLICE_MODE		(V4L2_CID_MPEG_BASE+221)
+#define V4L2_CID_MPEG_VIDEO_MAX_REF_PIC			(V4L2_CID_CODEC_BASE+217)
+#define V4L2_CID_MPEG_VIDEO_MB_RC_ENABLE		(V4L2_CID_CODEC_BASE+218)
+#define V4L2_CID_MPEG_VIDEO_MULTI_SLICE_MAX_BYTES	(V4L2_CID_CODEC_BASE+219)
+#define V4L2_CID_MPEG_VIDEO_MULTI_SLICE_MAX_MB		(V4L2_CID_CODEC_BASE+220)
+#define V4L2_CID_MPEG_VIDEO_MULTI_SLICE_MODE		(V4L2_CID_CODEC_BASE+221)
 enum v4l2_mpeg_video_multi_slice_mode {
 	V4L2_MPEG_VIDEO_MULTI_SLICE_MODE_SINGLE		= 0,
 	V4L2_MPEG_VIDEO_MULTI_SLICE_MODE_MAX_MB		= 1,
 	V4L2_MPEG_VIDEO_MULTI_SLICE_MODE_MAX_BYTES	= 2,
-#ifndef __KERNEL__
 	/* Kept for backwards compatibility reasons. Stupid typo... */
 	V4L2_MPEG_VIDEO_MULTI_SICE_MODE_MAX_MB		= 1,
 	V4L2_MPEG_VIDEO_MULTI_SICE_MODE_MAX_BYTES	= 2,
-#endif
 };
-#define V4L2_CID_MPEG_VIDEO_VBV_SIZE			(V4L2_CID_MPEG_BASE+222)
-#define V4L2_CID_MPEG_VIDEO_DEC_PTS			(V4L2_CID_MPEG_BASE+223)
-#define V4L2_CID_MPEG_VIDEO_DEC_FRAME			(V4L2_CID_MPEG_BASE+224)
-#define V4L2_CID_MPEG_VIDEO_VBV_DELAY			(V4L2_CID_MPEG_BASE+225)
-#define V4L2_CID_MPEG_VIDEO_REPEAT_SEQ_HEADER		(V4L2_CID_MPEG_BASE+226)
-#define V4L2_CID_MPEG_VIDEO_MV_H_SEARCH_RANGE		(V4L2_CID_MPEG_BASE+227)
-#define V4L2_CID_MPEG_VIDEO_MV_V_SEARCH_RANGE		(V4L2_CID_MPEG_BASE+228)
-#define V4L2_CID_MPEG_VIDEO_FORCE_KEY_FRAME		(V4L2_CID_MPEG_BASE+229)
+#define V4L2_CID_MPEG_VIDEO_VBV_SIZE			(V4L2_CID_CODEC_BASE+222)
+#define V4L2_CID_MPEG_VIDEO_DEC_PTS			(V4L2_CID_CODEC_BASE+223)
+#define V4L2_CID_MPEG_VIDEO_DEC_FRAME			(V4L2_CID_CODEC_BASE+224)
+#define V4L2_CID_MPEG_VIDEO_VBV_DELAY			(V4L2_CID_CODEC_BASE+225)
+#define V4L2_CID_MPEG_VIDEO_REPEAT_SEQ_HEADER		(V4L2_CID_CODEC_BASE+226)
+#define V4L2_CID_MPEG_VIDEO_MV_H_SEARCH_RANGE		(V4L2_CID_CODEC_BASE+227)
+#define V4L2_CID_MPEG_VIDEO_MV_V_SEARCH_RANGE		(V4L2_CID_CODEC_BASE+228)
+#define V4L2_CID_MPEG_VIDEO_FORCE_KEY_FRAME		(V4L2_CID_CODEC_BASE+229)
+#define V4L2_CID_MPEG_VIDEO_BASELAYER_PRIORITY_ID	(V4L2_CID_CODEC_BASE+230)
 
 /* CIDs for the MPEG-2 Part 2 (H.262) codec */
-#define V4L2_CID_MPEG_VIDEO_MPEG2_LEVEL			(V4L2_CID_MPEG_BASE+270)
+#define V4L2_CID_MPEG_VIDEO_MPEG2_LEVEL			(V4L2_CID_CODEC_BASE+270)
 enum v4l2_mpeg_video_mpeg2_level {
 	V4L2_MPEG_VIDEO_MPEG2_LEVEL_LOW		= 0,
 	V4L2_MPEG_VIDEO_MPEG2_LEVEL_MAIN	= 1,
 	V4L2_MPEG_VIDEO_MPEG2_LEVEL_HIGH_1440	= 2,
 	V4L2_MPEG_VIDEO_MPEG2_LEVEL_HIGH	= 3,
 };
-#define V4L2_CID_MPEG_VIDEO_MPEG2_PROFILE		(V4L2_CID_MPEG_BASE+271)
+#define V4L2_CID_MPEG_VIDEO_MPEG2_PROFILE		(V4L2_CID_CODEC_BASE+271)
 enum v4l2_mpeg_video_mpeg2_profile {
 	V4L2_MPEG_VIDEO_MPEG2_PROFILE_SIMPLE				= 0,
 	V4L2_MPEG_VIDEO_MPEG2_PROFILE_MAIN				= 1,
@@ -434,28 +446,28 @@ enum v4l2_mpeg_video_mpeg2_profile {
 };
 
 /* CIDs for the FWHT codec as used by the vicodec driver. */
-#define V4L2_CID_FWHT_I_FRAME_QP             (V4L2_CID_MPEG_BASE + 290)
-#define V4L2_CID_FWHT_P_FRAME_QP             (V4L2_CID_MPEG_BASE + 291)
-
-#define V4L2_CID_MPEG_VIDEO_H263_I_FRAME_QP		(V4L2_CID_MPEG_BASE+300)
-#define V4L2_CID_MPEG_VIDEO_H263_P_FRAME_QP		(V4L2_CID_MPEG_BASE+301)
-#define V4L2_CID_MPEG_VIDEO_H263_B_FRAME_QP		(V4L2_CID_MPEG_BASE+302)
-#define V4L2_CID_MPEG_VIDEO_H263_MIN_QP			(V4L2_CID_MPEG_BASE+303)
-#define V4L2_CID_MPEG_VIDEO_H263_MAX_QP			(V4L2_CID_MPEG_BASE+304)
-#define V4L2_CID_MPEG_VIDEO_H264_I_FRAME_QP		(V4L2_CID_MPEG_BASE+350)
-#define V4L2_CID_MPEG_VIDEO_H264_P_FRAME_QP		(V4L2_CID_MPEG_BASE+351)
-#define V4L2_CID_MPEG_VIDEO_H264_B_FRAME_QP		(V4L2_CID_MPEG_BASE+352)
-#define V4L2_CID_MPEG_VIDEO_H264_MIN_QP			(V4L2_CID_MPEG_BASE+353)
-#define V4L2_CID_MPEG_VIDEO_H264_MAX_QP			(V4L2_CID_MPEG_BASE+354)
-#define V4L2_CID_MPEG_VIDEO_H264_8X8_TRANSFORM		(V4L2_CID_MPEG_BASE+355)
-#define V4L2_CID_MPEG_VIDEO_H264_CPB_SIZE		(V4L2_CID_MPEG_BASE+356)
-#define V4L2_CID_MPEG_VIDEO_H264_ENTROPY_MODE		(V4L2_CID_MPEG_BASE+357)
+#define V4L2_CID_FWHT_I_FRAME_QP             (V4L2_CID_CODEC_BASE + 290)
+#define V4L2_CID_FWHT_P_FRAME_QP             (V4L2_CID_CODEC_BASE + 291)
+
+#define V4L2_CID_MPEG_VIDEO_H263_I_FRAME_QP		(V4L2_CID_CODEC_BASE+300)
+#define V4L2_CID_MPEG_VIDEO_H263_P_FRAME_QP		(V4L2_CID_CODEC_BASE+301)
+#define V4L2_CID_MPEG_VIDEO_H263_B_FRAME_QP		(V4L2_CID_CODEC_BASE+302)
+#define V4L2_CID_MPEG_VIDEO_H263_MIN_QP			(V4L2_CID_CODEC_BASE+303)
+#define V4L2_CID_MPEG_VIDEO_H263_MAX_QP			(V4L2_CID_CODEC_BASE+304)
+#define V4L2_CID_MPEG_VIDEO_H264_I_FRAME_QP		(V4L2_CID_CODEC_BASE+350)
+#define V4L2_CID_MPEG_VIDEO_H264_P_FRAME_QP		(V4L2_CID_CODEC_BASE+351)
+#define V4L2_CID_MPEG_VIDEO_H264_B_FRAME_QP		(V4L2_CID_CODEC_BASE+352)
+#define V4L2_CID_MPEG_VIDEO_H264_MIN_QP			(V4L2_CID_CODEC_BASE+353)
+#define V4L2_CID_MPEG_VIDEO_H264_MAX_QP			(V4L2_CID_CODEC_BASE+354)
+#define V4L2_CID_MPEG_VIDEO_H264_8X8_TRANSFORM		(V4L2_CID_CODEC_BASE+355)
+#define V4L2_CID_MPEG_VIDEO_H264_CPB_SIZE		(V4L2_CID_CODEC_BASE+356)
+#define V4L2_CID_MPEG_VIDEO_H264_ENTROPY_MODE		(V4L2_CID_CODEC_BASE+357)
 enum v4l2_mpeg_video_h264_entropy_mode {
 	V4L2_MPEG_VIDEO_H264_ENTROPY_MODE_CAVLC	= 0,
 	V4L2_MPEG_VIDEO_H264_ENTROPY_MODE_CABAC	= 1,
 };
-#define V4L2_CID_MPEG_VIDEO_H264_I_PERIOD		(V4L2_CID_MPEG_BASE+358)
-#define V4L2_CID_MPEG_VIDEO_H264_LEVEL			(V4L2_CID_MPEG_BASE+359)
+#define V4L2_CID_MPEG_VIDEO_H264_I_PERIOD		(V4L2_CID_CODEC_BASE+358)
+#define V4L2_CID_MPEG_VIDEO_H264_LEVEL			(V4L2_CID_CODEC_BASE+359)
 enum v4l2_mpeg_video_h264_level {
 	V4L2_MPEG_VIDEO_H264_LEVEL_1_0	= 0,
 	V4L2_MPEG_VIDEO_H264_LEVEL_1B	= 1,
@@ -473,16 +485,20 @@ enum v4l2_mpeg_video_h264_level {
 	V4L2_MPEG_VIDEO_H264_LEVEL_4_2	= 13,
 	V4L2_MPEG_VIDEO_H264_LEVEL_5_0	= 14,
 	V4L2_MPEG_VIDEO_H264_LEVEL_5_1	= 15,
-};
-#define V4L2_CID_MPEG_VIDEO_H264_LOOP_FILTER_ALPHA	(V4L2_CID_MPEG_BASE+360)
-#define V4L2_CID_MPEG_VIDEO_H264_LOOP_FILTER_BETA	(V4L2_CID_MPEG_BASE+361)
-#define V4L2_CID_MPEG_VIDEO_H264_LOOP_FILTER_MODE	(V4L2_CID_MPEG_BASE+362)
+	V4L2_MPEG_VIDEO_H264_LEVEL_5_2	= 16,
+	V4L2_MPEG_VIDEO_H264_LEVEL_6_0	= 17,
+	V4L2_MPEG_VIDEO_H264_LEVEL_6_1	= 18,
+	V4L2_MPEG_VIDEO_H264_LEVEL_6_2	= 19,
+};
+#define V4L2_CID_MPEG_VIDEO_H264_LOOP_FILTER_ALPHA	(V4L2_CID_CODEC_BASE+360)
+#define V4L2_CID_MPEG_VIDEO_H264_LOOP_FILTER_BETA	(V4L2_CID_CODEC_BASE+361)
+#define V4L2_CID_MPEG_VIDEO_H264_LOOP_FILTER_MODE	(V4L2_CID_CODEC_BASE+362)
 enum v4l2_mpeg_video_h264_loop_filter_mode {
 	V4L2_MPEG_VIDEO_H264_LOOP_FILTER_MODE_ENABLED				= 0,
 	V4L2_MPEG_VIDEO_H264_LOOP_FILTER_MODE_DISABLED				= 1,
 	V4L2_MPEG_VIDEO_H264_LOOP_FILTER_MODE_DISABLED_AT_SLICE_BOUNDARY	= 2,
 };
-#define V4L2_CID_MPEG_VIDEO_H264_PROFILE		(V4L2_CID_MPEG_BASE+363)
+#define V4L2_CID_MPEG_VIDEO_H264_PROFILE		(V4L2_CID_CODEC_BASE+363)
 enum v4l2_mpeg_video_h264_profile {
 	V4L2_MPEG_VIDEO_H264_PROFILE_BASELINE			= 0,
 	V4L2_MPEG_VIDEO_H264_PROFILE_CONSTRAINED_BASELINE	= 1,
@@ -501,11 +517,12 @@ enum v4l2_mpeg_video_h264_profile {
 	V4L2_MPEG_VIDEO_H264_PROFILE_SCALABLE_HIGH_INTRA	= 14,
 	V4L2_MPEG_VIDEO_H264_PROFILE_STEREO_HIGH		= 15,
 	V4L2_MPEG_VIDEO_H264_PROFILE_MULTIVIEW_HIGH		= 16,
+	V4L2_MPEG_VIDEO_H264_PROFILE_CONSTRAINED_HIGH		= 17,
 };
-#define V4L2_CID_MPEG_VIDEO_H264_VUI_EXT_SAR_HEIGHT	(V4L2_CID_MPEG_BASE+364)
-#define V4L2_CID_MPEG_VIDEO_H264_VUI_EXT_SAR_WIDTH	(V4L2_CID_MPEG_BASE+365)
-#define V4L2_CID_MPEG_VIDEO_H264_VUI_SAR_ENABLE		(V4L2_CID_MPEG_BASE+366)
-#define V4L2_CID_MPEG_VIDEO_H264_VUI_SAR_IDC		(V4L2_CID_MPEG_BASE+367)
+#define V4L2_CID_MPEG_VIDEO_H264_VUI_EXT_SAR_HEIGHT	(V4L2_CID_CODEC_BASE+364)
+#define V4L2_CID_MPEG_VIDEO_H264_VUI_EXT_SAR_WIDTH	(V4L2_CID_CODEC_BASE+365)
+#define V4L2_CID_MPEG_VIDEO_H264_VUI_SAR_ENABLE		(V4L2_CID_CODEC_BASE+366)
+#define V4L2_CID_MPEG_VIDEO_H264_VUI_SAR_IDC		(V4L2_CID_CODEC_BASE+367)
 enum v4l2_mpeg_video_h264_vui_sar_idc {
 	V4L2_MPEG_VIDEO_H264_VUI_SAR_IDC_UNSPECIFIED	= 0,
 	V4L2_MPEG_VIDEO_H264_VUI_SAR_IDC_1x1		= 1,
@@ -526,9 +543,9 @@ enum v4l2_mpeg_video_h264_vui_sar_idc {
 	V4L2_MPEG_VIDEO_H264_VUI_SAR_IDC_2x1		= 16,
 	V4L2_MPEG_VIDEO_H264_VUI_SAR_IDC_EXTENDED	= 17,
 };
-#define V4L2_CID_MPEG_VIDEO_H264_SEI_FRAME_PACKING		(V4L2_CID_MPEG_BASE+368)
-#define V4L2_CID_MPEG_VIDEO_H264_SEI_FP_CURRENT_FRAME_0		(V4L2_CID_MPEG_BASE+369)
-#define V4L2_CID_MPEG_VIDEO_H264_SEI_FP_ARRANGEMENT_TYPE	(V4L2_CID_MPEG_BASE+370)
+#define V4L2_CID_MPEG_VIDEO_H264_SEI_FRAME_PACKING		(V4L2_CID_CODEC_BASE+368)
+#define V4L2_CID_MPEG_VIDEO_H264_SEI_FP_CURRENT_FRAME_0		(V4L2_CID_CODEC_BASE+369)
+#define V4L2_CID_MPEG_VIDEO_H264_SEI_FP_ARRANGEMENT_TYPE	(V4L2_CID_CODEC_BASE+370)
 enum v4l2_mpeg_video_h264_sei_fp_arrangement_type {
 	V4L2_MPEG_VIDEO_H264_SEI_FP_ARRANGEMENT_TYPE_CHECKERBOARD	= 0,
 	V4L2_MPEG_VIDEO_H264_SEI_FP_ARRANGEMENT_TYPE_COLUMN		= 1,
@@ -537,8 +554,8 @@ enum v4l2_mpeg_video_h264_sei_fp_arrangement_type {
 	V4L2_MPEG_VIDEO_H264_SEI_FP_ARRANGEMENT_TYPE_TOP_BOTTOM		= 4,
 	V4L2_MPEG_VIDEO_H264_SEI_FP_ARRANGEMENT_TYPE_TEMPORAL		= 5,
 };
-#define V4L2_CID_MPEG_VIDEO_H264_FMO			(V4L2_CID_MPEG_BASE+371)
-#define V4L2_CID_MPEG_VIDEO_H264_FMO_MAP_TYPE		(V4L2_CID_MPEG_BASE+372)
+#define V4L2_CID_MPEG_VIDEO_H264_FMO			(V4L2_CID_CODEC_BASE+371)
+#define V4L2_CID_MPEG_VIDEO_H264_FMO_MAP_TYPE		(V4L2_CID_CODEC_BASE+372)
 enum v4l2_mpeg_video_h264_fmo_map_type {
 	V4L2_MPEG_VIDEO_H264_FMO_MAP_TYPE_INTERLEAVED_SLICES		= 0,
 	V4L2_MPEG_VIDEO_H264_FMO_MAP_TYPE_SCATTERED_SLICES		= 1,
@@ -548,36 +565,45 @@ enum v4l2_mpeg_video_h264_fmo_map_type {
 	V4L2_MPEG_VIDEO_H264_FMO_MAP_TYPE_WIPE_SCAN			= 5,
 	V4L2_MPEG_VIDEO_H264_FMO_MAP_TYPE_EXPLICIT			= 6,
 };
-#define V4L2_CID_MPEG_VIDEO_H264_FMO_SLICE_GROUP	(V4L2_CID_MPEG_BASE+373)
-#define V4L2_CID_MPEG_VIDEO_H264_FMO_CHANGE_DIRECTION	(V4L2_CID_MPEG_BASE+374)
+#define V4L2_CID_MPEG_VIDEO_H264_FMO_SLICE_GROUP	(V4L2_CID_CODEC_BASE+373)
+#define V4L2_CID_MPEG_VIDEO_H264_FMO_CHANGE_DIRECTION	(V4L2_CID_CODEC_BASE+374)
 enum v4l2_mpeg_video_h264_fmo_change_dir {
 	V4L2_MPEG_VIDEO_H264_FMO_CHANGE_DIR_RIGHT	= 0,
 	V4L2_MPEG_VIDEO_H264_FMO_CHANGE_DIR_LEFT	= 1,
 };
-#define V4L2_CID_MPEG_VIDEO_H264_FMO_CHANGE_RATE	(V4L2_CID_MPEG_BASE+375)
-#define V4L2_CID_MPEG_VIDEO_H264_FMO_RUN_LENGTH		(V4L2_CID_MPEG_BASE+376)
-#define V4L2_CID_MPEG_VIDEO_H264_ASO			(V4L2_CID_MPEG_BASE+377)
-#define V4L2_CID_MPEG_VIDEO_H264_ASO_SLICE_ORDER	(V4L2_CID_MPEG_BASE+378)
-#define V4L2_CID_MPEG_VIDEO_H264_HIERARCHICAL_CODING		(V4L2_CID_MPEG_BASE+379)
-#define V4L2_CID_MPEG_VIDEO_H264_HIERARCHICAL_CODING_TYPE	(V4L2_CID_MPEG_BASE+380)
+#define V4L2_CID_MPEG_VIDEO_H264_FMO_CHANGE_RATE	(V4L2_CID_CODEC_BASE+375)
+#define V4L2_CID_MPEG_VIDEO_H264_FMO_RUN_LENGTH		(V4L2_CID_CODEC_BASE+376)
+#define V4L2_CID_MPEG_VIDEO_H264_ASO			(V4L2_CID_CODEC_BASE+377)
+#define V4L2_CID_MPEG_VIDEO_H264_ASO_SLICE_ORDER	(V4L2_CID_CODEC_BASE+378)
+#define V4L2_CID_MPEG_VIDEO_H264_HIERARCHICAL_CODING		(V4L2_CID_CODEC_BASE+379)
+#define V4L2_CID_MPEG_VIDEO_H264_HIERARCHICAL_CODING_TYPE	(V4L2_CID_CODEC_BASE+380)
 enum v4l2_mpeg_video_h264_hierarchical_coding_type {
 	V4L2_MPEG_VIDEO_H264_HIERARCHICAL_CODING_B	= 0,
 	V4L2_MPEG_VIDEO_H264_HIERARCHICAL_CODING_P	= 1,
 };
-#define V4L2_CID_MPEG_VIDEO_H264_HIERARCHICAL_CODING_LAYER	(V4L2_CID_MPEG_BASE+381)
-#define V4L2_CID_MPEG_VIDEO_H264_HIERARCHICAL_CODING_LAYER_QP	(V4L2_CID_MPEG_BASE+382)
-#define V4L2_CID_MPEG_VIDEO_H264_CONSTRAINED_INTRA_PREDICTION	(V4L2_CID_MPEG_BASE+383)
-#define V4L2_CID_MPEG_VIDEO_H264_CHROMA_QP_INDEX_OFFSET		(V4L2_CID_MPEG_BASE+384)
-#define V4L2_CID_MPEG_VIDEO_H264_I_FRAME_MIN_QP	(V4L2_CID_MPEG_BASE+385)
-#define V4L2_CID_MPEG_VIDEO_H264_I_FRAME_MAX_QP	(V4L2_CID_MPEG_BASE+386)
-#define V4L2_CID_MPEG_VIDEO_H264_P_FRAME_MIN_QP	(V4L2_CID_MPEG_BASE+387)
-#define V4L2_CID_MPEG_VIDEO_H264_P_FRAME_MAX_QP	(V4L2_CID_MPEG_BASE+388)
-#define V4L2_CID_MPEG_VIDEO_MPEG4_I_FRAME_QP	(V4L2_CID_MPEG_BASE+400)
-#define V4L2_CID_MPEG_VIDEO_MPEG4_P_FRAME_QP	(V4L2_CID_MPEG_BASE+401)
-#define V4L2_CID_MPEG_VIDEO_MPEG4_B_FRAME_QP	(V4L2_CID_MPEG_BASE+402)
-#define V4L2_CID_MPEG_VIDEO_MPEG4_MIN_QP	(V4L2_CID_MPEG_BASE+403)
-#define V4L2_CID_MPEG_VIDEO_MPEG4_MAX_QP	(V4L2_CID_MPEG_BASE+404)
-#define V4L2_CID_MPEG_VIDEO_MPEG4_LEVEL		(V4L2_CID_MPEG_BASE+405)
+#define V4L2_CID_MPEG_VIDEO_H264_HIERARCHICAL_CODING_LAYER	(V4L2_CID_CODEC_BASE+381)
+#define V4L2_CID_MPEG_VIDEO_H264_HIERARCHICAL_CODING_LAYER_QP	(V4L2_CID_CODEC_BASE+382)
+#define V4L2_CID_MPEG_VIDEO_H264_CONSTRAINED_INTRA_PREDICTION	(V4L2_CID_CODEC_BASE+383)
+#define V4L2_CID_MPEG_VIDEO_H264_CHROMA_QP_INDEX_OFFSET		(V4L2_CID_CODEC_BASE+384)
+#define V4L2_CID_MPEG_VIDEO_H264_I_FRAME_MIN_QP	(V4L2_CID_CODEC_BASE+385)
+#define V4L2_CID_MPEG_VIDEO_H264_I_FRAME_MAX_QP	(V4L2_CID_CODEC_BASE+386)
+#define V4L2_CID_MPEG_VIDEO_H264_P_FRAME_MIN_QP	(V4L2_CID_CODEC_BASE+387)
+#define V4L2_CID_MPEG_VIDEO_H264_P_FRAME_MAX_QP	(V4L2_CID_CODEC_BASE+388)
+#define V4L2_CID_MPEG_VIDEO_H264_B_FRAME_MIN_QP	(V4L2_CID_CODEC_BASE+389)
+#define V4L2_CID_MPEG_VIDEO_H264_B_FRAME_MAX_QP	(V4L2_CID_CODEC_BASE+390)
+#define V4L2_CID_MPEG_VIDEO_H264_HIER_CODING_L0_BR	(V4L2_CID_CODEC_BASE+391)
+#define V4L2_CID_MPEG_VIDEO_H264_HIER_CODING_L1_BR	(V4L2_CID_CODEC_BASE+392)
+#define V4L2_CID_MPEG_VIDEO_H264_HIER_CODING_L2_BR	(V4L2_CID_CODEC_BASE+393)
+#define V4L2_CID_MPEG_VIDEO_H264_HIER_CODING_L3_BR	(V4L2_CID_CODEC_BASE+394)
+#define V4L2_CID_MPEG_VIDEO_H264_HIER_CODING_L4_BR	(V4L2_CID_CODEC_BASE+395)
+#define V4L2_CID_MPEG_VIDEO_H264_HIER_CODING_L5_BR	(V4L2_CID_CODEC_BASE+396)
+#define V4L2_CID_MPEG_VIDEO_H264_HIER_CODING_L6_BR	(V4L2_CID_CODEC_BASE+397)
+#define V4L2_CID_MPEG_VIDEO_MPEG4_I_FRAME_QP	(V4L2_CID_CODEC_BASE+400)
+#define V4L2_CID_MPEG_VIDEO_MPEG4_P_FRAME_QP	(V4L2_CID_CODEC_BASE+401)
+#define V4L2_CID_MPEG_VIDEO_MPEG4_B_FRAME_QP	(V4L2_CID_CODEC_BASE+402)
+#define V4L2_CID_MPEG_VIDEO_MPEG4_MIN_QP	(V4L2_CID_CODEC_BASE+403)
+#define V4L2_CID_MPEG_VIDEO_MPEG4_MAX_QP	(V4L2_CID_CODEC_BASE+404)
+#define V4L2_CID_MPEG_VIDEO_MPEG4_LEVEL		(V4L2_CID_CODEC_BASE+405)
 enum v4l2_mpeg_video_mpeg4_level {
 	V4L2_MPEG_VIDEO_MPEG4_LEVEL_0	= 0,
 	V4L2_MPEG_VIDEO_MPEG4_LEVEL_0B	= 1,
@@ -588,7 +614,7 @@ enum v4l2_mpeg_video_mpeg4_level {
 	V4L2_MPEG_VIDEO_MPEG4_LEVEL_4	= 6,
 	V4L2_MPEG_VIDEO_MPEG4_LEVEL_5	= 7,
 };
-#define V4L2_CID_MPEG_VIDEO_MPEG4_PROFILE	(V4L2_CID_MPEG_BASE+406)
+#define V4L2_CID_MPEG_VIDEO_MPEG4_PROFILE	(V4L2_CID_CODEC_BASE+406)
 enum v4l2_mpeg_video_mpeg4_profile {
 	V4L2_MPEG_VIDEO_MPEG4_PROFILE_SIMPLE				= 0,
 	V4L2_MPEG_VIDEO_MPEG4_PROFILE_ADVANCED_SIMPLE			= 1,
@@ -596,40 +622,40 @@ enum v4l2_mpeg_video_mpeg4_profile {
 	V4L2_MPEG_VIDEO_MPEG4_PROFILE_SIMPLE_SCALABLE			= 3,
 	V4L2_MPEG_VIDEO_MPEG4_PROFILE_ADVANCED_CODING_EFFICIENCY	= 4,
 };
-#define V4L2_CID_MPEG_VIDEO_MPEG4_QPEL		(V4L2_CID_MPEG_BASE+407)
+#define V4L2_CID_MPEG_VIDEO_MPEG4_QPEL		(V4L2_CID_CODEC_BASE+407)
 
 /*  Control IDs for VP8 streams
  *  Although VP8 is not part of MPEG we add these controls to the MPEG class
  *  as that class is already handling other video compression standards
  */
-#define V4L2_CID_MPEG_VIDEO_VPX_NUM_PARTITIONS		(V4L2_CID_MPEG_BASE+500)
+#define V4L2_CID_MPEG_VIDEO_VPX_NUM_PARTITIONS		(V4L2_CID_CODEC_BASE+500)
 enum v4l2_vp8_num_partitions {
 	V4L2_CID_MPEG_VIDEO_VPX_1_PARTITION	= 0,
 	V4L2_CID_MPEG_VIDEO_VPX_2_PARTITIONS	= 1,
 	V4L2_CID_MPEG_VIDEO_VPX_4_PARTITIONS	= 2,
 	V4L2_CID_MPEG_VIDEO_VPX_8_PARTITIONS	= 3,
 };
-#define V4L2_CID_MPEG_VIDEO_VPX_IMD_DISABLE_4X4		(V4L2_CID_MPEG_BASE+501)
-#define V4L2_CID_MPEG_VIDEO_VPX_NUM_REF_FRAMES		(V4L2_CID_MPEG_BASE+502)
+#define V4L2_CID_MPEG_VIDEO_VPX_IMD_DISABLE_4X4		(V4L2_CID_CODEC_BASE+501)
+#define V4L2_CID_MPEG_VIDEO_VPX_NUM_REF_FRAMES		(V4L2_CID_CODEC_BASE+502)
 enum v4l2_vp8_num_ref_frames {
 	V4L2_CID_MPEG_VIDEO_VPX_1_REF_FRAME	= 0,
 	V4L2_CID_MPEG_VIDEO_VPX_2_REF_FRAME	= 1,
 	V4L2_CID_MPEG_VIDEO_VPX_3_REF_FRAME	= 2,
 };
-#define V4L2_CID_MPEG_VIDEO_VPX_FILTER_LEVEL		(V4L2_CID_MPEG_BASE+503)
-#define V4L2_CID_MPEG_VIDEO_VPX_FILTER_SHARPNESS	(V4L2_CID_MPEG_BASE+504)
-#define V4L2_CID_MPEG_VIDEO_VPX_GOLDEN_FRAME_REF_PERIOD	(V4L2_CID_MPEG_BASE+505)
-#define V4L2_CID_MPEG_VIDEO_VPX_GOLDEN_FRAME_SEL	(V4L2_CID_MPEG_BASE+506)
+#define V4L2_CID_MPEG_VIDEO_VPX_FILTER_LEVEL		(V4L2_CID_CODEC_BASE+503)
+#define V4L2_CID_MPEG_VIDEO_VPX_FILTER_SHARPNESS	(V4L2_CID_CODEC_BASE+504)
+#define V4L2_CID_MPEG_VIDEO_VPX_GOLDEN_FRAME_REF_PERIOD	(V4L2_CID_CODEC_BASE+505)
+#define V4L2_CID_MPEG_VIDEO_VPX_GOLDEN_FRAME_SEL	(V4L2_CID_CODEC_BASE+506)
 enum v4l2_vp8_golden_frame_sel {
 	V4L2_CID_MPEG_VIDEO_VPX_GOLDEN_FRAME_USE_PREV		= 0,
 	V4L2_CID_MPEG_VIDEO_VPX_GOLDEN_FRAME_USE_REF_PERIOD	= 1,
 };
-#define V4L2_CID_MPEG_VIDEO_VPX_MIN_QP			(V4L2_CID_MPEG_BASE+507)
-#define V4L2_CID_MPEG_VIDEO_VPX_MAX_QP			(V4L2_CID_MPEG_BASE+508)
-#define V4L2_CID_MPEG_VIDEO_VPX_I_FRAME_QP		(V4L2_CID_MPEG_BASE+509)
-#define V4L2_CID_MPEG_VIDEO_VPX_P_FRAME_QP		(V4L2_CID_MPEG_BASE+510)
+#define V4L2_CID_MPEG_VIDEO_VPX_MIN_QP			(V4L2_CID_CODEC_BASE+507)
+#define V4L2_CID_MPEG_VIDEO_VPX_MAX_QP			(V4L2_CID_CODEC_BASE+508)
+#define V4L2_CID_MPEG_VIDEO_VPX_I_FRAME_QP		(V4L2_CID_CODEC_BASE+509)
+#define V4L2_CID_MPEG_VIDEO_VPX_P_FRAME_QP		(V4L2_CID_CODEC_BASE+510)
 
-#define V4L2_CID_MPEG_VIDEO_VP8_PROFILE			(V4L2_CID_MPEG_BASE+511)
+#define V4L2_CID_MPEG_VIDEO_VP8_PROFILE			(V4L2_CID_CODEC_BASE+511)
 enum v4l2_mpeg_video_vp8_profile {
 	V4L2_MPEG_VIDEO_VP8_PROFILE_0				= 0,
 	V4L2_MPEG_VIDEO_VP8_PROFILE_1				= 1,
@@ -638,42 +664,59 @@ enum v4l2_mpeg_video_vp8_profile {
 };
 /* Deprecated alias for compatibility reasons. */
 #define V4L2_CID_MPEG_VIDEO_VPX_PROFILE	V4L2_CID_MPEG_VIDEO_VP8_PROFILE
-#define V4L2_CID_MPEG_VIDEO_VP9_PROFILE			(V4L2_CID_MPEG_BASE+512)
+#define V4L2_CID_MPEG_VIDEO_VP9_PROFILE			(V4L2_CID_CODEC_BASE+512)
 enum v4l2_mpeg_video_vp9_profile {
 	V4L2_MPEG_VIDEO_VP9_PROFILE_0				= 0,
 	V4L2_MPEG_VIDEO_VP9_PROFILE_1				= 1,
 	V4L2_MPEG_VIDEO_VP9_PROFILE_2				= 2,
 	V4L2_MPEG_VIDEO_VP9_PROFILE_3				= 3,
 };
+#define V4L2_CID_MPEG_VIDEO_VP9_LEVEL			(V4L2_CID_CODEC_BASE+513)
+enum v4l2_mpeg_video_vp9_level {
+	V4L2_MPEG_VIDEO_VP9_LEVEL_1_0	= 0,
+	V4L2_MPEG_VIDEO_VP9_LEVEL_1_1	= 1,
+	V4L2_MPEG_VIDEO_VP9_LEVEL_2_0	= 2,
+	V4L2_MPEG_VIDEO_VP9_LEVEL_2_1	= 3,
+	V4L2_MPEG_VIDEO_VP9_LEVEL_3_0	= 4,
+	V4L2_MPEG_VIDEO_VP9_LEVEL_3_1	= 5,
+	V4L2_MPEG_VIDEO_VP9_LEVEL_4_0	= 6,
+	V4L2_MPEG_VIDEO_VP9_LEVEL_4_1	= 7,
+	V4L2_MPEG_VIDEO_VP9_LEVEL_5_0	= 8,
+	V4L2_MPEG_VIDEO_VP9_LEVEL_5_1	= 9,
+	V4L2_MPEG_VIDEO_VP9_LEVEL_5_2	= 10,
+	V4L2_MPEG_VIDEO_VP9_LEVEL_6_0	= 11,
+	V4L2_MPEG_VIDEO_VP9_LEVEL_6_1	= 12,
+	V4L2_MPEG_VIDEO_VP9_LEVEL_6_2	= 13,
+};
 
 /* CIDs for HEVC encoding. */
 
-#define V4L2_CID_MPEG_VIDEO_HEVC_MIN_QP		(V4L2_CID_MPEG_BASE + 600)
-#define V4L2_CID_MPEG_VIDEO_HEVC_MAX_QP		(V4L2_CID_MPEG_BASE + 601)
-#define V4L2_CID_MPEG_VIDEO_HEVC_I_FRAME_QP	(V4L2_CID_MPEG_BASE + 602)
-#define V4L2_CID_MPEG_VIDEO_HEVC_P_FRAME_QP	(V4L2_CID_MPEG_BASE + 603)
-#define V4L2_CID_MPEG_VIDEO_HEVC_B_FRAME_QP	(V4L2_CID_MPEG_BASE + 604)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_QP	(V4L2_CID_MPEG_BASE + 605)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_TYPE (V4L2_CID_MPEG_BASE + 606)
+#define V4L2_CID_MPEG_VIDEO_HEVC_MIN_QP		(V4L2_CID_CODEC_BASE + 600)
+#define V4L2_CID_MPEG_VIDEO_HEVC_MAX_QP		(V4L2_CID_CODEC_BASE + 601)
+#define V4L2_CID_MPEG_VIDEO_HEVC_I_FRAME_QP	(V4L2_CID_CODEC_BASE + 602)
+#define V4L2_CID_MPEG_VIDEO_HEVC_P_FRAME_QP	(V4L2_CID_CODEC_BASE + 603)
+#define V4L2_CID_MPEG_VIDEO_HEVC_B_FRAME_QP	(V4L2_CID_CODEC_BASE + 604)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_QP	(V4L2_CID_CODEC_BASE + 605)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_TYPE (V4L2_CID_CODEC_BASE + 606)
 enum v4l2_mpeg_video_hevc_hier_coding_type {
 	V4L2_MPEG_VIDEO_HEVC_HIERARCHICAL_CODING_B	= 0,
 	V4L2_MPEG_VIDEO_HEVC_HIERARCHICAL_CODING_P	= 1,
 };
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_LAYER	(V4L2_CID_MPEG_BASE + 607)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L0_QP	(V4L2_CID_MPEG_BASE + 608)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L1_QP	(V4L2_CID_MPEG_BASE + 609)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L2_QP	(V4L2_CID_MPEG_BASE + 610)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L3_QP	(V4L2_CID_MPEG_BASE + 611)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L4_QP	(V4L2_CID_MPEG_BASE + 612)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L5_QP	(V4L2_CID_MPEG_BASE + 613)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L6_QP	(V4L2_CID_MPEG_BASE + 614)
-#define V4L2_CID_MPEG_VIDEO_HEVC_PROFILE	(V4L2_CID_MPEG_BASE + 615)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_LAYER	(V4L2_CID_CODEC_BASE + 607)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L0_QP	(V4L2_CID_CODEC_BASE + 608)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L1_QP	(V4L2_CID_CODEC_BASE + 609)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L2_QP	(V4L2_CID_CODEC_BASE + 610)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L3_QP	(V4L2_CID_CODEC_BASE + 611)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L4_QP	(V4L2_CID_CODEC_BASE + 612)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L5_QP	(V4L2_CID_CODEC_BASE + 613)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L6_QP	(V4L2_CID_CODEC_BASE + 614)
+#define V4L2_CID_MPEG_VIDEO_HEVC_PROFILE	(V4L2_CID_CODEC_BASE + 615)
 enum v4l2_mpeg_video_hevc_profile {
 	V4L2_MPEG_VIDEO_HEVC_PROFILE_MAIN = 0,
 	V4L2_MPEG_VIDEO_HEVC_PROFILE_MAIN_STILL_PICTURE = 1,
 	V4L2_MPEG_VIDEO_HEVC_PROFILE_MAIN_10 = 2,
 };
-#define V4L2_CID_MPEG_VIDEO_HEVC_LEVEL		(V4L2_CID_MPEG_BASE + 616)
+#define V4L2_CID_MPEG_VIDEO_HEVC_LEVEL		(V4L2_CID_CODEC_BASE + 616)
 enum v4l2_mpeg_video_hevc_level {
 	V4L2_MPEG_VIDEO_HEVC_LEVEL_1	= 0,
 	V4L2_MPEG_VIDEO_HEVC_LEVEL_2	= 1,
@@ -689,64 +732,78 @@ enum v4l2_mpeg_video_hevc_level {
 	V4L2_MPEG_VIDEO_HEVC_LEVEL_6_1	= 11,
 	V4L2_MPEG_VIDEO_HEVC_LEVEL_6_2	= 12,
 };
-#define V4L2_CID_MPEG_VIDEO_HEVC_FRAME_RATE_RESOLUTION	(V4L2_CID_MPEG_BASE + 617)
-#define V4L2_CID_MPEG_VIDEO_HEVC_TIER			(V4L2_CID_MPEG_BASE + 618)
+#define V4L2_CID_MPEG_VIDEO_HEVC_FRAME_RATE_RESOLUTION	(V4L2_CID_CODEC_BASE + 617)
+#define V4L2_CID_MPEG_VIDEO_HEVC_TIER			(V4L2_CID_CODEC_BASE + 618)
 enum v4l2_mpeg_video_hevc_tier {
 	V4L2_MPEG_VIDEO_HEVC_TIER_MAIN = 0,
 	V4L2_MPEG_VIDEO_HEVC_TIER_HIGH = 1,
 };
-#define V4L2_CID_MPEG_VIDEO_HEVC_MAX_PARTITION_DEPTH	(V4L2_CID_MPEG_BASE + 619)
-#define V4L2_CID_MPEG_VIDEO_HEVC_LOOP_FILTER_MODE	(V4L2_CID_MPEG_BASE + 620)
+#define V4L2_CID_MPEG_VIDEO_HEVC_MAX_PARTITION_DEPTH	(V4L2_CID_CODEC_BASE + 619)
+#define V4L2_CID_MPEG_VIDEO_HEVC_LOOP_FILTER_MODE	(V4L2_CID_CODEC_BASE + 620)
 enum v4l2_cid_mpeg_video_hevc_loop_filter_mode {
 	V4L2_MPEG_VIDEO_HEVC_LOOP_FILTER_MODE_DISABLED			 = 0,
 	V4L2_MPEG_VIDEO_HEVC_LOOP_FILTER_MODE_ENABLED			 = 1,
 	V4L2_MPEG_VIDEO_HEVC_LOOP_FILTER_MODE_DISABLED_AT_SLICE_BOUNDARY = 2,
 };
-#define V4L2_CID_MPEG_VIDEO_HEVC_LF_BETA_OFFSET_DIV2	(V4L2_CID_MPEG_BASE + 621)
-#define V4L2_CID_MPEG_VIDEO_HEVC_LF_TC_OFFSET_DIV2	(V4L2_CID_MPEG_BASE + 622)
-#define V4L2_CID_MPEG_VIDEO_HEVC_REFRESH_TYPE		(V4L2_CID_MPEG_BASE + 623)
+#define V4L2_CID_MPEG_VIDEO_HEVC_LF_BETA_OFFSET_DIV2	(V4L2_CID_CODEC_BASE + 621)
+#define V4L2_CID_MPEG_VIDEO_HEVC_LF_TC_OFFSET_DIV2	(V4L2_CID_CODEC_BASE + 622)
+#define V4L2_CID_MPEG_VIDEO_HEVC_REFRESH_TYPE		(V4L2_CID_CODEC_BASE + 623)
 enum v4l2_cid_mpeg_video_hevc_refresh_type {
 	V4L2_MPEG_VIDEO_HEVC_REFRESH_NONE		= 0,
 	V4L2_MPEG_VIDEO_HEVC_REFRESH_CRA		= 1,
 	V4L2_MPEG_VIDEO_HEVC_REFRESH_IDR		= 2,
 };
-#define V4L2_CID_MPEG_VIDEO_HEVC_REFRESH_PERIOD		(V4L2_CID_MPEG_BASE + 624)
-#define V4L2_CID_MPEG_VIDEO_HEVC_LOSSLESS_CU		(V4L2_CID_MPEG_BASE + 625)
-#define V4L2_CID_MPEG_VIDEO_HEVC_CONST_INTRA_PRED	(V4L2_CID_MPEG_BASE + 626)
-#define V4L2_CID_MPEG_VIDEO_HEVC_WAVEFRONT		(V4L2_CID_MPEG_BASE + 627)
-#define V4L2_CID_MPEG_VIDEO_HEVC_GENERAL_PB		(V4L2_CID_MPEG_BASE + 628)
-#define V4L2_CID_MPEG_VIDEO_HEVC_TEMPORAL_ID		(V4L2_CID_MPEG_BASE + 629)
-#define V4L2_CID_MPEG_VIDEO_HEVC_STRONG_SMOOTHING	(V4L2_CID_MPEG_BASE + 630)
-#define V4L2_CID_MPEG_VIDEO_HEVC_MAX_NUM_MERGE_MV_MINUS1	(V4L2_CID_MPEG_BASE + 631)
-#define V4L2_CID_MPEG_VIDEO_HEVC_INTRA_PU_SPLIT		(V4L2_CID_MPEG_BASE + 632)
-#define V4L2_CID_MPEG_VIDEO_HEVC_TMV_PREDICTION		(V4L2_CID_MPEG_BASE + 633)
-#define V4L2_CID_MPEG_VIDEO_HEVC_WITHOUT_STARTCODE	(V4L2_CID_MPEG_BASE + 634)
-#define V4L2_CID_MPEG_VIDEO_HEVC_SIZE_OF_LENGTH_FIELD	(V4L2_CID_MPEG_BASE + 635)
+#define V4L2_CID_MPEG_VIDEO_HEVC_REFRESH_PERIOD		(V4L2_CID_CODEC_BASE + 624)
+#define V4L2_CID_MPEG_VIDEO_HEVC_LOSSLESS_CU		(V4L2_CID_CODEC_BASE + 625)
+#define V4L2_CID_MPEG_VIDEO_HEVC_CONST_INTRA_PRED	(V4L2_CID_CODEC_BASE + 626)
+#define V4L2_CID_MPEG_VIDEO_HEVC_WAVEFRONT		(V4L2_CID_CODEC_BASE + 627)
+#define V4L2_CID_MPEG_VIDEO_HEVC_GENERAL_PB		(V4L2_CID_CODEC_BASE + 628)
+#define V4L2_CID_MPEG_VIDEO_HEVC_TEMPORAL_ID		(V4L2_CID_CODEC_BASE + 629)
+#define V4L2_CID_MPEG_VIDEO_HEVC_STRONG_SMOOTHING	(V4L2_CID_CODEC_BASE + 630)
+#define V4L2_CID_MPEG_VIDEO_HEVC_MAX_NUM_MERGE_MV_MINUS1	(V4L2_CID_CODEC_BASE + 631)
+#define V4L2_CID_MPEG_VIDEO_HEVC_INTRA_PU_SPLIT		(V4L2_CID_CODEC_BASE + 632)
+#define V4L2_CID_MPEG_VIDEO_HEVC_TMV_PREDICTION		(V4L2_CID_CODEC_BASE + 633)
+#define V4L2_CID_MPEG_VIDEO_HEVC_WITHOUT_STARTCODE	(V4L2_CID_CODEC_BASE + 634)
+#define V4L2_CID_MPEG_VIDEO_HEVC_SIZE_OF_LENGTH_FIELD	(V4L2_CID_CODEC_BASE + 635)
 enum v4l2_cid_mpeg_video_hevc_size_of_length_field {
 	V4L2_MPEG_VIDEO_HEVC_SIZE_0		= 0,
 	V4L2_MPEG_VIDEO_HEVC_SIZE_1		= 1,
 	V4L2_MPEG_VIDEO_HEVC_SIZE_2		= 2,
 	V4L2_MPEG_VIDEO_HEVC_SIZE_4		= 3,
 };
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L0_BR	(V4L2_CID_MPEG_BASE + 636)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L1_BR	(V4L2_CID_MPEG_BASE + 637)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L2_BR	(V4L2_CID_MPEG_BASE + 638)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L3_BR	(V4L2_CID_MPEG_BASE + 639)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L4_BR	(V4L2_CID_MPEG_BASE + 640)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L5_BR	(V4L2_CID_MPEG_BASE + 641)
-#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L6_BR	(V4L2_CID_MPEG_BASE + 642)
-#define V4L2_CID_MPEG_VIDEO_REF_NUMBER_FOR_PFRAMES	(V4L2_CID_MPEG_BASE + 643)
-#define V4L2_CID_MPEG_VIDEO_PREPEND_SPSPPS_TO_IDR	(V4L2_CID_MPEG_BASE + 644)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L0_BR	(V4L2_CID_CODEC_BASE + 636)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L1_BR	(V4L2_CID_CODEC_BASE + 637)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L2_BR	(V4L2_CID_CODEC_BASE + 638)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L3_BR	(V4L2_CID_CODEC_BASE + 639)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L4_BR	(V4L2_CID_CODEC_BASE + 640)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L5_BR	(V4L2_CID_CODEC_BASE + 641)
+#define V4L2_CID_MPEG_VIDEO_HEVC_HIER_CODING_L6_BR	(V4L2_CID_CODEC_BASE + 642)
+#define V4L2_CID_MPEG_VIDEO_REF_NUMBER_FOR_PFRAMES	(V4L2_CID_CODEC_BASE + 643)
+#define V4L2_CID_MPEG_VIDEO_PREPEND_SPSPPS_TO_IDR	(V4L2_CID_CODEC_BASE + 644)
+#define V4L2_CID_MPEG_VIDEO_CONSTANT_QUALITY		(V4L2_CID_CODEC_BASE + 645)
+#define V4L2_CID_MPEG_VIDEO_FRAME_SKIP_MODE		(V4L2_CID_CODEC_BASE + 646)
+enum v4l2_mpeg_video_frame_skip_mode {
+	V4L2_MPEG_VIDEO_FRAME_SKIP_MODE_DISABLED	= 0,
+	V4L2_MPEG_VIDEO_FRAME_SKIP_MODE_LEVEL_LIMIT	= 1,
+	V4L2_MPEG_VIDEO_FRAME_SKIP_MODE_BUF_LIMIT	= 2,
+};
+
+#define V4L2_CID_MPEG_VIDEO_HEVC_I_FRAME_MIN_QP        (V4L2_CID_CODEC_BASE + 647)
+#define V4L2_CID_MPEG_VIDEO_HEVC_I_FRAME_MAX_QP        (V4L2_CID_CODEC_BASE + 648)
+#define V4L2_CID_MPEG_VIDEO_HEVC_P_FRAME_MIN_QP        (V4L2_CID_CODEC_BASE + 649)
+#define V4L2_CID_MPEG_VIDEO_HEVC_P_FRAME_MAX_QP        (V4L2_CID_CODEC_BASE + 650)
+#define V4L2_CID_MPEG_VIDEO_HEVC_B_FRAME_MIN_QP        (V4L2_CID_CODEC_BASE + 651)
+#define V4L2_CID_MPEG_VIDEO_HEVC_B_FRAME_MAX_QP        (V4L2_CID_CODEC_BASE + 652)
 
 /*  MPEG-class control IDs specific to the CX2341x driver as defined by V4L2 */
-#define V4L2_CID_MPEG_CX2341X_BASE				(V4L2_CTRL_CLASS_MPEG | 0x1000)
-#define V4L2_CID_MPEG_CX2341X_VIDEO_SPATIAL_FILTER_MODE		(V4L2_CID_MPEG_CX2341X_BASE+0)
+#define V4L2_CID_CODEC_CX2341X_BASE				(V4L2_CTRL_CLASS_CODEC | 0x1000)
+#define V4L2_CID_MPEG_CX2341X_VIDEO_SPATIAL_FILTER_MODE		(V4L2_CID_CODEC_CX2341X_BASE+0)
 enum v4l2_mpeg_cx2341x_video_spatial_filter_mode {
 	V4L2_MPEG_CX2341X_VIDEO_SPATIAL_FILTER_MODE_MANUAL = 0,
 	V4L2_MPEG_CX2341X_VIDEO_SPATIAL_FILTER_MODE_AUTO   = 1,
 };
-#define V4L2_CID_MPEG_CX2341X_VIDEO_SPATIAL_FILTER		(V4L2_CID_MPEG_CX2341X_BASE+1)
-#define V4L2_CID_MPEG_CX2341X_VIDEO_LUMA_SPATIAL_FILTER_TYPE	(V4L2_CID_MPEG_CX2341X_BASE+2)
+#define V4L2_CID_MPEG_CX2341X_VIDEO_SPATIAL_FILTER		(V4L2_CID_CODEC_CX2341X_BASE+1)
+#define V4L2_CID_MPEG_CX2341X_VIDEO_LUMA_SPATIAL_FILTER_TYPE	(V4L2_CID_CODEC_CX2341X_BASE+2)
 enum v4l2_mpeg_cx2341x_video_luma_spatial_filter_type {
 	V4L2_MPEG_CX2341X_VIDEO_LUMA_SPATIAL_FILTER_TYPE_OFF                  = 0,
 	V4L2_MPEG_CX2341X_VIDEO_LUMA_SPATIAL_FILTER_TYPE_1D_HOR               = 1,
@@ -754,18 +811,18 @@ enum v4l2_mpeg_cx2341x_video_luma_spatial_filter_type {
 	V4L2_MPEG_CX2341X_VIDEO_LUMA_SPATIAL_FILTER_TYPE_2D_HV_SEPARABLE      = 3,
 	V4L2_MPEG_CX2341X_VIDEO_LUMA_SPATIAL_FILTER_TYPE_2D_SYM_NON_SEPARABLE = 4,
 };
-#define V4L2_CID_MPEG_CX2341X_VIDEO_CHROMA_SPATIAL_FILTER_TYPE	(V4L2_CID_MPEG_CX2341X_BASE+3)
+#define V4L2_CID_MPEG_CX2341X_VIDEO_CHROMA_SPATIAL_FILTER_TYPE	(V4L2_CID_CODEC_CX2341X_BASE+3)
 enum v4l2_mpeg_cx2341x_video_chroma_spatial_filter_type {
 	V4L2_MPEG_CX2341X_VIDEO_CHROMA_SPATIAL_FILTER_TYPE_OFF    = 0,
 	V4L2_MPEG_CX2341X_VIDEO_CHROMA_SPATIAL_FILTER_TYPE_1D_HOR = 1,
 };
-#define V4L2_CID_MPEG_CX2341X_VIDEO_TEMPORAL_FILTER_MODE	(V4L2_CID_MPEG_CX2341X_BASE+4)
+#define V4L2_CID_MPEG_CX2341X_VIDEO_TEMPORAL_FILTER_MODE	(V4L2_CID_CODEC_CX2341X_BASE+4)
 enum v4l2_mpeg_cx2341x_video_temporal_filter_mode {
 	V4L2_MPEG_CX2341X_VIDEO_TEMPORAL_FILTER_MODE_MANUAL = 0,
 	V4L2_MPEG_CX2341X_VIDEO_TEMPORAL_FILTER_MODE_AUTO   = 1,
 };
-#define V4L2_CID_MPEG_CX2341X_VIDEO_TEMPORAL_FILTER		(V4L2_CID_MPEG_CX2341X_BASE+5)
-#define V4L2_CID_MPEG_CX2341X_VIDEO_MEDIAN_FILTER_TYPE		(V4L2_CID_MPEG_CX2341X_BASE+6)
+#define V4L2_CID_MPEG_CX2341X_VIDEO_TEMPORAL_FILTER		(V4L2_CID_CODEC_CX2341X_BASE+5)
+#define V4L2_CID_MPEG_CX2341X_VIDEO_MEDIAN_FILTER_TYPE		(V4L2_CID_CODEC_CX2341X_BASE+6)
 enum v4l2_mpeg_cx2341x_video_median_filter_type {
 	V4L2_MPEG_CX2341X_VIDEO_MEDIAN_FILTER_TYPE_OFF      = 0,
 	V4L2_MPEG_CX2341X_VIDEO_MEDIAN_FILTER_TYPE_HOR      = 1,
@@ -773,38 +830,38 @@ enum v4l2_mpeg_cx2341x_video_median_filter_type {
 	V4L2_MPEG_CX2341X_VIDEO_MEDIAN_FILTER_TYPE_HOR_VERT = 3,
 	V4L2_MPEG_CX2341X_VIDEO_MEDIAN_FILTER_TYPE_DIAG     = 4,
 };
-#define V4L2_CID_MPEG_CX2341X_VIDEO_LUMA_MEDIAN_FILTER_BOTTOM	(V4L2_CID_MPEG_CX2341X_BASE+7)
-#define V4L2_CID_MPEG_CX2341X_VIDEO_LUMA_MEDIAN_FILTER_TOP	(V4L2_CID_MPEG_CX2341X_BASE+8)
-#define V4L2_CID_MPEG_CX2341X_VIDEO_CHROMA_MEDIAN_FILTER_BOTTOM	(V4L2_CID_MPEG_CX2341X_BASE+9)
-#define V4L2_CID_MPEG_CX2341X_VIDEO_CHROMA_MEDIAN_FILTER_TOP	(V4L2_CID_MPEG_CX2341X_BASE+10)
-#define V4L2_CID_MPEG_CX2341X_STREAM_INSERT_NAV_PACKETS		(V4L2_CID_MPEG_CX2341X_BASE+11)
+#define V4L2_CID_MPEG_CX2341X_VIDEO_LUMA_MEDIAN_FILTER_BOTTOM	(V4L2_CID_CODEC_CX2341X_BASE+7)
+#define V4L2_CID_MPEG_CX2341X_VIDEO_LUMA_MEDIAN_FILTER_TOP	(V4L2_CID_CODEC_CX2341X_BASE+8)
+#define V4L2_CID_MPEG_CX2341X_VIDEO_CHROMA_MEDIAN_FILTER_BOTTOM	(V4L2_CID_CODEC_CX2341X_BASE+9)
+#define V4L2_CID_MPEG_CX2341X_VIDEO_CHROMA_MEDIAN_FILTER_TOP	(V4L2_CID_CODEC_CX2341X_BASE+10)
+#define V4L2_CID_MPEG_CX2341X_STREAM_INSERT_NAV_PACKETS		(V4L2_CID_CODEC_CX2341X_BASE+11)
 
 /*  MPEG-class control IDs specific to the Samsung MFC 5.1 driver as defined by V4L2 */
-#define V4L2_CID_MPEG_MFC51_BASE				(V4L2_CTRL_CLASS_MPEG | 0x1100)
+#define V4L2_CID_CODEC_MFC51_BASE				(V4L2_CTRL_CLASS_CODEC | 0x1100)
 
-#define V4L2_CID_MPEG_MFC51_VIDEO_DECODER_H264_DISPLAY_DELAY		(V4L2_CID_MPEG_MFC51_BASE+0)
-#define V4L2_CID_MPEG_MFC51_VIDEO_DECODER_H264_DISPLAY_DELAY_ENABLE	(V4L2_CID_MPEG_MFC51_BASE+1)
-#define V4L2_CID_MPEG_MFC51_VIDEO_FRAME_SKIP_MODE			(V4L2_CID_MPEG_MFC51_BASE+2)
+#define V4L2_CID_MPEG_MFC51_VIDEO_DECODER_H264_DISPLAY_DELAY		(V4L2_CID_CODEC_MFC51_BASE+0)
+#define V4L2_CID_MPEG_MFC51_VIDEO_DECODER_H264_DISPLAY_DELAY_ENABLE	(V4L2_CID_CODEC_MFC51_BASE+1)
+#define V4L2_CID_MPEG_MFC51_VIDEO_FRAME_SKIP_MODE			(V4L2_CID_CODEC_MFC51_BASE+2)
 enum v4l2_mpeg_mfc51_video_frame_skip_mode {
 	V4L2_MPEG_MFC51_VIDEO_FRAME_SKIP_MODE_DISABLED		= 0,
 	V4L2_MPEG_MFC51_VIDEO_FRAME_SKIP_MODE_LEVEL_LIMIT	= 1,
 	V4L2_MPEG_MFC51_VIDEO_FRAME_SKIP_MODE_BUF_LIMIT		= 2,
 };
-#define V4L2_CID_MPEG_MFC51_VIDEO_FORCE_FRAME_TYPE			(V4L2_CID_MPEG_MFC51_BASE+3)
+#define V4L2_CID_MPEG_MFC51_VIDEO_FORCE_FRAME_TYPE			(V4L2_CID_CODEC_MFC51_BASE+3)
 enum v4l2_mpeg_mfc51_video_force_frame_type {
 	V4L2_MPEG_MFC51_VIDEO_FORCE_FRAME_TYPE_DISABLED		= 0,
 	V4L2_MPEG_MFC51_VIDEO_FORCE_FRAME_TYPE_I_FRAME		= 1,
 	V4L2_MPEG_MFC51_VIDEO_FORCE_FRAME_TYPE_NOT_CODED	= 2,
 };
-#define V4L2_CID_MPEG_MFC51_VIDEO_PADDING				(V4L2_CID_MPEG_MFC51_BASE+4)
-#define V4L2_CID_MPEG_MFC51_VIDEO_PADDING_YUV				(V4L2_CID_MPEG_MFC51_BASE+5)
-#define V4L2_CID_MPEG_MFC51_VIDEO_RC_FIXED_TARGET_BIT			(V4L2_CID_MPEG_MFC51_BASE+6)
-#define V4L2_CID_MPEG_MFC51_VIDEO_RC_REACTION_COEFF			(V4L2_CID_MPEG_MFC51_BASE+7)
-#define V4L2_CID_MPEG_MFC51_VIDEO_H264_ADAPTIVE_RC_ACTIVITY		(V4L2_CID_MPEG_MFC51_BASE+50)
-#define V4L2_CID_MPEG_MFC51_VIDEO_H264_ADAPTIVE_RC_DARK			(V4L2_CID_MPEG_MFC51_BASE+51)
-#define V4L2_CID_MPEG_MFC51_VIDEO_H264_ADAPTIVE_RC_SMOOTH		(V4L2_CID_MPEG_MFC51_BASE+52)
-#define V4L2_CID_MPEG_MFC51_VIDEO_H264_ADAPTIVE_RC_STATIC		(V4L2_CID_MPEG_MFC51_BASE+53)
-#define V4L2_CID_MPEG_MFC51_VIDEO_H264_NUM_REF_PIC_FOR_P		(V4L2_CID_MPEG_MFC51_BASE+54)
+#define V4L2_CID_MPEG_MFC51_VIDEO_PADDING				(V4L2_CID_CODEC_MFC51_BASE+4)
+#define V4L2_CID_MPEG_MFC51_VIDEO_PADDING_YUV				(V4L2_CID_CODEC_MFC51_BASE+5)
+#define V4L2_CID_MPEG_MFC51_VIDEO_RC_FIXED_TARGET_BIT			(V4L2_CID_CODEC_MFC51_BASE+6)
+#define V4L2_CID_MPEG_MFC51_VIDEO_RC_REACTION_COEFF			(V4L2_CID_CODEC_MFC51_BASE+7)
+#define V4L2_CID_MPEG_MFC51_VIDEO_H264_ADAPTIVE_RC_ACTIVITY		(V4L2_CID_CODEC_MFC51_BASE+50)
+#define V4L2_CID_MPEG_MFC51_VIDEO_H264_ADAPTIVE_RC_DARK			(V4L2_CID_CODEC_MFC51_BASE+51)
+#define V4L2_CID_MPEG_MFC51_VIDEO_H264_ADAPTIVE_RC_SMOOTH		(V4L2_CID_CODEC_MFC51_BASE+52)
+#define V4L2_CID_MPEG_MFC51_VIDEO_H264_ADAPTIVE_RC_STATIC		(V4L2_CID_CODEC_MFC51_BASE+53)
+#define V4L2_CID_MPEG_MFC51_VIDEO_H264_NUM_REF_PIC_FOR_P		(V4L2_CID_CODEC_MFC51_BASE+54)
 
 /*  Camera class control IDs */
 
@@ -918,6 +975,13 @@ enum v4l2_auto_focus_range {
 #define V4L2_CID_PAN_SPEED			(V4L2_CID_CAMERA_CLASS_BASE+32)
 #define V4L2_CID_TILT_SPEED			(V4L2_CID_CAMERA_CLASS_BASE+33)
 
+#define V4L2_CID_CAMERA_ORIENTATION		(V4L2_CID_CAMERA_CLASS_BASE+34)
+#define V4L2_CAMERA_ORIENTATION_FRONT		0
+#define V4L2_CAMERA_ORIENTATION_BACK		1
+#define V4L2_CAMERA_ORIENTATION_EXTERNAL	2
+
+#define V4L2_CID_CAMERA_SENSOR_ROTATION		(V4L2_CID_CAMERA_CLASS_BASE+35)
+
 /* FM Modulator class control IDs */
 
 #define V4L2_CID_FM_TX_CLASS_BASE		(V4L2_CTRL_CLASS_FM_TX | 0x900)
@@ -1134,4 +1198,664 @@ enum v4l2_detect_md_mode {
 #define V4L2_CID_DETECT_MD_THRESHOLD_GRID	(V4L2_CID_DETECT_CLASS_BASE + 3)
 #define V4L2_CID_DETECT_MD_REGION_GRID		(V4L2_CID_DETECT_CLASS_BASE + 4)
 
+
+/*  Stateless CODECs controls */
+#define V4L2_CID_CODEC_STATELESS_BASE          (V4L2_CTRL_CLASS_CODEC_STATELESS | 0x900)
+#define V4L2_CID_CODEC_STATELESS_CLASS         (V4L2_CTRL_CLASS_CODEC_STATELESS | 1)
+
+#define V4L2_CID_STATELESS_H264_DECODE_MODE	(V4L2_CID_CODEC_STATELESS_BASE + 0)
+/**
+ * enum v4l2_stateless_h264_decode_mode - Decoding mode
+ *
+ * @V4L2_STATELESS_H264_DECODE_MODE_SLICE_BASED: indicates that decoding
+ * is performed one slice at a time. In this mode,
+ * V4L2_CID_STATELESS_H264_SLICE_PARAMS must contain the parsed slice
+ * parameters and the OUTPUT buffer must contain a single slice.
+ * V4L2_BUF_CAP_SUPPORTS_M2M_HOLD_CAPTURE_BUF feature is used
+ * in order to support multislice frames.
+ * @V4L2_STATELESS_H264_DECODE_MODE_FRAME_BASED: indicates that
+ * decoding is performed per frame. The OUTPUT buffer must contain
+ * all slices and also both fields. This mode is typically supported
+ * by device drivers that are able to parse the slice(s) header(s)
+ * in hardware. When this mode is selected,
+ * V4L2_CID_STATELESS_H264_SLICE_PARAMS is not used.
+ */
+enum v4l2_stateless_h264_decode_mode {
+	V4L2_STATELESS_H264_DECODE_MODE_SLICE_BASED,
+	V4L2_STATELESS_H264_DECODE_MODE_FRAME_BASED,
+};
+
+#define V4L2_CID_STATELESS_H264_START_CODE	(V4L2_CID_CODEC_STATELESS_BASE + 1)
+/**
+ * enum v4l2_stateless_h264_start_code - Start code
+ *
+ * @V4L2_STATELESS_H264_START_CODE_NONE: slices are passed
+ * to the driver without any start code.
+ * @V4L2_STATELESS_H264_START_CODE_ANNEX_B: slices are passed
+ * to the driver with an Annex B start code prefix
+ * (legal start codes can be 3-bytes 0x000001 or 4-bytes 0x00000001).
+ * This mode is typically supported by device drivers that parse
+ * the start code in hardware.
+ */
+enum v4l2_stateless_h264_start_code {
+	V4L2_STATELESS_H264_START_CODE_NONE,
+	V4L2_STATELESS_H264_START_CODE_ANNEX_B,
+};
+
+#define V4L2_H264_SPS_CONSTRAINT_SET0_FLAG			0x01
+#define V4L2_H264_SPS_CONSTRAINT_SET1_FLAG			0x02
+#define V4L2_H264_SPS_CONSTRAINT_SET2_FLAG			0x04
+#define V4L2_H264_SPS_CONSTRAINT_SET3_FLAG			0x08
+#define V4L2_H264_SPS_CONSTRAINT_SET4_FLAG			0x10
+#define V4L2_H264_SPS_CONSTRAINT_SET5_FLAG			0x20
+
+#define V4L2_H264_SPS_FLAG_SEPARATE_COLOUR_PLANE		0x01
+#define V4L2_H264_SPS_FLAG_QPPRIME_Y_ZERO_TRANSFORM_BYPASS	0x02
+#define V4L2_H264_SPS_FLAG_DELTA_PIC_ORDER_ALWAYS_ZERO		0x04
+#define V4L2_H264_SPS_FLAG_GAPS_IN_FRAME_NUM_VALUE_ALLOWED	0x08
+#define V4L2_H264_SPS_FLAG_FRAME_MBS_ONLY			0x10
+#define V4L2_H264_SPS_FLAG_MB_ADAPTIVE_FRAME_FIELD		0x20
+#define V4L2_H264_SPS_FLAG_DIRECT_8X8_INFERENCE			0x40
+
+#define V4L2_H264_SPS_HAS_CHROMA_FORMAT(sps) \
+	((sps)->profile_idc == 100 || (sps)->profile_idc == 110 || \
+	 (sps)->profile_idc == 122 || (sps)->profile_idc == 244 || \
+	 (sps)->profile_idc == 44  || (sps)->profile_idc == 83  || \
+	 (sps)->profile_idc == 86  || (sps)->profile_idc == 118 || \
+	 (sps)->profile_idc == 128 || (sps)->profile_idc == 138 || \
+	 (sps)->profile_idc == 139 || (sps)->profile_idc == 134 || \
+	 (sps)->profile_idc == 135)
+
+#define V4L2_CID_STATELESS_H264_SPS		(V4L2_CID_CODEC_STATELESS_BASE + 2)
+/**
+ * struct v4l2_ctrl_h264_sps - H264 sequence parameter set
+ *
+ * All the members on this sequence parameter set structure match the
+ * sequence parameter set syntax as specified by the H264 specification.
+ *
+ * @profile_idc: see H264 specification.
+ * @constraint_set_flags: see H264 specification.
+ * @level_idc: see H264 specification.
+ * @seq_parameter_set_id: see H264 specification.
+ * @chroma_format_idc: see H264 specification.
+ * @bit_depth_luma_minus8: see H264 specification.
+ * @bit_depth_chroma_minus8: see H264 specification.
+ * @log2_max_frame_num_minus4: see H264 specification.
+ * @pic_order_cnt_type: see H264 specification.
+ * @log2_max_pic_order_cnt_lsb_minus4: see H264 specification.
+ * @max_num_ref_frames: see H264 specification.
+ * @num_ref_frames_in_pic_order_cnt_cycle: see H264 specification.
+ * @offset_for_ref_frame: see H264 specification.
+ * @offset_for_non_ref_pic: see H264 specification.
+ * @offset_for_top_to_bottom_field: see H264 specification.
+ * @pic_width_in_mbs_minus1: see H264 specification.
+ * @pic_height_in_map_units_minus1: see H264 specification.
+ * @flags: see V4L2_H264_SPS_FLAG_{}.
+ */
+struct v4l2_ctrl_h264_sps {
+	__u8 profile_idc;
+	__u8 constraint_set_flags;
+	__u8 level_idc;
+	__u8 seq_parameter_set_id;
+	__u8 chroma_format_idc;
+	__u8 bit_depth_luma_minus8;
+	__u8 bit_depth_chroma_minus8;
+	__u8 log2_max_frame_num_minus4;
+	__u8 pic_order_cnt_type;
+	__u8 log2_max_pic_order_cnt_lsb_minus4;
+	__u8 max_num_ref_frames;
+	__u8 num_ref_frames_in_pic_order_cnt_cycle;
+	__s32 offset_for_ref_frame[255];
+	__s32 offset_for_non_ref_pic;
+	__s32 offset_for_top_to_bottom_field;
+	__u16 pic_width_in_mbs_minus1;
+	__u16 pic_height_in_map_units_minus1;
+	__u32 flags;
+};
+
+#define V4L2_H264_PPS_FLAG_ENTROPY_CODING_MODE				0x0001
+#define V4L2_H264_PPS_FLAG_BOTTOM_FIELD_PIC_ORDER_IN_FRAME_PRESENT	0x0002
+#define V4L2_H264_PPS_FLAG_WEIGHTED_PRED				0x0004
+#define V4L2_H264_PPS_FLAG_DEBLOCKING_FILTER_CONTROL_PRESENT		0x0008
+#define V4L2_H264_PPS_FLAG_CONSTRAINED_INTRA_PRED			0x0010
+#define V4L2_H264_PPS_FLAG_REDUNDANT_PIC_CNT_PRESENT			0x0020
+#define V4L2_H264_PPS_FLAG_TRANSFORM_8X8_MODE				0x0040
+#define V4L2_H264_PPS_FLAG_SCALING_MATRIX_PRESENT			0x0080
+
+#define V4L2_CID_STATELESS_H264_PPS		(V4L2_CID_CODEC_STATELESS_BASE + 3)
+/**
+ * struct v4l2_ctrl_h264_pps - H264 picture parameter set
+ *
+ * Except where noted, all the members on this picture parameter set
+ * structure match the sequence parameter set syntax as specified
+ * by the H264 specification.
+ *
+ * In particular, V4L2_H264_PPS_FLAG_SCALING_MATRIX_PRESENT flag
+ * has a specific meaning. This flag should be set if a non-flat
+ * scaling matrix applies to the picture. In this case, applications
+ * are expected to use V4L2_CID_STATELESS_H264_SCALING_MATRIX,
+ * to pass the values of the non-flat matrices.
+ *
+ * @pic_parameter_set_id: see H264 specification.
+ * @seq_parameter_set_id: see H264 specification.
+ * @num_slice_groups_minus1: see H264 specification.
+ * @num_ref_idx_l0_default_active_minus1: see H264 specification.
+ * @num_ref_idx_l1_default_active_minus1: see H264 specification.
+ * @weighted_bipred_idc: see H264 specification.
+ * @pic_init_qp_minus26: see H264 specification.
+ * @pic_init_qs_minus26: see H264 specification.
+ * @chroma_qp_index_offset: see H264 specification.
+ * @second_chroma_qp_index_offset: see H264 specification.
+ * @flags: see V4L2_H264_PPS_FLAG_{}.
+ */
+struct v4l2_ctrl_h264_pps {
+	__u8 pic_parameter_set_id;
+	__u8 seq_parameter_set_id;
+	__u8 num_slice_groups_minus1;
+	__u8 num_ref_idx_l0_default_active_minus1;
+	__u8 num_ref_idx_l1_default_active_minus1;
+	__u8 weighted_bipred_idc;
+	__s8 pic_init_qp_minus26;
+	__s8 pic_init_qs_minus26;
+	__s8 chroma_qp_index_offset;
+	__s8 second_chroma_qp_index_offset;
+	__u16 flags;
+};
+
+#define V4L2_CID_STATELESS_H264_SCALING_MATRIX	(V4L2_CID_CODEC_STATELESS_BASE + 4)
+/**
+ * struct v4l2_ctrl_h264_scaling_matrix - H264 scaling matrices
+ *
+ * @scaling_list_4x4: scaling matrix after applying the inverse
+ * scanning process. Expected list order is Intra Y, Intra Cb,
+ * Intra Cr, Inter Y, Inter Cb, Inter Cr. The values on each
+ * scaling list are expected in raster scan order.
+ * @scaling_list_8x8: scaling matrix after applying the inverse
+ * scanning process. Expected list order is Intra Y, Inter Y,
+ * Intra Cb, Inter Cb, Intra Cr, Inter Cr. The values on each
+ * scaling list are expected in raster scan order.
+ *
+ * Note that the list order is different for the 4x4 and 8x8
+ * matrices as per the H264 specification, see table 7-2 "Assignment
+ * of mnemonic names to scaling list indices and specification of
+ * fall-back rule".
+ */
+struct v4l2_ctrl_h264_scaling_matrix {
+	__u8 scaling_list_4x4[6][16];
+	__u8 scaling_list_8x8[6][64];
+};
+
+struct v4l2_h264_weight_factors {
+	__s16 luma_weight[32];
+	__s16 luma_offset[32];
+	__s16 chroma_weight[32][2];
+	__s16 chroma_offset[32][2];
+};
+
+#define V4L2_H264_CTRL_PRED_WEIGHTS_REQUIRED(pps, slice) \
+	((((pps)->flags & V4L2_H264_PPS_FLAG_WEIGHTED_PRED) && \
+	 ((slice)->slice_type == V4L2_H264_SLICE_TYPE_P || \
+	  (slice)->slice_type == V4L2_H264_SLICE_TYPE_SP)) || \
+	 ((pps)->weighted_bipred_idc == 1 && \
+	  (slice)->slice_type == V4L2_H264_SLICE_TYPE_B))
+
+#define V4L2_CID_STATELESS_H264_PRED_WEIGHTS	(V4L2_CID_CODEC_STATELESS_BASE + 5)
+/**
+ * struct v4l2_ctrl_h264_pred_weights - Prediction weight table
+ *
+ * Prediction weight table, which matches the syntax specified
+ * by the H264 specification.
+ *
+ * @luma_log2_weight_denom: see H264 specification.
+ * @chroma_log2_weight_denom: see H264 specification.
+ * @weight_factors: luma and chroma weight factors.
+ */
+struct v4l2_ctrl_h264_pred_weights {
+	__u16 luma_log2_weight_denom;
+	__u16 chroma_log2_weight_denom;
+	struct v4l2_h264_weight_factors weight_factors[2];
+};
+
+#define V4L2_H264_SLICE_TYPE_P				0
+#define V4L2_H264_SLICE_TYPE_B				1
+#define V4L2_H264_SLICE_TYPE_I				2
+#define V4L2_H264_SLICE_TYPE_SP				3
+#define V4L2_H264_SLICE_TYPE_SI				4
+
+#define V4L2_H264_SLICE_FLAG_DIRECT_SPATIAL_MV_PRED	0x01
+#define V4L2_H264_SLICE_FLAG_SP_FOR_SWITCH		0x02
+
+#define V4L2_H264_TOP_FIELD_REF				0x1
+#define V4L2_H264_BOTTOM_FIELD_REF			0x2
+#define V4L2_H264_FRAME_REF				0x3
+
+/**
+ * struct v4l2_h264_reference - H264 picture reference
+ *
+ * @fields: indicates how the picture is referenced.
+ * Valid values are V4L2_H264_{}_REF.
+ * @index: index into v4l2_ctrl_h264_decode_params.dpb[].
+ */
+struct v4l2_h264_reference {
+	__u8 fields;
+	__u8 index;
+};
+
+/*
+ * Maximum DPB size, as specified by section 'A.3.1 Level limits
+ * common to the Baseline, Main, and Extended profiles'.
+ */
+#define V4L2_H264_NUM_DPB_ENTRIES 16
+#define V4L2_H264_REF_LIST_LEN (2 * V4L2_H264_NUM_DPB_ENTRIES)
+
+#define V4L2_CID_STATELESS_H264_SLICE_PARAMS	(V4L2_CID_CODEC_STATELESS_BASE + 6)
+/**
+ * struct v4l2_ctrl_h264_slice_params - H264 slice parameters
+ *
+ * This structure holds the H264 syntax elements that are specified
+ * as non-invariant for the slices in a given frame.
+ *
+ * Slice invariant syntax elements are contained in struct
+ * v4l2_ctrl_h264_decode_params. This is done to reduce the API surface
+ * on frame-based decoders, where slice header parsing is done by the
+ * hardware.
+ *
+ * Slice invariant syntax elements are specified in specification section
+ * "7.4.3 Slice header semantics".
+ *
+ * Except where noted, the members on this struct match the slice header syntax.
+ *
+ * @header_bit_size: offset in bits to slice_data() from the beginning of this slice.
+ * @first_mb_in_slice: see H264 specification.
+ * @slice_type: see H264 specification.
+ * @colour_plane_id: see H264 specification.
+ * @redundant_pic_cnt: see H264 specification.
+ * @cabac_init_idc: see H264 specification.
+ * @slice_qp_delta: see H264 specification.
+ * @slice_qs_delta: see H264 specification.
+ * @disable_deblocking_filter_idc: see H264 specification.
+ * @slice_alpha_c0_offset_div2: see H264 specification.
+ * @slice_beta_offset_div2: see H264 specification.
+ * @num_ref_idx_l0_active_minus1: see H264 specification.
+ * @num_ref_idx_l1_active_minus1: see H264 specification.
+ * @reserved: padding field. Should be zeroed by applications.
+ * @ref_pic_list0: reference picture list 0 after applying the per-slice modifications.
+ * @ref_pic_list1: reference picture list 1 after applying the per-slice modifications.
+ * @flags: see V4L2_H264_SLICE_FLAG_{}.
+ */
+struct v4l2_ctrl_h264_slice_params {
+	__u32 header_bit_size;
+	__u32 first_mb_in_slice;
+	__u32 next_slice_first_mb;
+	__u8 slice_type;
+	__u8 colour_plane_id;
+	__u8 redundant_pic_cnt;
+	__u8 cabac_init_idc;
+	__s8 slice_qp_delta;
+	__s8 slice_qs_delta;
+	__u8 disable_deblocking_filter_idc;
+	__s8 slice_alpha_c0_offset_div2;
+	__s8 slice_beta_offset_div2;
+	__u8 num_ref_idx_l0_active_minus1;
+	__u8 num_ref_idx_l1_active_minus1;
+
+	__u8 reserved;
+
+	struct v4l2_h264_reference ref_pic_list0[V4L2_H264_REF_LIST_LEN];
+	struct v4l2_h264_reference ref_pic_list1[V4L2_H264_REF_LIST_LEN];
+
+	__u32 flags;
+};
+
+#define V4L2_H264_DPB_ENTRY_FLAG_VALID		0x01
+#define V4L2_H264_DPB_ENTRY_FLAG_ACTIVE		0x02
+#define V4L2_H264_DPB_ENTRY_FLAG_LONG_TERM	0x04
+#define V4L2_H264_DPB_ENTRY_FLAG_FIELD		0x08
+
+/**
+ * struct v4l2_h264_dpb_entry - H264 decoded picture buffer entry
+ *
+ * @reference_ts: timestamp of the V4L2 capture buffer to use as reference.
+ * The timestamp refers to the timestamp field in struct v4l2_buffer.
+ * Use v4l2_timeval_to_ns() to convert the struct timeval to a __u64.
+ * @pic_num: matches PicNum variable assigned during the reference
+ * picture lists construction process.
+ * @frame_num: frame identifier which matches frame_num syntax element.
+ * @fields: indicates how the DPB entry is referenced. Valid values are
+ * V4L2_H264_{}_REF.
+ * @reserved: padding field. Should be zeroed by applications.
+ * @top_field_order_cnt: matches TopFieldOrderCnt picture value.
+ * @bottom_field_order_cnt: matches BottomFieldOrderCnt picture value.
+ * Note that picture field is indicated by v4l2_buffer.field.
+ * @flags: see V4L2_H264_DPB_ENTRY_FLAG_{}.
+ */
+struct v4l2_h264_dpb_entry {
+	__u64 reference_ts;
+	__u32 pic_num;
+	__u16 frame_num;
+	__u8 fields;
+	__u8 reserved[5];
+	__s32 top_field_order_cnt;
+	__s32 bottom_field_order_cnt;
+	__u32 flags;
+};
+
+#define V4L2_H264_DECODE_PARAM_FLAG_IDR_PIC		0x01
+#define V4L2_H264_DECODE_PARAM_FLAG_FIELD_PIC		0x02
+#define V4L2_H264_DECODE_PARAM_FLAG_BOTTOM_FIELD	0x04
+
+#define V4L2_CID_STATELESS_H264_DECODE_PARAMS	(V4L2_CID_CODEC_STATELESS_BASE + 7)
+/**
+ * struct v4l2_ctrl_h264_decode_params - H264 decoding parameters
+ *
+ * @dpb: decoded picture buffer.
+ * @nal_ref_idc: slice header syntax element.
+ * @frame_num: slice header syntax element.
+ * @top_field_order_cnt: matches TopFieldOrderCnt picture value.
+ * @bottom_field_order_cnt: matches BottomFieldOrderCnt picture value.
+ * Note that picture field is indicated by v4l2_buffer.field.
+ * @idr_pic_id: slice header syntax element.
+ * @pic_order_cnt_lsb: slice header syntax element.
+ * @delta_pic_order_cnt_bottom: slice header syntax element.
+ * @delta_pic_order_cnt0: slice header syntax element.
+ * @delta_pic_order_cnt1: slice header syntax element.
+ * @dec_ref_pic_marking_bit_size: size in bits of dec_ref_pic_marking()
+ * syntax element.
+ * @pic_order_cnt_bit_size: size in bits of pic order count syntax.
+ * @slice_group_change_cycle: slice header syntax element.
+ * @reserved: padding field. Should be zeroed by applications.
+ * @flags: see V4L2_H264_DECODE_PARAM_FLAG_{}.
+ */
+struct v4l2_ctrl_h264_decode_params {
+	struct v4l2_h264_dpb_entry dpb[V4L2_H264_NUM_DPB_ENTRIES];
+	__u16 nal_ref_idc;
+	__u16 frame_num;
+	__s32 top_field_order_cnt;
+	__s32 bottom_field_order_cnt;
+	__u16 idr_pic_id;
+	__u16 pic_order_cnt_lsb;
+	__s32 delta_pic_order_cnt_bottom;
+	__s32 delta_pic_order_cnt0;
+	__s32 delta_pic_order_cnt1;
+	__u32 dec_ref_pic_marking_bit_size;
+	__u32 pic_order_cnt_bit_size;
+	__u32 slice_group_change_cycle;
+
+	__u32 reserved;
+	__u32 flags;
+};
+
+
+/* Stateless FWHT control, used by the vicodec driver */
+
+/* Current FWHT version */
+#define V4L2_FWHT_VERSION			3
+
+/* Set if this is an interlaced format */
+#define V4L2_FWHT_FL_IS_INTERLACED		BIT(0)
+/* Set if this is a bottom-first (NTSC) interlaced format */
+#define V4L2_FWHT_FL_IS_BOTTOM_FIRST		BIT(1)
+/* Set if each 'frame' contains just one field */
+#define V4L2_FWHT_FL_IS_ALTERNATE		BIT(2)
+/*
+ * If V4L2_FWHT_FL_IS_ALTERNATE was set, then this is set if this
+ * 'frame' is the bottom field, else it is the top field.
+ */
+#define V4L2_FWHT_FL_IS_BOTTOM_FIELD		BIT(3)
+/* Set if the Y' plane is uncompressed */
+#define V4L2_FWHT_FL_LUMA_IS_UNCOMPRESSED	BIT(4)
+/* Set if the Cb plane is uncompressed */
+#define V4L2_FWHT_FL_CB_IS_UNCOMPRESSED		BIT(5)
+/* Set if the Cr plane is uncompressed */
+#define V4L2_FWHT_FL_CR_IS_UNCOMPRESSED		BIT(6)
+/* Set if the chroma plane is full height, if cleared it is half height */
+#define V4L2_FWHT_FL_CHROMA_FULL_HEIGHT		BIT(7)
+/* Set if the chroma plane is full width, if cleared it is half width */
+#define V4L2_FWHT_FL_CHROMA_FULL_WIDTH		BIT(8)
+/* Set if the alpha plane is uncompressed */
+#define V4L2_FWHT_FL_ALPHA_IS_UNCOMPRESSED	BIT(9)
+/* Set if this is an I Frame */
+#define V4L2_FWHT_FL_I_FRAME			BIT(10)
+
+/* A 4-values flag - the number of components - 1 */
+#define V4L2_FWHT_FL_COMPONENTS_NUM_MSK		GENMASK(18, 16)
+#define V4L2_FWHT_FL_COMPONENTS_NUM_OFFSET	16
+
+/* A 4-values flag - the pixel encoding type */
+#define V4L2_FWHT_FL_PIXENC_MSK			GENMASK(20, 19)
+#define V4L2_FWHT_FL_PIXENC_OFFSET		19
+#define V4L2_FWHT_FL_PIXENC_YUV			(1 << V4L2_FWHT_FL_PIXENC_OFFSET)
+#define V4L2_FWHT_FL_PIXENC_RGB			(2 << V4L2_FWHT_FL_PIXENC_OFFSET)
+#define V4L2_FWHT_FL_PIXENC_HSV			(3 << V4L2_FWHT_FL_PIXENC_OFFSET)
+
+#define V4L2_CID_STATELESS_FWHT_PARAMS		(V4L2_CID_CODEC_STATELESS_BASE + 100)
+/**
+ * struct v4l2_ctrl_fwht_params - FWHT parameters
+ *
+ * @backward_ref_ts: timestamp of the V4L2 capture buffer to use as reference.
+ * The timestamp refers to the timestamp field in struct v4l2_buffer.
+ * Use v4l2_timeval_to_ns() to convert the struct timeval to a __u64.
+ * @version: must be V4L2_FWHT_VERSION.
+ * @width: width of frame.
+ * @height: height of frame.
+ * @flags: FWHT flags (see V4L2_FWHT_FL_*).
+ * @colorspace: the colorspace (enum v4l2_colorspace).
+ * @xfer_func: the transfer function (enum v4l2_xfer_func).
+ * @ycbcr_enc: the Y'CbCr encoding (enum v4l2_ycbcr_encoding).
+ * @quantization: the quantization (enum v4l2_quantization).
+ */
+struct v4l2_ctrl_fwht_params {
+	__u64 backward_ref_ts;
+	__u32 version;
+	__u32 width;
+	__u32 height;
+	__u32 flags;
+	__u32 colorspace;
+	__u32 xfer_func;
+	__u32 ycbcr_enc;
+	__u32 quantization;
+};
+
+/* Stateless VP8 control */
+
+#define V4L2_VP8_SEGMENT_FLAG_ENABLED              0x01
+#define V4L2_VP8_SEGMENT_FLAG_UPDATE_MAP           0x02
+#define V4L2_VP8_SEGMENT_FLAG_UPDATE_FEATURE_DATA  0x04
+#define V4L2_VP8_SEGMENT_FLAG_DELTA_VALUE_MODE     0x08
+
+/**
+ * struct v4l2_vp8_segment - VP8 segment-based adjustments parameters
+ *
+ * @quant_update: update values for the segment quantizer.
+ * @lf_update: update values for the loop filter level.
+ * @segment_probs: branch probabilities of the segment_id decoding tree.
+ * @padding: padding field. Should be zeroed by applications.
+ * @flags: see V4L2_VP8_SEGMENT_FLAG_{}.
+ *
+ * This structure contains segment-based adjustments related parameters.
+ * See the 'update_segmentation()' part of the frame header syntax,
+ * and section '9.3. Segment-Based Adjustments' of the VP8 specification
+ * for more details.
+ */
+struct v4l2_vp8_segment {
+	__s8 quant_update[4];
+	__s8 lf_update[4];
+	__u8 segment_probs[3];
+	__u8 padding;
+	__u32 flags;
+};
+
+#define V4L2_VP8_LF_ADJ_ENABLE	0x01
+#define V4L2_VP8_LF_DELTA_UPDATE	0x02
+#define V4L2_VP8_LF_FILTER_TYPE_SIMPLE	0x04
+
+/**
+ * struct v4l2_vp8_loop_filter - VP8 loop filter parameters
+ *
+ * @ref_frm_delta: Reference frame signed delta values.
+ * @mb_mode_delta: MB prediction mode signed delta values.
+ * @sharpness_level: matches sharpness_level syntax element.
+ * @level: matches loop_filter_level syntax element.
+ * @padding: padding field. Should be zeroed by applications.
+ * @flags: see V4L2_VP8_LF_FLAG_{}.
+ *
+ * This structure contains loop filter related parameters.
+ * See the 'mb_lf_adjustments()' part of the frame header syntax,
+ * and section '9.4. Loop Filter Type and Levels' of the VP8 specification
+ * for more details.
+ */
+struct v4l2_vp8_loop_filter {
+	__s8 ref_frm_delta[4];
+	__s8 mb_mode_delta[4];
+	__u8 sharpness_level;
+	__u8 level;
+	__u16 padding;
+	__u32 flags;
+};
+
+/**
+ * struct v4l2_vp8_quantization - VP8 quantizattion indices
+ *
+ * @y_ac_qi: luma AC coefficient table index.
+ * @y_dc_delta: luma DC delta vaue.
+ * @y2_dc_delta: y2 block DC delta value.
+ * @y2_ac_delta: y2 block AC delta value.
+ * @uv_dc_delta: chroma DC delta value.
+ * @uv_ac_delta: chroma AC delta value.
+ * @padding: padding field. Should be zeroed by applications.
+
+ * This structure contains the quantization indices present
+ * in 'quant_indices()' part of the frame header syntax.
+ * See section '9.6. Dequantization Indices' of the VP8 specification
+ * for more details.
+ */
+struct v4l2_vp8_quantization {
+	__u8 y_ac_qi;
+	__s8 y_dc_delta;
+	__s8 y2_dc_delta;
+	__s8 y2_ac_delta;
+	__s8 uv_dc_delta;
+	__s8 uv_ac_delta;
+	__u16 padding;
+};
+
+#define V4L2_VP8_COEFF_PROB_CNT 11
+#define V4L2_VP8_MV_PROB_CNT 19
+
+/**
+ * struct v4l2_vp8_entropy - VP8 update probabilities
+ *
+ * @coeff_probs: coefficient probability update values.
+ * @y_mode_probs: luma intra-prediction probabilities.
+ * @uv_mode_probs: chroma intra-prediction probabilities.
+ * @mv_probs: mv decoding probability.
+ * @padding: padding field. Should be zeroed by applications.
+ *
+ * This structure contains the update probabilities present in
+ * 'token_prob_update()' and 'mv_prob_update()' part of the frame header.
+ * See section '17.2. Probability Updates' of the VP8 specification
+ * for more details.
+ */
+struct v4l2_vp8_entropy {
+	__u8 coeff_probs[4][8][3][V4L2_VP8_COEFF_PROB_CNT];
+	__u8 y_mode_probs[4];
+	__u8 uv_mode_probs[3];
+	__u8 mv_probs[2][V4L2_VP8_MV_PROB_CNT];
+	__u8 padding[3];
+};
+
+/**
+ * struct v4l2_vp8_entropy_coder_state - VP8 boolean coder state
+ *
+ * @range: coder state value for "Range"
+ * @value: coder state value for "Value"
+ * @bit_count: number of bits left in range "Value".
+ * @padding: padding field. Should be zeroed by applications.
+ *
+ * This structure contains the state for the boolean coder, as
+ * explained in section '7. Boolean Entropy Decoder' of the VP8 specification.
+ */
+struct v4l2_vp8_entropy_coder_state {
+	__u8 range;
+	__u8 value;
+	__u8 bit_count;
+	__u8 padding;
+};
+
+#define V4L2_VP8_FRAME_FLAG_KEY_FRAME		0x01
+#define V4L2_VP8_FRAME_FLAG_EXPERIMENTAL		0x02
+#define V4L2_VP8_FRAME_FLAG_SHOW_FRAME		0x04
+#define V4L2_VP8_FRAME_FLAG_MB_NO_SKIP_COEFF	0x08
+#define V4L2_VP8_FRAME_FLAG_SIGN_BIAS_GOLDEN	0x10
+#define V4L2_VP8_FRAME_FLAG_SIGN_BIAS_ALT	0x20
+
+#define V4L2_VP8_FRAME_IS_KEY_FRAME(hdr) \
+	(!!((hdr)->flags & V4L2_VP8_FRAME_FLAG_KEY_FRAME))
+
+#define V4L2_CID_STATELESS_VP8_FRAME (V4L2_CID_CODEC_STATELESS_BASE + 200)
+/**
+ * struct v4l2_vp8_frame - VP8 frame parameters
+ *
+ * @seg: segmentation parameters. See &v4l2_vp8_segment for more details
+ * @lf: loop filter parameters. See &v4l2_vp8_loop_filter for more details
+ * @quant: quantization parameters. See &v4l2_vp8_quantization for more details
+ * @probs: probabilities. See &v4l2_vp9_probabilities for more details
+ * @width: frame width.
+ * @height: frame height.
+ * @horizontal_scale: horizontal scaling factor.
+ * @vertical_scale: vertical scaling factor.
+ * @version: bitstream version.
+ * @prob_skip_false: frame header syntax element.
+ * @prob_intra: frame header syntax element.
+ * @prob_last: frame header syntax element.
+ * @prob_gf: frame header syntax element.
+ * @num_dct_parts: number of DCT coefficients partitions.
+ * @first_part_size: size of the first partition, i.e. the control partition.
+ * @first_part_header_bits: size in bits of the first partition header portion.
+ * @dct_part_sizes: DCT coefficients sizes.
+ * @last_frame_ts: "last" reference buffer timestamp.
+ * The timestamp refers to the timestamp field in struct v4l2_buffer.
+ * Use v4l2_timeval_to_ns() to convert the struct timeval to a __u64.
+ * @golden_frame_ts: "golden" reference buffer timestamp.
+ * @alt_frame_ts: "alt" reference buffer timestamp.
+ * @flags: see V4L2_VP8_FRAME_FLAG_{}.
+ */
+struct v4l2_ctrl_vp8_frame {
+	struct v4l2_vp8_segment seg;
+	struct v4l2_vp8_loop_filter lf;
+	struct v4l2_vp8_quantization quant;
+	struct v4l2_vp8_entropy entropy;
+	struct v4l2_vp8_entropy_coder_state coder_state;
+
+	__u16 width;
+	__u16 height;
+
+	__u8 horizontal_scale;
+	__u8 vertical_scale;
+
+	__u8 version;
+	__u8 prob_skip_false;
+	__u8 prob_intra;
+	__u8 prob_last;
+	__u8 prob_gf;
+	__u8 num_dct_parts;
+
+	__u32 first_part_size;
+	__u32 first_part_header_bits;
+	__u32 dct_part_sizes[8];
+
+	__u64 last_frame_ts;
+	__u64 golden_frame_ts;
+	__u64 alt_frame_ts;
+
+	__u64 flags;
+};
+
+/* MPEG-compression definitions kept for backwards compatibility */
+#define V4L2_CTRL_CLASS_MPEG            V4L2_CTRL_CLASS_CODEC
+#define V4L2_CID_MPEG_CLASS             V4L2_CID_CODEC_CLASS
+#define V4L2_CID_MPEG_BASE              V4L2_CID_CODEC_BASE
+#define V4L2_CID_MPEG_CX2341X_BASE      V4L2_CID_CODEC_CX2341X_BASE
+#define V4L2_CID_MPEG_MFC51_BASE        V4L2_CID_CODEC_MFC51_BASE
+
 #endif
diff --git a/sys/v4l2codecs/linux/videodev2.h b/sys/v4l2codecs/linux/videodev2.h
index 13355e4c0..bdd39c404 100644
--- a/sys/v4l2codecs/linux/videodev2.h
+++ b/sys/v4l2codecs/linux/videodev2.h
@@ -169,6 +169,8 @@ enum v4l2_buf_type {
 	 || (type) == V4L2_BUF_TYPE_SDR_OUTPUT			\
 	 || (type) == V4L2_BUF_TYPE_META_OUTPUT)
 
+#define V4L2_TYPE_IS_CAPTURE(type) (!V4L2_TYPE_IS_OUTPUT(type))
+
 enum v4l2_tuner_type {
 	V4L2_TUNER_RADIO	     = 1,
 	V4L2_TUNER_ANALOG_TV	     = 2,
@@ -217,9 +219,7 @@ enum v4l2_colorspace {
 	V4L2_COLORSPACE_470_SYSTEM_M  = 5,
 
 	/*
-	 * EBU Tech 3213 PAL/SECAM colorspace. This only makes sense when
-	 * dealing with really old PAL/SECAM recordings. Superseded by
-	 * SMPTE 170M.
+	 * EBU Tech 3213 PAL/SECAM colorspace.
 	 */
 	V4L2_COLORSPACE_470_SYSTEM_BG = 6,
 
@@ -324,14 +324,12 @@ enum v4l2_ycbcr_encoding {
 	/* Rec. 709/EN 61966-2-4 Extended Gamut -- HDTV */
 	V4L2_YCBCR_ENC_XV709          = 4,
 
-#ifndef __KERNEL__
 	/*
 	 * sYCC (Y'CbCr encoding of sRGB), identical to ENC_601. It was added
 	 * originally due to a misunderstanding of the sYCC standard. It should
 	 * not be used, instead use V4L2_YCBCR_ENC_601.
 	 */
 	V4L2_YCBCR_ENC_SYCC           = 5,
-#endif
 
 	/* BT.2020 Non-constant Luminance Y'CbCr */
 	V4L2_YCBCR_ENC_BT2020         = 6,
@@ -369,9 +367,9 @@ enum v4l2_hsv_encoding {
 
 enum v4l2_quantization {
 	/*
-	 * The default for R'G'B' quantization is always full range, except
-	 * for the BT2020 colorspace. For Y'CbCr the quantization is always
-	 * limited range, except for COLORSPACE_JPEG: this is full range.
+	 * The default for R'G'B' quantization is always full range.
+	 * For Y'CbCr the quantization is always limited range, except
+	 * for COLORSPACE_JPEG: this is full range.
 	 */
 	V4L2_QUANTIZATION_DEFAULT     = 0,
 	V4L2_QUANTIZATION_FULL_RANGE  = 1,
@@ -380,14 +378,13 @@ enum v4l2_quantization {
 
 /*
  * Determine how QUANTIZATION_DEFAULT should map to a proper quantization.
- * This depends on whether the image is RGB or not, the colorspace and the
- * Y'CbCr encoding.
+ * This depends on whether the image is RGB or not, the colorspace.
+ * The Y'CbCr encoding is not used anymore, but is still there for backwards
+ * compatibility.
  */
 #define V4L2_MAP_QUANTIZATION_DEFAULT(is_rgb_or_hsv, colsp, ycbcr_enc) \
-	(((is_rgb_or_hsv) && (colsp) == V4L2_COLORSPACE_BT2020) ? \
-	 V4L2_QUANTIZATION_LIM_RANGE : \
-	 (((is_rgb_or_hsv) || (colsp) == V4L2_COLORSPACE_JPEG) ? \
-	 V4L2_QUANTIZATION_FULL_RANGE : V4L2_QUANTIZATION_LIM_RANGE))
+	(((is_rgb_or_hsv) || (colsp) == V4L2_COLORSPACE_JPEG) ? \
+	 V4L2_QUANTIZATION_FULL_RANGE : V4L2_QUANTIZATION_LIM_RANGE)
 
 /*
  * Deprecated names for opRGB colorspace (IEC 61966-2-5)
@@ -395,10 +392,8 @@ enum v4l2_quantization {
  * WARNING: Please don't use these deprecated defines in your code, as
  * there is a chance we have to remove them in the future.
  */
-#ifndef __KERNEL__
 #define V4L2_COLORSPACE_ADOBERGB V4L2_COLORSPACE_OPRGB
 #define V4L2_XFER_FUNC_ADOBERGB  V4L2_XFER_FUNC_OPRGB
-#endif
 
 enum v4l2_priority {
 	V4L2_PRIORITY_UNSET       = 0,  /* not initialized */
@@ -485,6 +480,8 @@ struct v4l2_capability {
 
 #define V4L2_CAP_TOUCH                  0x10000000  /* Is a touch device */
 
+#define V4L2_CAP_IO_MC			0x20000000  /* Is input/output controlled by the media controller */
+
 #define V4L2_CAP_DEVICE_CAPS            0x80000000  /* sets device capabilities field */
 
 /*
@@ -592,8 +589,6 @@ struct v4l2_pix_format {
 #define V4L2_PIX_FMT_XYUV32  v4l2_fourcc('X', 'Y', 'U', 'V') /* 32  XYUV-8-8-8-8  */
 #define V4L2_PIX_FMT_VUYA32  v4l2_fourcc('V', 'U', 'Y', 'A') /* 32  VUYA-8-8-8-8  */
 #define V4L2_PIX_FMT_VUYX32  v4l2_fourcc('V', 'U', 'Y', 'X') /* 32  VUYX-8-8-8-8  */
-#define V4L2_PIX_FMT_HI240   v4l2_fourcc('H', 'I', '2', '4') /*  8  8-bit color   */
-#define V4L2_PIX_FMT_HM12    v4l2_fourcc('H', 'M', '1', '2') /*  8  YUV 4:2:0 16x16 macroblocks */
 #define V4L2_PIX_FMT_M420    v4l2_fourcc('M', '4', '2', '0') /* 12  YUV 4:2:0 2 lines y, 1 line uv interleaved */
 
 /* two planes -- one Y, one Cr + Cb interleaved  */
@@ -603,6 +598,7 @@ struct v4l2_pix_format {
 #define V4L2_PIX_FMT_NV61    v4l2_fourcc('N', 'V', '6', '1') /* 16  Y/CrCb 4:2:2  */
 #define V4L2_PIX_FMT_NV24    v4l2_fourcc('N', 'V', '2', '4') /* 24  Y/CbCr 4:4:4  */
 #define V4L2_PIX_FMT_NV42    v4l2_fourcc('N', 'V', '4', '2') /* 24  Y/CrCb 4:4:4  */
+#define V4L2_PIX_FMT_HM12    v4l2_fourcc('H', 'M', '1', '2') /*  8  YUV 4:2:0 16x16 macroblocks */
 
 /* two non contiguous planes - one Y, one Cr + Cb interleaved  */
 #define V4L2_PIX_FMT_NV12M   v4l2_fourcc('N', 'M', '1', '2') /* 12  Y/CbCr 4:2:0  */
@@ -696,10 +692,12 @@ struct v4l2_pix_format {
 #define V4L2_PIX_FMT_VC1_ANNEX_G v4l2_fourcc('V', 'C', '1', 'G') /* SMPTE 421M Annex G compliant stream */
 #define V4L2_PIX_FMT_VC1_ANNEX_L v4l2_fourcc('V', 'C', '1', 'L') /* SMPTE 421M Annex L compliant stream */
 #define V4L2_PIX_FMT_VP8      v4l2_fourcc('V', 'P', '8', '0') /* VP8 */
+#define V4L2_PIX_FMT_VP8_FRAME v4l2_fourcc('V', 'P', '8', 'F') /* VP8 parsed frame */
 #define V4L2_PIX_FMT_VP9      v4l2_fourcc('V', 'P', '9', '0') /* VP9 */
 #define V4L2_PIX_FMT_HEVC     v4l2_fourcc('H', 'E', 'V', 'C') /* HEVC aka H.265 */
 #define V4L2_PIX_FMT_FWHT     v4l2_fourcc('F', 'W', 'H', 'T') /* Fast Walsh Hadamard Transform (vicodec) */
 #define V4L2_PIX_FMT_FWHT_STATELESS     v4l2_fourcc('S', 'F', 'W', 'H') /* Stateless FWHT (vicodec) */
+#define V4L2_PIX_FMT_H264_SLICE v4l2_fourcc('S', '2', '6', '4') /* H264 parsed slices */
 
 /*  Vendor-specific formats   */
 #define V4L2_PIX_FMT_CPIA1    v4l2_fourcc('C', 'P', 'I', 'A') /* cpia1 YUV */
@@ -735,6 +733,7 @@ struct v4l2_pix_format {
 #define V4L2_PIX_FMT_INZI     v4l2_fourcc('I', 'N', 'Z', 'I') /* Intel Planar Greyscale 10-bit and Depth 16-bit */
 #define V4L2_PIX_FMT_SUNXI_TILED_NV12 v4l2_fourcc('S', 'T', '1', '2') /* Sunxi Tiled NV12 Format */
 #define V4L2_PIX_FMT_CNF4     v4l2_fourcc('C', 'N', 'F', '4') /* Intel 4-bit packed depth confidence information */
+#define V4L2_PIX_FMT_HI240    v4l2_fourcc('H', 'I', '2', '4') /* BTTV 8-bit dithered RGB */
 
 /* 10bit raw bayer packed, 32 bytes for every 25 pixels, last LSB 6 bits unused */
 #define V4L2_PIX_FMT_IPU3_SBGGR10	v4l2_fourcc('i', 'p', '3', 'b') /* IPU3 packed 10-bit BGGR bayer */
@@ -765,11 +764,16 @@ struct v4l2_pix_format {
 #define V4L2_META_FMT_D4XX        v4l2_fourcc('D', '4', 'X', 'X') /* D4XX Payload Header metadata */
 #define V4L2_META_FMT_VIVID	  v4l2_fourcc('V', 'I', 'V', 'D') /* Vivid Metadata */
 
+/* Vendor specific - used for RK_ISP1 camera sub-system */
+#define V4L2_META_FMT_RK_ISP1_PARAMS	v4l2_fourcc('R', 'K', '1', 'P') /* Rockchip ISP1 3A Parameters */
+#define V4L2_META_FMT_RK_ISP1_STAT_3A	v4l2_fourcc('R', 'K', '1', 'S') /* Rockchip ISP1 3A Statistics */
+
 /* priv field value to indicates that subsequent fields are valid. */
 #define V4L2_PIX_FMT_PRIV_MAGIC		0xfeedcafe
 
 /* Flags */
 #define V4L2_PIX_FMT_FLAG_PREMUL_ALPHA	0x00000001
+#define V4L2_PIX_FMT_FLAG_SET_CSC	0x00000002
 
 /*
  *	F O R M A T   E N U M E R A T I O N
@@ -780,13 +784,20 @@ struct v4l2_fmtdesc {
 	__u32               flags;
 	__u8		    description[32];   /* Description string */
 	__u32		    pixelformat;       /* Format fourcc      */
-	__u32		    reserved[4];
+	__u32		    mbus_code;		/* Media bus code    */
+	__u32		    reserved[3];
 };
 
 #define V4L2_FMT_FLAG_COMPRESSED		0x0001
 #define V4L2_FMT_FLAG_EMULATED			0x0002
 #define V4L2_FMT_FLAG_CONTINUOUS_BYTESTREAM	0x0004
 #define V4L2_FMT_FLAG_DYN_RESOLUTION		0x0008
+#define V4L2_FMT_FLAG_ENC_CAP_FRAME_INTERVAL	0x0010
+#define V4L2_FMT_FLAG_CSC_COLORSPACE		0x0020
+#define V4L2_FMT_FLAG_CSC_XFER_FUNC		0x0040
+#define V4L2_FMT_FLAG_CSC_YCBCR_ENC		0x0080
+#define V4L2_FMT_FLAG_CSC_HSV_ENC		V4L2_FMT_FLAG_CSC_YCBCR_ENC
+#define V4L2_FMT_FLAG_CSC_QUANTIZATION		0x0100
 
 	/* Frame Size and frame rate enumeration */
 /*
@@ -916,23 +927,6 @@ struct v4l2_jpegcompression {
  *	M E M O R Y - M A P P I N G   B U F F E R S
  */
 
-#ifdef __KERNEL__
-/*
- * This corresponds to the user space version of timeval
- * for 64-bit time_t. sparc64 is different from everyone
- * else, using the microseconds in the wrong half of the
- * second 64-bit word.
- */
-struct __kernel_v4l2_timeval {
-	long long	tv_sec;
-#if defined(__sparc__) && defined(__arch64__)
-	int		tv_usec;
-	int		__pad;
-#else
-	long long	tv_usec;
-#endif
-};
-#endif
 
 struct v4l2_requestbuffers {
 	__u32			count;
@@ -943,12 +937,13 @@ struct v4l2_requestbuffers {
 };
 
 /* capabilities for struct v4l2_requestbuffers and v4l2_create_buffers */
-#define V4L2_BUF_CAP_SUPPORTS_MMAP	(1 << 0)
-#define V4L2_BUF_CAP_SUPPORTS_USERPTR	(1 << 1)
-#define V4L2_BUF_CAP_SUPPORTS_DMABUF	(1 << 2)
-#define V4L2_BUF_CAP_SUPPORTS_REQUESTS	(1 << 3)
-#define V4L2_BUF_CAP_SUPPORTS_ORPHANED_BUFS (1 << 4)
+#define V4L2_BUF_CAP_SUPPORTS_MMAP			(1 << 0)
+#define V4L2_BUF_CAP_SUPPORTS_USERPTR			(1 << 1)
+#define V4L2_BUF_CAP_SUPPORTS_DMABUF			(1 << 2)
+#define V4L2_BUF_CAP_SUPPORTS_REQUESTS			(1 << 3)
+#define V4L2_BUF_CAP_SUPPORTS_ORPHANED_BUFS		(1 << 4)
 #define V4L2_BUF_CAP_SUPPORTS_M2M_HOLD_CAPTURE_BUF	(1 << 5)
+#define V4L2_BUF_CAP_SUPPORTS_MMAP_CACHE_HINTS		(1 << 6)
 
 /**
  * struct v4l2_plane - plane info for multi-planar buffers
@@ -1019,11 +1014,7 @@ struct v4l2_buffer {
 	__u32			bytesused;
 	__u32			flags;
 	__u32			field;
-#ifdef __KERNEL__
-	struct __kernel_v4l2_timeval timestamp;
-#else
 	struct timeval		timestamp;
-#endif
 	struct v4l2_timecode	timecode;
 	__u32			sequence;
 
@@ -1043,7 +1034,6 @@ struct v4l2_buffer {
 	};
 };
 
-#ifndef __KERNEL__
 /**
  * v4l2_timeval_to_ns - Convert timeval to nanoseconds
  * @ts:		pointer to the timeval variable to be converted
@@ -1051,11 +1041,10 @@ struct v4l2_buffer {
  * Returns the scalar nanosecond representation of the timeval
  * parameter.
  */
-static inline __u64 v4l2_timeval_to_ns(const struct timeval *tv)
+static __inline__ __u64 v4l2_timeval_to_ns(const struct timeval *tv)
 {
 	return (__u64)tv->tv_sec * 1000000000ULL + tv->tv_usec * 1000;
 }
-#endif
 
 /*  Flags for 'flags' field */
 /* Buffer is mapped (flag) */
@@ -1164,16 +1153,16 @@ struct v4l2_framebuffer {
 
 struct v4l2_clip {
 	struct v4l2_rect        c;
-	struct v4l2_clip	__user *next;
+	struct v4l2_clip	*next;
 };
 
 struct v4l2_window {
 	struct v4l2_rect        w;
 	__u32			field;	 /* enum v4l2_field */
 	__u32			chromakey;
-	struct v4l2_clip	__user *clips;
+	struct v4l2_clip	*clips;
 	__u32			clipcount;
-	void			__user *bitmap;
+	void			*bitmap;
 	__u8                    global_alpha;
 };
 
@@ -1712,20 +1701,25 @@ struct v4l2_ext_control {
 	union {
 		__s32 value;
 		__s64 value64;
-		char __user *string;
-		__u8 __user *p_u8;
-		__u16 __user *p_u16;
-		__u32 __user *p_u32;
-		struct v4l2_area __user *p_area;
-		void __user *ptr;
+		char *string;
+		__u8 *p_u8;
+		__u16 *p_u16;
+		__u32 *p_u32;
+		struct v4l2_area *p_area;
+		struct v4l2_ctrl_h264_sps *p_h264_sps;
+		struct v4l2_ctrl_h264_pps *p_h264_pps;
+		struct v4l2_ctrl_h264_scaling_matrix *p_h264_scaling_matrix;
+		struct v4l2_ctrl_h264_pred_weights *p_h264_pred_weights;
+		struct v4l2_ctrl_h264_slice_params *p_h264_slice_params;
+		struct v4l2_ctrl_h264_decode_params *p_h264_decode_params;
+		struct v4l2_ctrl_fwht_params *p_fwht_params;
+		void *ptr;
 	};
 } __attribute__ ((packed));
 
 struct v4l2_ext_controls {
 	union {
-#ifndef __KERNEL__
 		__u32 ctrl_class;
-#endif
 		__u32 which;
 	};
 	__u32 count;
@@ -1736,9 +1730,7 @@ struct v4l2_ext_controls {
 };
 
 #define V4L2_CTRL_ID_MASK	  (0x0fffffff)
-#ifndef __KERNEL__
 #define V4L2_CTRL_ID2CLASS(id)    ((id) & 0x0fff0000UL)
-#endif
 #define V4L2_CTRL_ID2WHICH(id)    ((id) & 0x0fff0000UL)
 #define V4L2_CTRL_DRIVER_PRIV(id) (((id) & 0xffff) >= 0x1000)
 #define V4L2_CTRL_MAX_DIMS	  (4)
@@ -1763,6 +1755,17 @@ enum v4l2_ctrl_type {
 	V4L2_CTRL_TYPE_U16	     = 0x0101,
 	V4L2_CTRL_TYPE_U32	     = 0x0102,
 	V4L2_CTRL_TYPE_AREA          = 0x0106,
+
+	V4L2_CTRL_TYPE_H264_SPS             = 0x0200,
+	V4L2_CTRL_TYPE_H264_PPS		    = 0x0201,
+	V4L2_CTRL_TYPE_H264_SCALING_MATRIX  = 0x0202,
+	V4L2_CTRL_TYPE_H264_SLICE_PARAMS    = 0x0203,
+	V4L2_CTRL_TYPE_H264_DECODE_PARAMS   = 0x0204,
+	V4L2_CTRL_TYPE_H264_PRED_WEIGHTS    = 0x0205,
+
+	V4L2_CTRL_TYPE_FWHT_PARAMS	    = 0x0220,
+
+	V4L2_CTRL_TYPE_VP8_FRAME            = 0x0240,
 };
 
 /*  Used in the VIDIOC_QUERYCTRL ioctl for querying controls */
@@ -2371,11 +2374,7 @@ struct v4l2_event {
 	} u;
 	__u32				pending;
 	__u32				sequence;
-#ifdef __KERNEL__
-	struct __kernel_timespec	timestamp;
-#else
 	struct timespec			timestamp;
-#endif
 	__u32				id;
 	__u32				reserved[8];
 };
diff --git a/sys/v4l2codecs/linux/vp8-ctrls.h b/sys/v4l2codecs/linux/vp8-ctrls.h
deleted file mode 100644
index 53cba826e..000000000
--- a/sys/v4l2codecs/linux/vp8-ctrls.h
+++ /dev/null
@@ -1,112 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*
- * These are the VP8 state controls for use with stateless VP8
- * codec drivers.
- *
- * It turns out that these structs are not stable yet and will undergo
- * more changes. So keep them private until they are stable and ready to
- * become part of the official public API.
- */
-
-#ifndef _VP8_CTRLS_H_
-#define _VP8_CTRLS_H_
-
-#include <linux/types.h>
-
-#define V4L2_PIX_FMT_VP8_FRAME v4l2_fourcc('V', 'P', '8', 'F')
-
-#define V4L2_CID_MPEG_VIDEO_VP8_FRAME_HEADER (V4L2_CID_MPEG_BASE + 2000)
-#define V4L2_CTRL_TYPE_VP8_FRAME_HEADER 0x301
-
-#define V4L2_VP8_SEGMENT_HEADER_FLAG_ENABLED              0x01
-#define V4L2_VP8_SEGMENT_HEADER_FLAG_UPDATE_MAP           0x02
-#define V4L2_VP8_SEGMENT_HEADER_FLAG_UPDATE_FEATURE_DATA  0x04
-#define V4L2_VP8_SEGMENT_HEADER_FLAG_DELTA_VALUE_MODE     0x08
-
-struct v4l2_vp8_segment_header {
-	__s8 quant_update[4];
-	__s8 lf_update[4];
-	__u8 segment_probs[3];
-	__u8 padding;
-	__u32 flags;
-};
-
-#define V4L2_VP8_LF_HEADER_ADJ_ENABLE	0x01
-#define V4L2_VP8_LF_HEADER_DELTA_UPDATE	0x02
-#define V4L2_VP8_LF_FILTER_TYPE_SIMPLE	0x04
-struct v4l2_vp8_loopfilter_header {
-	__s8 ref_frm_delta[4];
-	__s8 mb_mode_delta[4];
-	__u8 sharpness_level;
-	__u8 level;
-	__u16 padding;
-	__u32 flags;
-};
-
-struct v4l2_vp8_quantization_header {
-	__u8 y_ac_qi;
-	__s8 y_dc_delta;
-	__s8 y2_dc_delta;
-	__s8 y2_ac_delta;
-	__s8 uv_dc_delta;
-	__s8 uv_ac_delta;
-	__u16 padding;
-};
-
-struct v4l2_vp8_entropy_header {
-	__u8 coeff_probs[4][8][3][11];
-	__u8 y_mode_probs[4];
-	__u8 uv_mode_probs[3];
-	__u8 mv_probs[2][19];
-	__u8 padding[3];
-};
-
-struct v4l2_vp8_entropy_coder_state {
-	__u8 range;
-	__u8 value;
-	__u8 bit_count;
-	__u8 padding;
-};
-
-#define V4L2_VP8_FRAME_HEADER_FLAG_KEY_FRAME		0x01
-#define V4L2_VP8_FRAME_HEADER_FLAG_EXPERIMENTAL		0x02
-#define V4L2_VP8_FRAME_HEADER_FLAG_SHOW_FRAME		0x04
-#define V4L2_VP8_FRAME_HEADER_FLAG_MB_NO_SKIP_COEFF	0x08
-#define V4L2_VP8_FRAME_HEADER_FLAG_SIGN_BIAS_GOLDEN	0x10
-#define V4L2_VP8_FRAME_HEADER_FLAG_SIGN_BIAS_ALT	0x20
-
-#define VP8_FRAME_IS_KEY_FRAME(hdr) \
-	(!!((hdr)->flags & V4L2_VP8_FRAME_HEADER_FLAG_KEY_FRAME))
-
-struct v4l2_ctrl_vp8_frame_header {
-	struct v4l2_vp8_segment_header segment_header;
-	struct v4l2_vp8_loopfilter_header lf_header;
-	struct v4l2_vp8_quantization_header quant_header;
-	struct v4l2_vp8_entropy_header entropy_header;
-	struct v4l2_vp8_entropy_coder_state coder_state;
-
-	__u16 width;
-	__u16 height;
-
-	__u8 horizontal_scale;
-	__u8 vertical_scale;
-
-	__u8 version;
-	__u8 prob_skip_false;
-	__u8 prob_intra;
-	__u8 prob_last;
-	__u8 prob_gf;
-	__u8 num_dct_parts;
-
-	__u32 first_part_size;
-	__u32 first_part_header_bits;
-	__u32 dct_part_sizes[8];
-
-	__u64 last_frame_ts;
-	__u64 golden_frame_ts;
-	__u64 alt_frame_ts;
-
-	__u64 flags;
-};
-
-#endif
diff --git a/sys/v4l2codecs/meson.build b/sys/v4l2codecs/meson.build
index 886798bee..ae6ee70c3 100644
--- a/sys/v4l2codecs/meson.build
+++ b/sys/v4l2codecs/meson.build
@@ -4,9 +4,10 @@ v4l2codecs_sources = [
   'gstv4l2codecdevice.c',
   'gstv4l2codech264dec.c',
   'gstv4l2codecpool.c',
-  'gstv4l2codecvp8dec.c',
+#  'gstv4l2codecvp8dec.c',
   'gstv4l2decoder.c',
   'gstv4l2format.c',
+  'gstv4l2codecalphadecodebin.c',
 ]
 
 libgudev_dep = dependency('gudev-1.0', required: get_option('v4l2codecs'))
@@ -37,7 +38,8 @@ if have_v4l2 and libgudev_dep.found()
     c_args : gst_plugins_bad_args,
     cpp_args: gst_plugins_bad_args,
     include_directories : [configinc],
-    dependencies : [gstbase_dep, gstcodecs_dep, gstallocators_dep, libgudev_dep],
+    dependencies : [gstbase_dep, gstcodecs_dep, gstallocators_dep, libgudev_dep,
+                   gstpbutils_dep,],
     install : true,
     install_dir : plugins_install_dir,
   )
diff --git a/sys/v4l2codecs/plugin.c b/sys/v4l2codecs/plugin.c
index eb3afcdbd..0b283213e 100644
--- a/sys/v4l2codecs/plugin.c
+++ b/sys/v4l2codecs/plugin.c
@@ -26,8 +26,7 @@
 #include "gstv4l2codech264dec.h"
 #include "gstv4l2codecvp8dec.h"
 #include "gstv4l2decoder.h"
-#include "linux/h264-ctrls.h"
-#include "linux/vp8-ctrls.h"
+#include "linux/v4l2-controls.h"
 #include "linux/media.h"
 
 #define GST_CAT_DEFAULT gstv4l2codecs_debug
@@ -50,13 +49,15 @@ register_video_decoder (GstPlugin * plugin, GstV4l2CodecDevice * device)
       case V4L2_PIX_FMT_H264_SLICE:
         GST_INFO_OBJECT (decoder, "Registering %s as H264 Decoder",
             device->name);
-        gst_v4l2_codec_h264_dec_register (plugin, device, GST_RANK_PRIMARY + 1);
-        break;
-      case V4L2_PIX_FMT_VP8_FRAME:
-        GST_INFO_OBJECT (decoder, "Registering %s as VP8 Decoder",
-            device->name);
-        gst_v4l2_codec_vp8_dec_register (plugin, device, GST_RANK_PRIMARY + 1);
+        gst_v4l2_codec_h264_dec_register (plugin, decoder, device,
+            GST_RANK_PRIMARY + 1);
         break;
+        // case V4L2_PIX_FMT_VP8_FRAME:
+        //  GST_INFO_OBJECT (decoder, "Registering %s as VP8 Decoder",
+        //      device->name);
+        //  gst_v4l2_codec_vp8_dec_register (plugin, decoder,
+        //      device, GST_RANK_PRIMARY + 1);
+        //  break;
       default:
         GST_FIXME_OBJECT (decoder, "%" GST_FOURCC_FORMAT " is not supported.",
             GST_FOURCC_ARGS (fmt));
-- 
2.25.1

